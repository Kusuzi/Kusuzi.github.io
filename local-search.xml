<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>BingDwenDwen</title>
    <link href="/2022/02/09/BingDwenDwen/"/>
    <url>/2022/02/09/BingDwenDwen/</url>
    
    <content type="html"><![CDATA[<p> 冰墩墩太可爱啦，看到有python画冰墩墩就试了一下，有点好玩。</p><p>原创在公众号 —— Crossing的编程教室</p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Hbase/image.46sj7my77020.webp" alt="image" style="zoom:80%;" /><p>主要是利用了turtle库。turtle绘图体系：1969年诞生，主要用于程序设计入门；turtle库是python的标准库之一；属于入门级的图形绘制函数库。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> turtle<br><br>turtle.title(<span class="hljs-string">&#x27;BingDwenDwen&#x27;</span>)<br><br>turtle.speed(<span class="hljs-number">1000</span>)  <span class="hljs-comment"># 画笔速度，设置表越小</span><br><br><span class="hljs-comment"># 左手</span><br>turtle.penup()  <span class="hljs-comment"># 打开画笔</span><br>turtle.goto(<span class="hljs-number">177</span>, <span class="hljs-number">112</span>)  <span class="hljs-comment"># 设置画笔坐标</span><br>turtle.pencolor(<span class="hljs-string">&quot;lightgray&quot;</span>)   <span class="hljs-comment"># 设置画笔颜色</span><br>turtle.pensize(<span class="hljs-number">3</span>)  <span class="hljs-comment"># 设置画笔粗细</span><br>turtle.fillcolor(<span class="hljs-string">&quot;white&quot;</span>)  <span class="hljs-comment"># 设置即将填充的颜色</span><br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">80</span>)  <span class="hljs-comment"># 设置画笔出发角度</span><br>turtle.circle(-<span class="hljs-number">45</span>, <span class="hljs-number">200</span>)  <span class="hljs-comment"># 弧度右顺</span><br>turtle.circle(-<span class="hljs-number">300</span>, <span class="hljs-number">23</span>)<br>turtle.end_fill()  <span class="hljs-comment"># 将弧度所包围的区域填充设置的颜色</span><br><br><span class="hljs-comment"># 左手内</span><br>turtle.penup()<br>turtle.goto(<span class="hljs-number">182</span>, <span class="hljs-number">95</span>)<br>turtle.pencolor(<span class="hljs-string">&quot;black&quot;</span>)<br>turtle.pensize(<span class="hljs-number">1</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;black&quot;</span>)<br>turtle.begin_fill()<br>turtle.setheading(<span class="hljs-number">95</span>)<br>turtle.pendown()<br>turtle.circle(-<span class="hljs-number">37</span>, <span class="hljs-number">160</span>)<br>turtle.circle(-<span class="hljs-number">20</span>, <span class="hljs-number">50</span>)<br>turtle.circle(-<span class="hljs-number">200</span>, <span class="hljs-number">30</span>)<br>turtle.end_fill()<br><span class="hljs-comment"># 轮廓</span><br><span class="hljs-comment"># 头顶</span><br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">73</span>, <span class="hljs-number">230</span>)<br>turtle.pencolor(<span class="hljs-string">&quot;lightgray&quot;</span>)<br>turtle.pensize(<span class="hljs-number">3</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;white&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">20</span>)<br>turtle.circle(-<span class="hljs-number">250</span>, <span class="hljs-number">35</span>)<br><span class="hljs-comment"># 左耳</span><br>turtle.setheading(<span class="hljs-number">50</span>)<br>turtle.circle(-<span class="hljs-number">42</span>, <span class="hljs-number">180</span>)<br><span class="hljs-comment"># 左侧</span><br>turtle.setheading(-<span class="hljs-number">50</span>)<br>turtle.circle(-<span class="hljs-number">190</span>, <span class="hljs-number">30</span>)<br>turtle.circle(-<span class="hljs-number">320</span>, <span class="hljs-number">45</span>)<br><span class="hljs-comment"># 左腿</span><br>turtle.circle(<span class="hljs-number">120</span>, <span class="hljs-number">30</span>)<br>turtle.circle(<span class="hljs-number">200</span>, <span class="hljs-number">12</span>)<br>turtle.circle(-<span class="hljs-number">18</span>, <span class="hljs-number">85</span>)<br>turtle.circle(-<span class="hljs-number">180</span>, <span class="hljs-number">23</span>)<br>turtle.circle(-<span class="hljs-number">20</span>, <span class="hljs-number">110</span>)<br>turtle.circle(<span class="hljs-number">15</span>, <span class="hljs-number">115</span>)<br>turtle.circle(<span class="hljs-number">100</span>, <span class="hljs-number">12</span>)<br><span class="hljs-comment"># 右腿</span><br>turtle.circle(<span class="hljs-number">15</span>, <span class="hljs-number">120</span>)<br>turtle.circle(-<span class="hljs-number">15</span>, <span class="hljs-number">110</span>)<br>turtle.circle(-<span class="hljs-number">150</span>, <span class="hljs-number">30</span>)<br>turtle.circle(-<span class="hljs-number">15</span>, <span class="hljs-number">70</span>)<br>turtle.circle(-<span class="hljs-number">150</span>, <span class="hljs-number">10</span>)<br>turtle.circle(<span class="hljs-number">200</span>, <span class="hljs-number">35</span>)<br>turtle.circle(-<span class="hljs-number">150</span>, <span class="hljs-number">20</span>)<br><span class="hljs-comment"># 右手</span><br>turtle.setheading(-<span class="hljs-number">120</span>)<br>turtle.circle(<span class="hljs-number">50</span>, <span class="hljs-number">30</span>)<br>turtle.circle(-<span class="hljs-number">35</span>, <span class="hljs-number">200</span>)<br>turtle.circle(-<span class="hljs-number">300</span>, <span class="hljs-number">23</span>)<br><span class="hljs-comment"># 右侧</span><br>turtle.setheading(<span class="hljs-number">86</span>)<br>turtle.circle(-<span class="hljs-number">300</span>, <span class="hljs-number">26</span>)<br><span class="hljs-comment"># 右耳</span><br>turtle.setheading(<span class="hljs-number">122</span>)<br>turtle.circle(-<span class="hljs-number">53</span>, <span class="hljs-number">160</span>)<br>turtle.end_fill()<br><br><span class="hljs-comment"># 右耳内</span><br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">130</span>, <span class="hljs-number">180</span>)<br>turtle.pencolor(<span class="hljs-string">&quot;black&quot;</span>)<br>turtle.pensize(<span class="hljs-number">1</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;black&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">120</span>)<br>turtle.circle(-<span class="hljs-number">28</span>, <span class="hljs-number">160</span>)<br>turtle.setheading(<span class="hljs-number">210</span>)<br>turtle.circle(<span class="hljs-number">150</span>, <span class="hljs-number">20</span>)<br>turtle.end_fill()<br><br><span class="hljs-comment"># 左耳内</span><br>turtle.penup()<br>turtle.goto(<span class="hljs-number">90</span>, <span class="hljs-number">230</span>)<br>turtle.setheading(<span class="hljs-number">40</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.circle(-<span class="hljs-number">30</span>, <span class="hljs-number">170</span>)<br>turtle.setheading(<span class="hljs-number">125</span>)<br>turtle.circle(<span class="hljs-number">150</span>, <span class="hljs-number">23</span>)<br>turtle.end_fill()<br><br><span class="hljs-comment"># 右手内</span><br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">180</span>, -<span class="hljs-number">55</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;black&quot;</span>)<br>turtle.begin_fill()<br>turtle.setheading(-<span class="hljs-number">120</span>)<br>turtle.pendown()<br>turtle.circle(<span class="hljs-number">50</span>, <span class="hljs-number">30</span>)<br>turtle.circle(-<span class="hljs-number">27</span>, <span class="hljs-number">200</span>)<br>turtle.circle(-<span class="hljs-number">300</span>, <span class="hljs-number">20</span>)<br>turtle.setheading(-<span class="hljs-number">90</span>)<br>turtle.circle(<span class="hljs-number">300</span>, <span class="hljs-number">14</span>)<br>turtle.end_fill()<br><br><span class="hljs-comment"># 左腿内</span><br>turtle.penup()<br>turtle.goto(<span class="hljs-number">108</span>, -<span class="hljs-number">168</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;black&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(-<span class="hljs-number">115</span>)<br>turtle.circle(<span class="hljs-number">110</span>, <span class="hljs-number">15</span>)<br>turtle.circle(<span class="hljs-number">200</span>, <span class="hljs-number">10</span>)<br>turtle.circle(-<span class="hljs-number">18</span>, <span class="hljs-number">80</span>)<br>turtle.circle(-<span class="hljs-number">180</span>, <span class="hljs-number">13</span>)<br>turtle.circle(-<span class="hljs-number">20</span>, <span class="hljs-number">90</span>)<br>turtle.circle(<span class="hljs-number">15</span>, <span class="hljs-number">60</span>)<br>turtle.setheading(<span class="hljs-number">42</span>)<br>turtle.circle(-<span class="hljs-number">200</span>, <span class="hljs-number">29</span>)<br>turtle.end_fill()<br><span class="hljs-comment"># 右腿内</span><br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">38</span>, -<span class="hljs-number">210</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;black&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(-<span class="hljs-number">155</span>)<br>turtle.circle(<span class="hljs-number">15</span>, <span class="hljs-number">100</span>)<br>turtle.circle(-<span class="hljs-number">10</span>, <span class="hljs-number">110</span>)<br>turtle.circle(-<span class="hljs-number">100</span>, <span class="hljs-number">30</span>)<br>turtle.circle(-<span class="hljs-number">15</span>, <span class="hljs-number">65</span>)<br>turtle.circle(-<span class="hljs-number">100</span>, <span class="hljs-number">10</span>)<br>turtle.circle(<span class="hljs-number">200</span>, <span class="hljs-number">15</span>)<br>turtle.setheading(-<span class="hljs-number">14</span>)<br>turtle.circle(-<span class="hljs-number">200</span>, <span class="hljs-number">27</span>)<br>turtle.end_fill()<br><br><span class="hljs-comment"># 右眼</span><br><span class="hljs-comment"># 眼圈</span><br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">64</span>, <span class="hljs-number">120</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">40</span>)<br>turtle.circle(-<span class="hljs-number">35</span>, <span class="hljs-number">152</span>)<br>turtle.circle(-<span class="hljs-number">100</span>, <span class="hljs-number">50</span>)<br>turtle.circle(-<span class="hljs-number">35</span>, <span class="hljs-number">130</span>)<br>turtle.circle(-<span class="hljs-number">100</span>, <span class="hljs-number">50</span>)<br>turtle.end_fill()<br><span class="hljs-comment"># 眼珠</span><br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">47</span>, <span class="hljs-number">55</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;white&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">0</span>)<br>turtle.circle(<span class="hljs-number">25</span>, <span class="hljs-number">360</span>)<br>turtle.end_fill()<br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">45</span>, <span class="hljs-number">62</span>)<br>turtle.pencolor(<span class="hljs-string">&quot;darkslategray&quot;</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;darkslategray&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">0</span>)<br>turtle.circle(<span class="hljs-number">19</span>, <span class="hljs-number">360</span>)<br>turtle.end_fill()<br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">45</span>, <span class="hljs-number">68</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;black&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">0</span>)<br>turtle.circle(<span class="hljs-number">10</span>, <span class="hljs-number">360</span>)<br>turtle.end_fill()<br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">47</span>, <span class="hljs-number">86</span>)<br>turtle.pencolor(<span class="hljs-string">&quot;white&quot;</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;white&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">0</span>)<br>turtle.circle(<span class="hljs-number">5</span>, <span class="hljs-number">360</span>)<br>turtle.end_fill()<br><br><span class="hljs-comment"># 左眼</span><br><span class="hljs-comment"># 眼圈</span><br>turtle.penup()<br>turtle.goto(<span class="hljs-number">51</span>, <span class="hljs-number">82</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;black&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">120</span>)<br>turtle.circle(-<span class="hljs-number">32</span>, <span class="hljs-number">152</span>)<br>turtle.circle(-<span class="hljs-number">100</span>, <span class="hljs-number">55</span>)<br>turtle.circle(-<span class="hljs-number">25</span>, <span class="hljs-number">120</span>)<br>turtle.circle(-<span class="hljs-number">120</span>, <span class="hljs-number">45</span>)<br>turtle.end_fill()<br><span class="hljs-comment"># 眼珠</span><br>turtle.penup()<br>turtle.goto(<span class="hljs-number">79</span>, <span class="hljs-number">60</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;white&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">0</span>)<br>turtle.circle(<span class="hljs-number">24</span>, <span class="hljs-number">360</span>)<br>turtle.end_fill()<br>turtle.penup()<br>turtle.goto(<span class="hljs-number">79</span>, <span class="hljs-number">64</span>)<br>turtle.pencolor(<span class="hljs-string">&quot;darkslategray&quot;</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;darkslategray&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">0</span>)<br>turtle.circle(<span class="hljs-number">19</span>, <span class="hljs-number">360</span>)<br>turtle.end_fill()<br>turtle.penup()<br>turtle.goto(<span class="hljs-number">79</span>, <span class="hljs-number">70</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;black&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">0</span>)<br>turtle.circle(<span class="hljs-number">10</span>, <span class="hljs-number">360</span>)<br>turtle.end_fill()<br>turtle.penup()<br>turtle.goto(<span class="hljs-number">79</span>, <span class="hljs-number">88</span>)<br>turtle.pencolor(<span class="hljs-string">&quot;white&quot;</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;white&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">0</span>)<br>turtle.circle(<span class="hljs-number">5</span>, <span class="hljs-number">360</span>)<br>turtle.end_fill()<br><br><span class="hljs-comment"># 鼻子</span><br>turtle.penup()<br>turtle.goto(<span class="hljs-number">37</span>, <span class="hljs-number">80</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;black&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.circle(-<span class="hljs-number">8</span>, <span class="hljs-number">130</span>)<br>turtle.circle(-<span class="hljs-number">22</span>, <span class="hljs-number">100</span>)<br>turtle.circle(-<span class="hljs-number">8</span>, <span class="hljs-number">130</span>)<br>turtle.end_fill()<br><br><span class="hljs-comment"># 嘴</span><br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">15</span>, <span class="hljs-number">48</span>)<br>turtle.setheading(-<span class="hljs-number">36</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.circle(<span class="hljs-number">60</span>, <span class="hljs-number">70</span>)<br>turtle.setheading(-<span class="hljs-number">132</span>)<br>turtle.circle(-<span class="hljs-number">45</span>, <span class="hljs-number">100</span>)<br>turtle.end_fill()<br><br><span class="hljs-comment"># 彩虹圈</span><br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">135</span>, <span class="hljs-number">120</span>)<br>turtle.pensize(<span class="hljs-number">5</span>)<br>turtle.pencolor(<span class="hljs-string">&quot;cyan&quot;</span>)<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">60</span>)<br>turtle.circle(-<span class="hljs-number">165</span>, <span class="hljs-number">150</span>)<br>turtle.circle(-<span class="hljs-number">130</span>, <span class="hljs-number">78</span>)<br>turtle.circle(-<span class="hljs-number">250</span>, <span class="hljs-number">30</span>)<br>turtle.circle(-<span class="hljs-number">138</span>, <span class="hljs-number">105</span>)<br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">131</span>, <span class="hljs-number">116</span>)<br>turtle.pencolor(<span class="hljs-string">&quot;slateblue&quot;</span>)<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">60</span>)<br>turtle.circle(-<span class="hljs-number">160</span>, <span class="hljs-number">144</span>)<br>turtle.circle(-<span class="hljs-number">120</span>, <span class="hljs-number">78</span>)<br>turtle.circle(-<span class="hljs-number">242</span>, <span class="hljs-number">30</span>)<br>turtle.circle(-<span class="hljs-number">135</span>, <span class="hljs-number">105</span>)<br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">127</span>, <span class="hljs-number">112</span>)<br>turtle.pencolor(<span class="hljs-string">&quot;orangered&quot;</span>)<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">60</span>)<br>turtle.circle(-<span class="hljs-number">155</span>, <span class="hljs-number">136</span>)<br>turtle.circle(-<span class="hljs-number">116</span>, <span class="hljs-number">86</span>)<br>turtle.circle(-<span class="hljs-number">220</span>, <span class="hljs-number">30</span>)<br>turtle.circle(-<span class="hljs-number">134</span>, <span class="hljs-number">103</span>)<br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">123</span>, <span class="hljs-number">108</span>)<br>turtle.pencolor(<span class="hljs-string">&quot;gold&quot;</span>)<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">60</span>)<br>turtle.circle(-<span class="hljs-number">150</span>, <span class="hljs-number">136</span>)<br>turtle.circle(-<span class="hljs-number">104</span>, <span class="hljs-number">86</span>)<br>turtle.circle(-<span class="hljs-number">220</span>, <span class="hljs-number">30</span>)<br>turtle.circle(-<span class="hljs-number">126</span>, <span class="hljs-number">102</span>)<br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">120</span>, <span class="hljs-number">104</span>)<br>turtle.pencolor(<span class="hljs-string">&quot;greenyellow&quot;</span>)<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">60</span>)<br>turtle.circle(-<span class="hljs-number">145</span>, <span class="hljs-number">136</span>)<br>turtle.circle(-<span class="hljs-number">90</span>, <span class="hljs-number">83</span>)<br>turtle.circle(-<span class="hljs-number">220</span>, <span class="hljs-number">30</span>)<br>turtle.circle(-<span class="hljs-number">120</span>, <span class="hljs-number">100</span>)<br>turtle.penup()<br><br><span class="hljs-comment"># 爱心</span><br>turtle.penup()<br>turtle.goto(<span class="hljs-number">220</span>, <span class="hljs-number">115</span>)<br>turtle.pencolor(<span class="hljs-string">&quot;brown&quot;</span>)<br>turtle.pensize(<span class="hljs-number">1</span>)<br>turtle.fillcolor(<span class="hljs-string">&quot;brown&quot;</span>)<br>turtle.begin_fill()<br>turtle.pendown()<br>turtle.setheading(<span class="hljs-number">36</span>)<br>turtle.circle(-<span class="hljs-number">8</span>, <span class="hljs-number">180</span>)<br>turtle.circle(-<span class="hljs-number">60</span>, <span class="hljs-number">24</span>)<br>turtle.setheading(<span class="hljs-number">110</span>)<br>turtle.circle(-<span class="hljs-number">60</span>, <span class="hljs-number">24</span>)<br>turtle.circle(-<span class="hljs-number">8</span>, <span class="hljs-number">180</span>)<br>turtle.end_fill()<br><br><span class="hljs-comment"># 五环</span><br>turtle.penup()<br>turtle.goto(-<span class="hljs-number">5</span>, -<span class="hljs-number">170</span>)<br>turtle.pendown()<br>turtle.pencolor(<span class="hljs-string">&quot;blue&quot;</span>)<br>turtle.circle(<span class="hljs-number">6</span>)<br>turtle.penup()<br>turtle.goto(<span class="hljs-number">10</span>, -<span class="hljs-number">170</span>)<br>turtle.pendown()<br>turtle.pencolor(<span class="hljs-string">&quot;black&quot;</span>)<br>turtle.circle(<span class="hljs-number">6</span>)<br>turtle.penup()<br>turtle.goto(<span class="hljs-number">25</span>, -<span class="hljs-number">170</span>)<br>turtle.pendown()<br>turtle.pencolor(<span class="hljs-string">&quot;brown&quot;</span>)<br>turtle.circle(<span class="hljs-number">6</span>)<br>turtle.penup()<br>turtle.goto(<span class="hljs-number">2</span>, -<span class="hljs-number">175</span>)<br>turtle.pendown()<br>turtle.pencolor(<span class="hljs-string">&quot;lightgoldenrod&quot;</span>)<br>turtle.circle(<span class="hljs-number">6</span>)<br>turtle.penup()<br>turtle.goto(<span class="hljs-number">16</span>, -<span class="hljs-number">175</span>)<br>turtle.pendown()<br>turtle.pencolor(<span class="hljs-string">&quot;green&quot;</span>)<br>turtle.circle(<span class="hljs-number">6</span>)<br>turtle.penup()<br><br>turtle.pencolor(<span class="hljs-string">&quot;black&quot;</span>)<br>turtle.goto(-<span class="hljs-number">16</span>, -<span class="hljs-number">160</span>)<br>turtle.write(<span class="hljs-string">&quot;BEIJING 2022&quot;</span>, font=(<span class="hljs-string">&#x27;Arial&#x27;</span>, <span class="hljs-number">10</span>, <span class="hljs-string">&#x27;bold italic&#x27;</span>))<br>turtle.hideturtle()<br><br>turtle.done()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Try</category>
      
    </categories>
    
    
    <tags>
      
      <tag>joy</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hbase</title>
    <link href="/2022/01/29/Hbase/"/>
    <url>/2022/01/29/Hbase/</url>
    
    <content type="html"><![CDATA[<h1 id="01-HBase简介"><a href="#01-HBase简介" class="headerlink" title="01. HBase简介"></a>01. HBase简介</h1><p>定义：HBase 是一种分布式、可扩展、支持海量数据存储的 <strong>NoSQL 数据库。</strong></p><h2 id="1-1-HBase数据模型"><a href="#1-1-HBase数据模型" class="headerlink" title="1.1. HBase数据模型"></a>1.1. HBase数据模型</h2><ul><li><p>逻辑结构</p><p>其中包括：列族，rowkey，region，store</p><ol><li>一个列族可以包含多个列</li><li>一个region可以包括多个列族</li><li>一个store包括一个列族</li></ol><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Hbase/image-20220125101908063.1m905abzl128.webp" alt="image-20220125101908063"></p></li><li><p>物理存储结构</p><ol><li>Habse通过cell来定义一个具体的数据</li><li>数据顺序按照row key的字典序来排序</li></ol><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Hbase/image-20220125102158111.2tvwcuj2voo0.webp" alt="image-20220125102158111"></p></li><li><p>数据模型</p><ol><li><strong>Name Space</strong><br>命名空间，<font color='red'>类似于关系型数据库的 DatabBase </font>概念，每个命名空间下有多个表。HBase有两个自带的命名空间，分别是 hbase和 default，hbase 中存放的是 HBase 内置的表，<font color='cornflowerblue'>default 表是用户默认使用的命名空间。</font></li><li><strong>Region</strong><br><font color='red'>类似于关系型数据库的表</font>概念。不同的是，HBase 定义表时只需要声明列族即可，不需要声明具体的列。这意味着，往 HBase 写入数据时，字段可以动态、按需指定。因此，和关系型数据库相比，HBase 能够轻松应对字段变更的场景。</li><li><strong>Row</strong><br>HBase 表中的每行数据都由一个RowKey 和多个  Column（列）组成，数据是按照 RowKey的字典顺序存储的，并且查询数据时只能根据 RowKey 进行检索，所以 RowKey 的设计十分重要。</li><li><strong>Column</strong><br>HBase 中的每个列都由 Column Family(列族)和 Column Qualifier（列限定符）进行限定，例如 info：name，info：age。建表时，只需指明列族，而列限定符无需预先定义</li><li><strong>Time Stamp</strong><br>用于标识数据的不同版本（version），每条数据写入时，如果不指定时间戳，系统会自动为其加上该字段，其值为写入 HBase 的时间。</li><li><strong>Cell</strong><br>由{rowkey, column Family：column Qualifier, time Stamp} 唯一确定的单元。cell 中的数据是没有类型的，全部是字节码形式存贮。</li></ol></li></ul><h2 id="1-2-基础架构"><a href="#1-2-基础架构" class="headerlink" title="1.2. 基础架构"></a>1.2. 基础架构</h2><p>  架构角色主要包括Region Server【对于数据的操作，mysql中的DML语言】,Master【对于表的操作，mysql中的DDL语言】,Zookeeper,HDFS</p><p>  <img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Hbase/image-20220125102756468.2szelrgicvk0.webp" alt="image-20220125102756468"></p><ol><li><strong>Region Server</strong><br>Region Server 为 <font color='cornflowerblue'>Region 的管理者</font>，其实现类为 HRegionServer，主要作用如下:<ul><li>对于数据的操作：get, put, delete；</li><li>对于 Region 的操作：splitRegion、compactRegion。</li></ul></li><li><strong>Master</strong><br>Master 是所有 <font color='cornflowerblue'>Region Server 的管理者</font>，其实现类为 HMaster，主要作用如下：<ul><li>对于表的操作：create, delete, alter</li><li>对于RegionServer的操作：分配regions到每个RegionServer，监控每个RegionServer的状态，负载均衡和故障转移。</li></ul></li><li><strong>Zookeeper</strong><br>HBase 通过 Zookeeper 来做 Master 的高可用、RegionServer 的监控、元数据的入口以及集群配置的维护等工作。</li><li><strong>HDFS</strong><br>HDFS 为 HBase 提供最终的底层数据存储服务，同时为 HBase 提供高可用的支持。</li></ol><h1 id="02-HBase快速入门"><a href="#02-HBase快速入门" class="headerlink" title="02. HBase快速入门"></a>02. HBase快速入门</h1><h2 id="2-1-HBase的安装部署"><a href="#2-1-HBase的安装部署" class="headerlink" title="2.1. HBase的安装部署"></a>2.1. HBase的安装部署</h2><ul><li><p>zookeeper的正常部署</p><blockquote><p>bin/zkServer.sh start</p></blockquote></li><li><p>Hadoop的正常部署</p><blockquote><p>sbin/start-dfs.sh</p></blockquote></li><li><p>Hbae解压</p><p>解压路径为/opt/module文件夹下</p><blockquote><p>tar -zxvf hbase-1.3.1-bin.tar.gz -C /opt/module</p></blockquote></li><li><p>修改Hbase的配置文件</p><p>(1) hbase-env.sh 修改内容</p><blockquote><p>export JAVA_HOME=/opt/module/jdk1.6.0_144<br>export HBASE_MANAGES_ZK=false</p></blockquote><p>(2) hbase-site.xml 修改内容：</p><blockquote><configuration>    <property>            <name>hbase.rootdir</name>            <value>**hdfs://hadoop102:9000/HBase**</value>    </property><p>​    <property><br>​        <name>hbase.cluster.distributed</name><br>​        <value>true</value><br>​    </property></p><!-- 0.98 后的新变动，之前版本没有.port,默认端口为 60000 --><pre><code>&lt;property&gt;        &lt;name&gt;hbase.master.port&lt;/name&gt;        &lt;value&gt;16000&lt;/value&gt;&lt;/property&gt;</code></pre><p>​    <property><br>​            <name>hbase.zookeeper.quorum</name><br>​            <value><strong>hadoop102,hadoop103,hadoop104</strong></value></p><p>​    </property></p><p>​    <property><br>​            <name>hbase.zookeeper.property.dataDir</name><br>​            <value>/opt/module/zookeeper-3.4.10/zkData</value><br>​    </property></p></configuration></blockquote><p>3）regionservers：</p><blockquote><p>hadoop102<br>hadoop103<br>hadoop104</p></blockquote><p>4）软连接 hadoop 配置文件到 HBase：</p><blockquote><p>ln  -s  /opt/module/hadoop-2.7.2/etc/hadoop/<strong>core-site.xml</strong>  /opt/module/hbase/conf/<strong>core-site.xml</strong></p><p>ln  -s  /opt/module/hadoop-2.7.2/etc/hadoop/<strong>hdfs-site.xml</strong>  /opt/module/hbase/conf/<strong>hdfs-site.xml</strong></p></blockquote></li><li><p>HBase 远程发送到其他集群</p><p>在hbase的安装路径下</p><blockquote><p>xsync hbase/</p></blockquote></li><li><p>Hbase服务的启动</p><blockquote><p>bin/start-hbase.sh</p></blockquote></li><li><p>查看Hbase页面</p><blockquote><p>启动成功后，可以通过“host:port”的方式来访问 HBase 管理页面，例如：<a href="http://hadoop102:16010/">http://hadoop102:16010</a></p></blockquote></li></ul><h2 id="2-2-HBase-shell操作"><a href="#2-2-HBase-shell操作" class="headerlink" title="2.2. HBase shell操作"></a>2.2. HBase shell操作</h2><h3 id="2-2-1-基本操作"><a href="#2-2-1-基本操作" class="headerlink" title="2.2.1. 基本操作"></a>2.2.1. 基本操作</h3><ul><li><p>进入Hbase  客户端命令行【bin/hbase shell】</p></li><li><p>查看帮助命令【help】</p></li><li><p>查看当前数据库中有哪些表【list】</p></li></ul><h3 id="2-2-2-表的操作"><a href="#2-2-2-表的操作" class="headerlink" title="2.2.2. 表的操作"></a>2.2.2. 表的操作</h3><ol><li><p>创建表 【create  表名  列族】</p></li><li><p>插入数据列表【put  表名  rowkey  列族:列名  数据】</p></li><li><p>查看全表数据【scan  并表明】</p></li><li><p>查看表结构【describe  表名】</p></li><li><p>更新指定字段的数据【put  表名  rowkey  列族:列名  修改后的数据】</p></li><li><p>查看“指定行”或“指定列族：列”的数据【get  表名  rowkey  （列族:列） || get  表名  rowkey ｛列族:列， VERSION=&gt;X}，指定查看版本数】</p></li><li><p>统计表数据行数【count  表名】</p></li><li><p>删除数据【delete 表名  rowkey  （列族:列）】</p><p><font color='red'>注意：</font>对于命令行来说，删除某一行数据不能用delete，只能用deleteall，但是Java客户端可以直接删</p></li><li><p>清空表数据【truncate  表明】</p><p><font color='red'>注意：</font>清空表的操作顺序为先 disable  表名，然后再 truncate。</p></li><li><p>删除表【drop  表名】</p><p><font color='red'>注意</font>：删除表的操作顺序为先 disable  表名，然后再drop。</p></li><li><p>表更表信息</p><blockquote><p> 将 info 列族中的数据存放 3 个版本：</p><p> alter ‘student’,{NAME=&gt;’info’,VERSIONS=&gt;3}</p></blockquote></li></ol><h1 id="03-HBase进阶"><a href="#03-HBase进阶" class="headerlink" title="03. HBase进阶"></a>03. HBase进阶</h1><h2 id="3-1-架构原理"><a href="#3-1-架构原理" class="headerlink" title="3.1. 架构原理"></a>3.1. 架构原理</h2><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Hbase/image-20220125131748965.38eqqhrpigo0.webp" alt="image-20220125131748965"></p><ol><li>StoreFile<br>保存实际数据的物理文件，StoreFile 以 HFile 的形式存储在 HDFS 上。每个 Store 会有一个或多个 StoreFile（HFile），数据在每个 StoreFile 中都是有序的。</li><li>Me mStore【写缓存】<br>由于 HFile 中的数据要求是有序的，所以数据是<font color='cornflowerblue'>先存储在 MemStore 中，排好序</font>后，等到达刷写时机才会刷写到 HFile，每次刷写都会形成一个新的 HFile。</li><li>WAL【HLog】<br>由于数据要经 MemStore 排序后才能刷写到 HFile，但把数据保存在内存中会有很高的<br>概率导致数据丢失，为了解决这个问题，数据会先写在一个叫做 Write-Ahead logfile 的文件<br>中，然后再写入 MemStore 中。所以在系统出现故障的时候，数据可以通过这个日志文件重<br>建。</li></ol><h2 id="3-2-写流程"><a href="#3-2-写流程" class="headerlink" title="3.2. 写流程"></a>3.2. 写流程</h2><p>写流程需要知道写到哪台机器上，所以需要先请求meta表，meta表保存了表和机器的映射。</p><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Hbase/image-20220125132215629.7430553kubs0.webp" alt="image-20220125132215629"></p><p>流程：</p><ol><li>Client 先访问 zookeeper，获取 hbase:meta 表位于哪个 Region Server。</li><li>访问对应的 Region Server，获取 hbase:meta 表，根据读请求的 namespace:table/rowkey，<br>查询出目标数据位于哪个 Region Server 中的哪个 Region 中。并将该 table 的 region 信息以<br>及 meta 表的位置信息缓存在客户端的 meta cache，方便下次访问。</li><li>与目标 Region Server 进行通讯；</li><li>将数据顺序写入（追加）到 WAL；</li><li>将数据写入对应的 MemStore，数据会在 MemStore 进行排序；</li><li>向客户端发送 ack；</li><li>等达到 MemStore 的刷写时机后，将数据刷写到 HFile。</li></ol><h2 id="3-3-MemStore-Flush"><a href="#3-3-MemStore-Flush" class="headerlink" title="3.3. MemStore Flush"></a>3.3. MemStore Flush</h2><p><strong>刷写规则：</strong>不同的列族是相互独立的，会刷写到不同的文件中。因此图中store对应一个storeFile组。</p><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Hbase/image-20220125132919132.5afdiphw6bo0.webp" alt="image-20220125132919132"></p><p><strong>刷写时机：</strong>主要从容量和时间两个方面进行限制。</p><ul><li><p>容量</p><p>（1）针对单个region来说</p><ul><li>当某个 memstroe 的大小达到了 <u><strong><font color='red'>hbase.hregion.memstore.flush.size （默认值 128M ）</font></strong></u>，<font color='red'>其所在 region 的所有 memstore 都会开始刷写。</font>【开始写入磁盘】</li><li>当 memstore 的大小达到了<u>hbase.hregion.memstore.flush.size*hbase.hregion.memstore.<font color='red'>block.multiplier</font>(默认值 4 )</u>时，会阻止继续往该 memstore 写数据。【阻止客户端往memstore中写】</li></ul><p>（2）针对region server来说            </p><ul><li><p>当 region server 中 memstore 的总大小达到<u>java_heapsize*hbase.regionserver.<font color='red'>global.memstore.size</font>(0.4 )*  hbase.regionserver.global.memstore.size.lower.limit (0.95)</u>时，region 会按照其所有 memstore 的大小顺序（由大到小）依次进行刷写。直到 region server中所有 memstore 的总大小减小到上述值以下。【开始写入磁盘】</p></li><li><p>当 region server 中 memstore 的总大小达到  <u>java_heapsize*hbase.regionserver.global.memstore.size （默认值 0.4 ）</u><br>时，会阻止继续往所有的 memstore 写数据。【阻止客户端往memstore中写】</p></li></ul></li><li><p>时间</p><p>到达自动刷写的时间，也会触发 memstore flush。自动刷新的时间间隔由该属性进行<br>配置 hbase.regionserver.optionalcacheflushinterval （默认 1 小时）。</p></li></ul><h2 id="3-4-读流程"><a href="#3-4-读流程" class="headerlink" title="3.4. 读流程"></a>3.4. 读流程</h2><p>因为Hbase有多版本（按照时间戳分辨）和刷写磁盘，因此不能单单看缓存，也需要和HFile中读取数据来一起对时间戳进行比较，返回时间戳最大的那个版本。当磁盘数据的时间戳比内存数据额时间戳大，也会返回磁盘内的数据，因此不能先读内存，而是将磁盘内的HFile和内存以及读缓存一起查询。</p><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Hbase/image-20220125134508267.3h6ilodqnr80.webp" alt="image-20220125134508267"></p><ol><li>Client 先访问 zookeeper，获取 hbase:meta 表位于哪个 Region Server。</li><li>访问对应的 Region Server，获取 hbase:meta 表，根据读请求的 namespace:table/rowkey，<br>查询出目标数据位于哪个 Region Server 中的哪个 Region 中。并将该 table 的 region 信息以<br>及 meta 表的位置信息缓存在客户端的 meta cache，方便下次访问。</li><li>与目标 Region Server 进行通讯；</li><li>分别在 <font color='cornflowerblue'>Block Cache（读缓存），MemStore 和 Store File（HFile）中查询目标数据</font>，并将<br>查到的所有数据进行合并。此处所有数据是指同一条数据的不同版本（time stamp）或者不<br>同的类型（Put/Delete）。</li><li>将从文件中查询到的数据块（Block，HFile 数据存储单元，默认大小为 64KB）缓存到<br>Block Cache。</li><li>将合并后的最终结果返回给客户端。</li></ol><h2 id="3-5-StoreFile-Compaction"><a href="#3-5-StoreFile-Compaction" class="headerlink" title="3.5. StoreFile Compaction"></a>3.5. StoreFile Compaction</h2><p>​        由于memstore每次刷写都会生成一个新的HFile，且同一个字段的不同版本（timestamp）和不同类型（Put/Delete）有可能会分布在不同的HFile中，因此查询时需要遍历所有的HFile。为了减少 HFile 的个数，以及清理掉过期和删除的数据，会进行 StoreFile Compaction。<br>​        Compaction 分为两种，分别是 <font color='red'>Minor Compaction</font> 和 <font color='red'>Major Compaction</font>。Minor Compaction会将临近的若干个较小的 HFile 合并成一个较大的 HFile，但不会清理过期和删除的数据。<font color='red'>Major Compaction 会将一个 Store 下的所有的 HFile 合并成一个大 HFile，并且会清理掉过期和删除的数据。</font></p><p>​        对于删除标记，在刷写到磁盘时并不会删掉这个标记，因为在磁盘中可能还存在该字段的旧值。只有当major compaction时，才会将数据和标记同时删掉。</p><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Hbase/image-20220125135018888.3z0w92mns100.webp" alt="image-20220125135018888"></p><h2 id="3-6-Region-Split"><a href="#3-6-Region-Split" class="headerlink" title="3.6. Region Split"></a>3.6. Region Split</h2><p>​        默认情况下，每个 Table 起初只有一个 Region，随着数据的不断写入，Region 会自动进<br>行拆分。刚拆分时，两个子 Region 都位于当前的 Region Server，但处于负载均衡的考虑，<br>HMaster 有可能会将某个 Region 转移给其他的 Region Server。<br>Region Split 时机：</p><ol><li>当1个region中的某个Store下所有StoreFile的总大小超过hbase.hregion.max.filesize，<br>该 Region 就会进行拆分（0.94 版本之前）。</li><li>当 1 个 region 中 的某 个 Store 下所有 StoreFile 的总 大 小超过 Min(R^2 *<br>“hbase.hregion.memstore.flush.size”,hbase.hregion.max.filesize”)，该 Region 就会进行拆分，其中 R 为当前 Region Server 中属于该 Table 的region个数（0.94 版本之后）</li></ol><h1 id="04-HBase-API"><a href="#04-HBase-API" class="headerlink" title="04. HBase API"></a>04. HBase API</h1><h2 id="4-1-环境准备"><a href="#4-1-环境准备" class="headerlink" title="4.1. 环境准备"></a>4.1. 环境准备</h2><p>导入hbase依赖</p><blockquote><dependency>        <groupId>org.apache.hbase</groupId>        <artifactId>hbase-server</artifactId>        <version>1.3.1</version></dependency><dependency>        <groupId>org.apache.hbase</groupId>        <artifactId>hbase-client</artifactId>        <version>1.3.1</version></dependency></blockquote><h2 id="4-2-HBase-API"><a href="#4-2-HBase-API" class="headerlink" title="4.2. HBase API"></a>4.2. HBase API</h2><h3 id="4-2-1-获取-Configuration"><a href="#4-2-1-获取-Configuration" class="headerlink" title="4.2.1.  获取 Configuration"></a>4.2.1.  获取 Configuration</h3><p>配置集群信息</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Configuration conf;<br><span class="hljs-keyword">static</span>&#123;<br><span class="hljs-comment">//使用 HBaseConfiguration 的单例方法实例化</span><br>conf = HBaseConfiguration.create();<br>conf.set(<span class="hljs-string">&quot;hbase.zookeeper.quorum&quot;</span>, <span class="hljs-string">&quot;192.166.9.102&quot;</span>); <span class="hljs-comment">// 和集群配置的ip相同</span><br>conf.set(<span class="hljs-string">&quot;hbase.zookeeper.property.clientPort&quot;</span>, <span class="hljs-string">&quot;2181&quot;</span>);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-2-2-判断表是否存在"><a href="#4-2-2-判断表是否存在" class="headerlink" title="4.2.2.  判断表是否存在"></a>4.2.2.  判断表是否存在</h3><p>对表据进行操作时，首先需要获得**<font color='red'>HBaseAdmin</font>**对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">isTableExist</span><span class="hljs-params">(String tableName)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>    <span class="hljs-comment">//在 HBase 中管理、访问表需要先创建 HBaseAdmin 对象</span><br>    HBaseAdmin admin = <span class="hljs-keyword">new</span> HBaseAdmin(conf);<br>    <span class="hljs-keyword">return</span> admin.tableExists(tableName);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-2-3-创建表"><a href="#4-2-3-创建表" class="headerlink" title="4.2.3.  创建表"></a>4.2.3.  创建表</h3><p>创建表时，表名需要通过TableName.valueOf转换为字节</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">createTable</span><span class="hljs-params">(String tableName, String... columnFamily)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>    HBaseAdmin admin = <span class="hljs-keyword">new</span> HBaseAdmin(conf);<br>    <span class="hljs-comment">//判断表是否存在</span><br>    <span class="hljs-keyword">if</span> (isTableExist(tableName)) &#123;<br>        System.out.println(<span class="hljs-string">&quot;表&quot;</span> + tableName + <span class="hljs-string">&quot;已存在&quot;</span>);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">//创建表属性对象,表名需要转字节</span><br>        HTableDescriptor descriptor = <span class="hljs-keyword">new</span> HTableDescriptor(TableName.valueOf(tableName));<br>        <span class="hljs-comment">//创建多个列族</span><br>        <span class="hljs-keyword">for</span> (String cf : columnFamily) &#123;<br>            descriptor.addFamily(<span class="hljs-keyword">new</span> HColumnDescriptor(cf));<br>        &#125;<br>        <span class="hljs-comment">//根据对表的配置，创建表</span><br>        admin.createTable(descriptor);<br>        System.out.println(<span class="hljs-string">&quot;表&quot;</span> + tableName + <span class="hljs-string">&quot;创建成功！&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-2-4-删除表"><a href="#4-2-4-删除表" class="headerlink" title="4.2.4.  删除表"></a>4.2.4.  删除表</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">dropTable</span><span class="hljs-params">(String tableName)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>    HBaseAdmin admin = <span class="hljs-keyword">new</span> HBaseAdmin(conf);<br>    <span class="hljs-keyword">if</span> (isTableExist(tableName)) &#123;<br>        admin.disableTable(tableName);<br>        admin.deleteTable(tableName);<br>        System.out.println(<span class="hljs-string">&quot;表&quot;</span> + tableName + <span class="hljs-string">&quot;删除成功！&quot;</span>);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        System.out.println(<span class="hljs-string">&quot;表&quot;</span> + tableName + <span class="hljs-string">&quot;不存在！&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-2-5-插入数据"><a href="#4-2-5-插入数据" class="headerlink" title="4.2.5.  插入数据"></a>4.2.5.  插入数据</h3><p>对数据进行操作时，首先需要获得**<font color='red'>HTable</font>**对象</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">addRowData</span><span class="hljs-params">(String tableName, String rowKey,</span></span><br><span class="hljs-params"><span class="hljs-function">                              String columnFamily, String column,</span></span><br><span class="hljs-params"><span class="hljs-function">                              String value)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>    <span class="hljs-comment">//创建 HTable 对象</span><br>    HTable hTable = <span class="hljs-keyword">new</span> HTable(conf, tableName);<br>    <span class="hljs-comment">//向表中插入数据，创建Put对象</span><br>    Put put = <span class="hljs-keyword">new</span> Put(Bytes.toBytes(rowKey));<br>    <span class="hljs-comment">//向 Put 对象中组装数据</span><br>    put.add(Bytes.toBytes(columnFamily), Bytes.toBytes(column), Bytes.toBytes(value));<br>    hTable.put(put);<br>    hTable.close();<br>    System.out.println(<span class="hljs-string">&quot;插入数据成功&quot;</span>);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-2-6-删除多行数据"><a href="#4-2-6-删除多行数据" class="headerlink" title="4.2.6.  删除多行数据"></a>4.2.6.  删除多行数据</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">deleteMultiRow</span><span class="hljs-params">(String tableName, String... rows)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>    HTable hTable = <span class="hljs-keyword">new</span> HTable(conf, tableName);<br>    List&lt;Delete&gt; deleteList = <span class="hljs-keyword">new</span> ArrayList&lt;Delete&gt;();<br>    <span class="hljs-keyword">for</span> (String row : rows) &#123;<br>        Delete delete = <span class="hljs-keyword">new</span> Delete(Bytes.toBytes(row));<br>        deleteList.add(delete);<br>    &#125;<br>    hTable.delete(deleteList);<br>    hTable.close();<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-2-7-获取所有数据"><a href="#4-2-7-获取所有数据" class="headerlink" title="4.2.7.  获取所有数据"></a>4.2.7.  获取所有数据</h3><p>全表扫描用scan</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">getAllRows</span><span class="hljs-params">(String tableName)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>    HTable hTable = <span class="hljs-keyword">new</span> HTable(conf, tableName);<br>    <span class="hljs-comment">//得到用于扫描 region 的对象</span><br>    Scan scan = <span class="hljs-keyword">new</span> Scan();<br>    <span class="hljs-comment">//使用 HTable 得到 resultcanner 实现类的对象</span><br>    ResultScanner resultScanner = hTable.getScanner(scan);<br>    <span class="hljs-keyword">for</span> (Result result : resultScanner) &#123;<br>        <span class="hljs-keyword">for</span> (Cell cell : result.rawCells()) &#123;<br>            System.out.println(<span class="hljs-string">&quot; 行 键 :&quot;</span> + Bytes.toString(CellUtil.cloneRow(cell)));<br>            System.out.println(<span class="hljs-string">&quot; 列 族 &quot;</span> + Bytes.toString(CellUtil.cloneFamily(cell)));<br>            System.out.println(<span class="hljs-string">&quot; 列 :&quot;</span> + Bytes.toString(CellUtil.cloneQualifier(cell)));<br>            System.out.println(<span class="hljs-string">&quot; 值 :&quot;</span> + Bytes.toString(CellUtil.cloneValue(cell)));<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-2-8-获取某一行数据"><a href="#4-2-8-获取某一行数据" class="headerlink" title="4.2.8.  获取某一行数据"></a>4.2.8.  获取某一行数据</h3><p>指定查看用get</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">getRow</span><span class="hljs-params">(String tableName, String rowKey)</span> <span class="hljs-keyword">throws</span></span><br><span class="hljs-function">        IOException</span>&#123;<br>    HTable hTable = <span class="hljs-keyword">new</span> HTable(conf, tableName);<br>    Get get = <span class="hljs-keyword">new</span> Get(Bytes.toBytes(rowKey));<br>    <span class="hljs-comment">//get.setMaxVersions();显示所有版本</span><br>    <span class="hljs-comment">//get.setTimeStamp();显示指定时间戳的版本</span><br>    Result result = hTable.get(get);<br>    <span class="hljs-keyword">for</span>(Cell cell : result.rawCells())&#123;<br>        System.out.println(<span class="hljs-string">&quot; 行 键 :&quot;</span>  + Bytes.toString(result.getRow()));<br>        System.out.println(<span class="hljs-string">&quot; 列 族 &quot;</span>  + Bytes.toString(CellUtil.cloneFamily(cell)));<br>        System.out.println(<span class="hljs-string">&quot; 列 :&quot;</span>  + Bytes.toString(CellUtil.cloneQualifier(cell)));<br>        System.out.println(<span class="hljs-string">&quot; 值 :&quot;</span>  + Bytes.toString(CellUtil.cloneValue(cell)));<br>        System.out.println(<span class="hljs-string">&quot;时间戳:&quot;</span> + cell.getTimestamp());<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-2-9-获取某一行某一列数据"><a href="#4-2-9-获取某一行某一列数据" class="headerlink" title="4.2.9.  获取某一行某一列数据"></a>4.2.9.  获取某一行某一列数据</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">getRowQualifier</span><span class="hljs-params">(String tableName, String rowKey, String family, String qualifier)</span> <span class="hljs-keyword">throws</span> IOException</span>&#123;<br>    HTable table = <span class="hljs-keyword">new</span> HTable(conf, tableName);<br>    Get get = <span class="hljs-keyword">new</span> Get(Bytes.toBytes(rowKey));<br>    get.addColumn(Bytes.toBytes(family), Bytes.toBytes(qualifier));<br>    Result result = table.get(get);<br>    <span class="hljs-keyword">for</span>(Cell cell : result.rawCells())&#123;<br>        System.out.println(<span class="hljs-string">&quot; 行 键 :&quot;</span>  + Bytes.toString(result.getRow()));<br>        System.out.println(<span class="hljs-string">&quot; 列 族 &quot;</span>  + Bytes.toString(CellUtil.cloneFamily(cell)));<br>        System.out.println(<span class="hljs-string">&quot; 列 :&quot;</span>  + Bytes.toString(CellUtil.cloneQualifier(cell)));<br>        System.out.println(<span class="hljs-string">&quot; 值 :&quot;</span>  + Bytes.toString(CellUtil.cloneValue(cell)));<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h1 id="05-HBase-优化"><a href="#05-HBase-优化" class="headerlink" title="05. HBase 优化"></a>05. HBase 优化</h1><h2 id="5-1-高可用"><a href="#5-1-高可用" class="headerlink" title="5.1. 高可用"></a>5.1. 高可用</h2><p>在 HBase 中 HMaster 负责监控 HRegionServer 的生命周期，均衡 RegionServer 的负载，如果 HMaster 挂掉了，那么整个 HBase 集群将陷入不健康的状态，并且此时的工作状态并不会维持太久。所以 <font color='cornflowerblue'>HBase 支持对 HMaster 的高可用配置。</font>配置如下：</p><blockquote><p>1．关闭 HBase 集群（如果没有开启则跳过此步）<br>bin/stop-hbase.sh<br>2．在 conf 目录下创建 backup-masters 文件<br>touch conf/backup-masters<br>3．在 backup-masters 文件中配置高可用 HMaster 节点<br>echo hadoop103 &gt; conf/backup-masters<br>4．将整个 conf 目录 scp 到其他节点<br>scp  -r  conf/hadoop103:/opt/module/hbase/<br>scp  -r  conf/hadoop104:/opt/module/hbase/<br>5．打开页面测试查看</p></blockquote><h2 id="5-2-预分区"><a href="#5-2-预分区" class="headerlink" title="5.2. 预分区"></a>5.2. 预分区</h2><h2 id="5-3-rowkey的设计"><a href="#5-3-rowkey的设计" class="headerlink" title="5.3. rowkey的设计"></a>5.3. rowkey的设计</h2><h1 id="06-HBase实战之微博"><a href="#06-HBase实战之微博" class="headerlink" title="06. HBase实战之微博"></a>06. HBase实战之微博</h1><h2 id="6-1-需求分析"><a href="#6-1-需求分析" class="headerlink" title="6.1. 需求分析"></a>6.1. 需求分析</h2><ol><li>微博用户的内容浏览，数据库表设计</li><li>用户社交体现：关注用户，取关用户【粉丝数和关注列表】</li><li>拉取关注的人的微博内容【打开界面的初始化界面】</li></ol><h2 id="6-2-代码实现"><a href="#6-2-代码实现" class="headerlink" title="6.2. 代码实现"></a>6.2. 代码实现</h2><p>6.2.1. 代码结构</p><ul><li>创建命名空间。</li><li>创建表：分别是内容表【不同用户所发的微博】，用户关系表【粉丝关注列表】以及微博内容接收邮件表【每次打开界面拉去关注人的微博】</li><li>发送微博【将微博信息保存在内容表】</li><li>关注用户【需要影响用户的关注数和另个用户的分析，影响用户关系表】</li><li>移除用户【取关，同上】</li><li>拉取微博内容【通过微博内容接收邮件表展示微博】</li></ul>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>learn</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kafka</title>
    <link href="/2022/01/29/Kafka/"/>
    <url>/2022/01/29/Kafka/</url>
    
    <content type="html"><![CDATA[<h2 id="01-Kafka官方资料"><a href="#01-Kafka官方资料" class="headerlink" title="01. Kafka官方资料"></a>01. Kafka官方资料</h2><p><a href="https://kafka.apache.org/">官网文档</a></p><p><a href="https://kafka.apachecn.org/">中文文档</a></p><h2 id="02-Kafka定义"><a href="#02-Kafka定义" class="headerlink" title="02. Kafka定义"></a>02. Kafka定义</h2><p>Kafka 是一个<strong>分布式</strong>的基于<strong>发布/订阅模式</strong>的<strong>消息队列</strong>（Message Queue），主要应用于大数据实时处理领域。</p><h2 id="03-Kafka消息队列"><a href="#03-Kafka消息队列" class="headerlink" title="03. Kafka消息队列"></a>03. Kafka消息队列</h2><h3 id="3-1-传统消息队列的应用场景"><a href="#3-1-传统消息队列的应用场景" class="headerlink" title="3.1. 传统消息队列的应用场景"></a>3.1. 传统消息队列的应用场景</h3><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/mq.webp" alt="mq" style="zoom:80%;" /><h3 id="3-2-使用消息队列的好处"><a href="#3-2-使用消息队列的好处" class="headerlink" title="3.2. 使用消息队列的好处"></a>3.2. 使用消息队列的好处</h3><ol><li><p>解耦</p><p>（类似Spring的IOC）</p><ul><li>允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</li></ul></li><li><p>可恢复性</p><ul><li>系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。</li></ul></li><li><p>缓冲</p><ul><li>有助于控制和优化数据流经过系统的速度， 解决生产消息和消费消息的处理速度不一致的情况。</li></ul></li><li><p>灵活性 &amp; 峰值处理能力（削峰）</p><ul><li>在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。</li></ul></li><li><p>异步通信</p><ul><li>很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</li></ul></li></ol><h3 id="3-4-消息队列的两种模式"><a href="#3-4-消息队列的两种模式" class="headerlink" title="3.4. 消息队列的两种模式"></a>3.4. 消息队列的两种模式</h3><p><strong>(1)点对点模式</strong></p><p>一对一，消费者主动拉取数据，消息收到后消息清除</p><p>消息生产者生产消息发送到Queue中，然后消息消费者从Queue中取出并且消费消息。消息被消费以后， queue 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。Queue 支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。</p><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.1nh4690c74bk.webp" alt="image"></p><p><strong>(2) 发布/订阅模式</strong></p><p>一对多，消费者消费数据之后不会清除消息</p><p>消息生产者（发布）将消息发布到 topic 中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。</p><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.1u3w2y4jppcw.webp" alt="image"></p><h2 id="04-Kafka-基础架构"><a href="#04-Kafka-基础架构" class="headerlink" title="04. Kafka_基础架构"></a>04. Kafka_基础架构</h2><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.26axx1c41wtc.webp" alt="image"></p><ol><li><strong>Producer</strong> ： 消息生产者，就是向 Kafka ；</li><li><strong>Consumer</strong> ： 消息消费者，向 Kafka broker 取消息的客户端；</li><li><strong>Consumer Group （CG）</strong>： 消费者组，由多个 consumer 组成。 消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。 所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li><li><strong>Broker</strong> ：经纪人 一台 Kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker可以容纳多个 topic。</li><li><strong>Topic</strong> ： 话题，可以理解为一个队列， 生产者和消费者面向的都是一个 topic；</li><li><strong>Partition</strong>： 为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列；</li><li><strong>Replica</strong>： 副本（Replication），为保证集群中的某个节点发生故障时， 该节点上的 partition 数据不丢失，且 Kafka仍然能够继续工作， Kafka 提供了副本机制，一个 topic 的每个分区都有若干个副本，一个 leader 和若干个 follower。</li><li><strong>Leader</strong>： 每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 leader。</li><li><strong>Follower</strong>： 每个分区多个副本中的“从”，实时从 leader 中同步数据，保持和 leader 数据的同步。 leader 发生故障时，某个 Follower 会成为新的 leader。</li></ol><h2 id="05-Kafka-快速入门"><a href="#05-Kafka-快速入门" class="headerlink" title="05. Kafka_快速入门"></a>05. Kafka_快速入门</h2><h3 id="5-1-Quick-Start"><a href="#5-1-Quick-Start" class="headerlink" title="5.1. Quick Start"></a>5.1. Quick Start</h3><p>​    本次安装学习在Windows操作系统进行。（Linux版本的差别不大，运行脚本文件后缀从<code>bat</code>改为<code>sh</code>，配置路径改用Unix风格的）</p><ul><li><p>Step 1: Download the code</p><p><a href="https://kafka.apache.org/downloads">下载代码</a>并解压</p><p>解压到D:\Kafka`路径下，Kafka主目录文件为D:\Kafka\kafka_xxx`（下文的路径均用这个路径的相对路径表示）。</p></li><li><p>Step 2: Start the server</p><p>​    Kafka 用到 ZooKeeper 功能，所以要预先运行ZooKeeper,再启动kafka。</p><ul><li><p>修改zookeeper日志文件的位置，创建新目录<code>D:\Kafka\zk-data</code></p></li><li><p>修改<code>\conf\zookeeper.properties</code>，将<code>dataDir=/tmp/zookeeper</code>改为<code>dataDir=D:\Kafka\zk-data</code>。</p></li><li><p>在 <code>D:\Kafka\kafka_xxx</code>路径的上方输入cmd，进入命令窗口，启动zookeeper</p><blockquote><p>start bin\windows\zookeeper-server-start.bat config\zookeeper.properties</p></blockquote></li><li><p>修改kafka日志文件的位置，创建新目录``D:\Kafka\kafka-logs`</p></li><li><p>修改<code>\conf\server.properties</code>，将<code>log.dirs=/tmp/kafka-logs</code>改为<code>log.dirs=D:\Kafka\kafka-logs</code>。</p></li><li><p>在 <code>D:\Kafka\kafka_xxx</code>路径的上方输入cmd，进入命令窗口，启动kafka：</p><blockquote><p>start bin\windows\kafka-server-start.bat config\server.properties</p></blockquote></li><li><p>关闭服务，<code>bin\windows\kafka-server-stop.bat</code>和<code>bin\windows\zookeeper-server-stop.bat</code>。</p></li></ul></li><li><p>Step 3: Create a topic</p><ul><li>用单一partition和单一replica创建一个名为<code>test</code>的topic:</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">bin \windows\kafka-topics.bat --create --zookeeper localhost:<span class="hljs-number">2181</span> --replication-factor <span class="hljs-number">1</span> --partitions <span class="hljs-number">1</span> --topic test<br></code></pre></td></tr></table></figure><ul><li>查看已创建的topic，也就刚才创建的名为<code>test</code>的topic：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">bin \windows\kafka-topics.bat --list --zookeeper localhost:<span class="hljs-number">2181</span><br></code></pre></td></tr></table></figure></li><li><p>Step 4: Start a producer</p><p>运行producer，并指定主题。然后输入几行文本，发至服务器：</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs applescript">bin\windows\kafka-console-producer.bat <span class="hljs-comment">--broker-list localhost:9092 --topic test</span><br>&gt;hello, kafka.<br>&gt;what a nice <span class="hljs-built_in">day</span>!<br>&gt;<span class="hljs-keyword">to</span> be <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">to</span> be. <span class="hljs-keyword">that</span>&#x27; s a question.<br></code></pre></td></tr></table></figure></li><li><p>Step 5: Start a consumer</p><p>运行consumer，指定消费者将要消费的topic。会发现消费者窗口将Step 4中输入的几行句子，标准输出。</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-keyword">bin\windows\kafka-console-consumer.bat </span>--<span class="hljs-keyword">bootstrap-server </span>localhost:<span class="hljs-number">9092</span> --topic test --from-<span class="hljs-keyword">beginning</span><br><span class="hljs-keyword"></span>hello, kafka.<br>what a nice day!<br>to <span class="hljs-keyword">be </span><span class="hljs-keyword">or </span>not to <span class="hljs-keyword">be. </span>that<span class="hljs-string">&#x27; s a question.</span><br></code></pre></td></tr></table></figure><p>若你另启cmd，执行命令行<code>bin\windows\kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic test --from-beginning</code>来运行consumer，然后在<a href="https://gitee.com/jallenkwong/LearnKafka#">Step 4</a>中producer窗口输入一行句子，如<code>I must admit, I can&#39;t help but feel a twinge of envy.</code>，两个consumer也会同时输出<code>I must admit, I can&#39;t help but feel a twinge of envy.</code>。</p></li><li><p>Step 6: Setting up a multi-broker cluster</p><p>​    如果需要多增加节点，则需要复制配置文件并进行修改。</p><ul><li><p>首先，在<code>%KAFKA%\config\server.properties</code>的基础上创建两个副本<code>server-1.properties</code>和<code>server-2.properties</code>。</p><p>​    copy config\server.properties   config\server-1.properties </p><p>​    copy config\server.properties   config\server-2.properties</p></li><li><p>打开新复制生成的两个副本，编辑如下属性</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs routeros">config/server-1.properties:<br>    broker.<span class="hljs-attribute">id</span>=1<br>    <span class="hljs-attribute">listeners</span>=PLAINTEXT://127.0.0.1:9093<br>    log.<span class="hljs-attribute">dir</span>=D:\Kafka\kafka-logs-1<br> <br>config/server-2.properties:<br>    broker.<span class="hljs-attribute">id</span>=2<br>    <span class="hljs-attribute">listeners</span>=PLAINTEXT://127.0.0.1:9094<br>    log.<span class="hljs-attribute">dir</span>=D:\Kafka\kafka-logs-2<br></code></pre></td></tr></table></figure><p>注意对于不同节点，<code>broker.id </code>的设置不能相同。这个<code>broker.id</code>属性是集群中每个节点的唯一永久的名称。</p><p>同时，我们必须重写端口和日志目录，只是因为我们在同一台机器上运行它们，并且我们希望阻止brokers试图在同一个端口上注册或覆盖彼此的数据。</p></li><li><p>目前已经启动了Zookeeper和单个kafka节点，配置结束后，启动两个新节点：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">start</span> bin\windows\kafka-<span class="hljs-keyword">server</span>-<span class="hljs-keyword">start</span>.bat config\<span class="hljs-keyword">server</span><span class="hljs-number">-1.</span>properties <br><span class="hljs-keyword">start</span> bin\windows\kafka-<span class="hljs-keyword">server</span>-<span class="hljs-keyword">start</span>.bat config\<span class="hljs-keyword">server</span><span class="hljs-number">-2.</span>properties<br></code></pre></td></tr></table></figure></li><li><p>创建一个replication-factor为3的topic，名为<code>my-replicated-topic</code></p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">bin\windows\kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">topics</span><span class="hljs-string">.</span><span class="hljs-comment">bat</span> --<span class="hljs-comment">create</span> --<span class="hljs-comment">zookeeper</span> <span class="hljs-comment">localhost:2181</span> --<span class="hljs-comment">replication</span><span class="hljs-literal">-</span><span class="hljs-comment">factor</span> <span class="hljs-comment">3</span> --<span class="hljs-comment">partitions</span> <span class="hljs-comment">1</span> --<span class="hljs-comment">topic</span> <span class="hljs-comment">my</span><span class="hljs-literal">-</span><span class="hljs-comment">replicated</span><span class="hljs-literal">-</span><span class="hljs-comment">topic</span><br></code></pre></td></tr></table></figure></li><li><p>OK，现在我们有了一个集群，但是我们怎么知道哪个broker在做什么呢？那就运行<code>describe topics</code>命令：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">bin</span>\windows\kafka-topics.bat --describe --zookeeper localhost:<span class="hljs-number">2181</span> --topic my-replicated-topic<br><br><span class="hljs-attribute">Topic</span>:my-replicated-topic PartitionCount:<span class="hljs-number">1</span> ReplicationFactor:<span class="hljs-number">3</span> Configs: Topic: my-replicated-topic Partition: <span class="hljs-number">0</span> Leader: <span class="hljs-number">0</span><br><span class="hljs-attribute">Replicas</span>: <span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span> Isr: <span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><ul><li>“leader”是负责给定Partition的所有读写的节点。每个节点都可能成为Partition随机选择的leader。</li><li>“replicas”是复制此Partition日志的节点列表，无论它们是leader还是当前处于存活状态。</li><li>“isr”是一组 “in-sync” replicas。这是replicas列表的一个子集，它当前处于存活状态，并补充leader。</li></ul><p>注意，<strong>在我的示例中，node 0是Topic唯一Partition的leader</strong>。（下面操作需要用到）</p></li><li><p>通过生产者向<code>my-replicated-topic</code>这个主题发布一些信息：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">bin\windows\kafka-console-producer.bat <span class="hljs-comment">--broker-list localhost:9092 --topic my-replicated-topic</span><br><br>Ther<span class="hljs-string">e&#x27;s sadness in your eyes, I don&#x27;</span>t want <span class="hljs-keyword">to</span> say goodbye <span class="hljs-keyword">to</span> you. Love <span class="hljs-keyword">is</span> a big illusion, I should try <span class="hljs-keyword">to</span> forget, but ther<span class="hljs-string">e&#x27;s something left in m y head.</span><br></code></pre></td></tr></table></figure></li><li><p>通过消费者消费消息</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">bin\windows\kafka-console-consumer.bat <span class="hljs-comment">--bootstrap-server localhost:9092 --from-beginning --topic my-replicated-topic</span><br><br>Ther<span class="hljs-string">e&#x27;s sadness in your eyes, I don&#x27;</span>t want <span class="hljs-keyword">to</span> say goodbye <span class="hljs-keyword">to</span> you. Love <span class="hljs-keyword">is</span> a big illusion, I should try <span class="hljs-keyword">to</span> forget, but ther<span class="hljs-string">e&#x27;s something left in my head.</span><br></code></pre></td></tr></table></figure><p>如果当前某个partition的leader挂掉过后，将会发生什么呢？</p><ul><li><p>先找出 Broker 0 的进程pid。</p><blockquote><p>wmic process where “caption=’java.exe’ and commandline like ‘%server.properties%’” get processid,caption Caption ProcessId java.exe 7528</p></blockquote></li><li><p>杀掉 Broker 0 的进程。</p><blockquote><p>taskkill /pid 7528 /f 成功: 已终止 PID 为 7528 的进程。</p></blockquote></li></ul></li><li><p>通过<code>describe Topic</code>命令查看当前主题的信息</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">bin</span>\windows\kafka-topics.bat --describe --zookeeper localhost:<span class="hljs-number">2181</span> --topic my-replicated-topic<br><br><span class="hljs-attribute">Topic</span>:my-replicated-topic PartitionCount:<span class="hljs-number">1</span> ReplicationFactor:<span class="hljs-number">3</span> Configs: Topic: my-replicated-topic Partition: <span class="hljs-number">0</span> Leader: <span class="hljs-number">1</span> <br><span class="hljs-attribute">Replicas</span>: <span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span> Isr: <span class="hljs-number">1</span>,<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><p>可以发现原leader为node1，目前已被替换成它的ISR中的其中一个，并且 node 0 不在 in-sync replica 集合当中。</p></li><li><p>尽管原leader已逝，但原来消息依然可以接收。（注意，参数<code>--bootstrap-server localhost:9093</code>，而不是<code>--bootstrap-server localhost:9092</code>）</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">bin\windows\kafka-console-consumer.bat <span class="hljs-comment">--bootstrap-server localhost:9093 --from-beginning --topic my-replicated-topic</span><br><br>Ther<span class="hljs-string">e&#x27;s sadness in your eyes, I don&#x27;</span>t want <span class="hljs-keyword">to</span> say goodbye <span class="hljs-keyword">to</span> you. Love <span class="hljs-keyword">is</span> a big illusion, I should try <span class="hljs-keyword">to</span> forget, but ther<span class="hljs-string">e&#x27;s something left in my head. I don&#x27;</span>t forget the way your kissing, the feeling <span class="hljs-string">&#x27;s so strong which is lasting for so long.</span><br></code></pre></td></tr></table></figure></li></ul></li></ul><h3 id="5-2-配置文件server-properties"><a href="#5-2-配置文件server-properties" class="headerlink" title="5.2. 配置文件server.properties"></a>5.2. 配置文件server.properties</h3><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-comment">#broker 的全局唯一编号，不能重复</span><br><span class="hljs-attr">broker.id</span>=<span class="hljs-number">0</span><br><span class="hljs-comment">#删除 topic 功能使能</span><br><span class="hljs-attr">delete.topic.enable</span>=<span class="hljs-literal">true</span><br><span class="hljs-comment">#处理网络请求的线程数量</span><br><span class="hljs-attr">num.network.threads</span>=<span class="hljs-number">3</span><br><span class="hljs-comment">#用来处理磁盘 IO 的现成数量</span><br><span class="hljs-attr">num.io.threads</span>=<span class="hljs-number">8</span><br><span class="hljs-comment">#发送套接字的缓冲区大小</span><br><span class="hljs-attr">socket.send.buffer.bytes</span>=<span class="hljs-number">102400</span><br><span class="hljs-comment">#接收套接字的缓冲区大小</span><br><span class="hljs-attr">socket.receive.buffer.bytes</span>=<span class="hljs-number">102400</span><br><span class="hljs-comment">#请求套接字的缓冲区大小</span><br><span class="hljs-attr">socket.request.max.bytes</span>=<span class="hljs-number">104857600</span><br><span class="hljs-comment">#kafka 运行日志存放的路径</span><br><span class="hljs-attr">log.dirs</span>=/opt/module/kafka/logs<br><span class="hljs-comment">#topic 在当前 broker 上的分区个数</span><br><span class="hljs-attr">num.partitions</span>=<span class="hljs-number">1</span><br><span class="hljs-comment">#用来恢复和清理 data 下数据的线程数量</span><br><span class="hljs-attr">num.recovery.threads.per.data.dir</span>=<span class="hljs-number">1</span><br><span class="hljs-comment">#segment 文件保留的最长时间，超时将被删除</span><br><span class="hljs-attr">log.retention.hours</span>=<span class="hljs-number">168</span><br><span class="hljs-comment">#配置连接 Zookeeper 集群地址</span><br><span class="hljs-attr">zookeeper.connect</span>=hadoop102:<span class="hljs-number">2181</span>,hadoop103:<span class="hljs-number">2181</span>,hadoop104:<span class="hljs-number">2181</span><br></code></pre></td></tr></table></figure><h2 id="06-命令行操作Topic增删查"><a href="#06-命令行操作Topic增删查" class="headerlink" title="06. 命令行操作Topic增删查"></a>06. 命令行操作Topic增删查</h2><p>所有命令均为<font color='red'>kafka-topics.bat</font></p><h3 id="6-1-查看-topic列表"><a href="#6-1-查看-topic列表" class="headerlink" title="6.1. 查看 topic列表"></a>6.1. 查看 topic列表</h3><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">bin\windows\kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">topics</span><span class="hljs-string">.</span><span class="hljs-comment">bat</span> --<span class="hljs-comment">list</span> --<span class="hljs-comment">zookeeper</span> <span class="hljs-comment">localhost:2181</span><br></code></pre></td></tr></table></figure><h3 id="6-2-创建-topic"><a href="#6-2-创建-topic" class="headerlink" title="6.2. 创建 topic"></a>6.2. 创建 topic</h3><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">bin\windows\kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">topics</span><span class="hljs-string">.</span><span class="hljs-comment">bat</span> --<span class="hljs-comment">create</span> --<span class="hljs-comment">zookeeper</span> <span class="hljs-comment">localhost:2181</span> --<span class="hljs-comment">replication</span><span class="hljs-literal">-</span><span class="hljs-comment">factor</span> <span class="hljs-comment">3</span> --<span class="hljs-comment">partitions</span> <span class="hljs-comment">1</span> --<span class="hljs-comment">topic</span> <span class="hljs-comment">my</span><span class="hljs-literal">-</span><span class="hljs-comment">replicated</span><span class="hljs-literal">-</span><span class="hljs-comment">topic</span><br></code></pre></td></tr></table></figure><p>选项说明：</p><ul><li>–topic 定义 topic 名</li><li>–replication-factor 定义副本数</li><li>–partitions 定义分区数</li></ul><blockquote><p>为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列；</p><p>a broker = a kafka server a broker can contain N topic a topic can contain N partition a broker can contain a part of a topic (a broker can contain M(N&gt;M) partition)</p></blockquote><h3 id="6-3-删除-topic"><a href="#6-3-删除-topic" class="headerlink" title="6.3. 删除 topic"></a>6.3. 删除 topic</h3><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">bin\windows\kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">topics</span><span class="hljs-string">.</span><span class="hljs-comment">bat</span> --<span class="hljs-comment">zookeeper</span> <span class="hljs-comment">localhost:2181</span> --<span class="hljs-comment">delete</span> --<span class="hljs-comment">topic</span> <span class="hljs-comment">my</span><span class="hljs-literal">-</span><span class="hljs-comment">replicated</span><span class="hljs-literal">-</span><span class="hljs-comment">topic</span><br></code></pre></td></tr></table></figure><p>需要 server.properties 中设置 <code>delete.topic.enable=true</code> 否则只是标记删除。</p><h3 id="6-4-查看-topic-详情"><a href="#6-4-查看-topic-详情" class="headerlink" title="6.4. 查看 topic 详情"></a>6.4. 查看 topic 详情</h3><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">bin\windows\kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">topics</span><span class="hljs-string">.</span><span class="hljs-comment">bat</span> --<span class="hljs-comment">zookeeper</span> <span class="hljs-comment">localhost:2181</span> --<span class="hljs-comment">describe</span> --<span class="hljs-comment">topic</span> <span class="hljs-comment">first</span><br></code></pre></td></tr></table></figure><h3 id="6-5-修改分区数"><a href="#6-5-修改分区数" class="headerlink" title="6.5. 修改分区数"></a>6.5. 修改分区数</h3><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">bin\windows\kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">topics</span><span class="hljs-string">.</span><span class="hljs-comment">bat</span> --<span class="hljs-comment">zookeeper</span> <span class="hljs-comment">localhost:2181</span> --<span class="hljs-comment">alter</span> --<span class="hljs-comment">topic</span> <span class="hljs-comment">first</span> --<span class="hljs-comment">partitions</span> <span class="hljs-comment">6</span><br></code></pre></td></tr></table></figure><h2 id="07-命令行操作生产者消费者测试"><a href="#07-命令行操作生产者消费者测试" class="headerlink" title="07. 命令行操作生产者消费者测试"></a>07. 命令行操作生产者消费者测试</h2><h3 id="7-1-发送消息"><a href="#7-1-发送消息" class="headerlink" title="7.1. 发送消息"></a>7.1. 发送消息</h3><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs applescript">bin\windows\kafka-console-producer.bat <span class="hljs-comment">--broker-list localhost:9092 --topic test</span><br><br>&gt;hello, kafka.<br>&gt;what a nice <span class="hljs-built_in">day</span>!<br>&gt;<span class="hljs-keyword">to</span> be <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">to</span> be. <span class="hljs-keyword">that</span>&#x27; s a question.<br></code></pre></td></tr></table></figure><h3 id="7-2-消费消息"><a href="#7-2-消费消息" class="headerlink" title="7.2. 消费消息"></a>7.2. 消费消息</h3><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-keyword">bin\windows\kafka-console-consumer.bat </span>--<span class="hljs-keyword">bootstrap-server </span>localhost:<span class="hljs-number">9092</span> --topic test --from-<span class="hljs-keyword">beginning</span><br><span class="hljs-keyword"></span><br>hello, kafka.<br>what a nice day!<br>to <span class="hljs-keyword">be </span><span class="hljs-keyword">or </span>not to <span class="hljs-keyword">be. </span>that<span class="hljs-string">&#x27; s a question.</span><br></code></pre></td></tr></table></figure><ul><li>–from-beginning： 会把主题中以往所有的数据都读取出来。</li></ul><h2 id="08-Kafka工作流程"><a href="#08-Kafka工作流程" class="headerlink" title="08. Kafka工作流程"></a>08. Kafka工作流程</h2><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Kafka/image.41y5jgtywlw0.webp" alt="image" style="zoom:80%;" /><p>Kafka 中消息是以 topic 进行分类的， producer生产消息，consumer消费消息，都是面向 topic的。(从命令行操作看出)</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">bin\windows\kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">console</span><span class="hljs-literal">-</span><span class="hljs-comment">producer</span><span class="hljs-string">.</span><span class="hljs-comment">bat</span> --<span class="hljs-comment">broker</span><span class="hljs-literal">-</span><span class="hljs-comment">list</span> <span class="hljs-comment">localhost:9092</span> --<span class="hljs-comment">topic</span> <span class="hljs-comment">test</span><br><br><span class="hljs-comment">bin\windows\kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">console</span><span class="hljs-literal">-</span><span class="hljs-comment">consumer</span><span class="hljs-string">.</span><span class="hljs-comment">bat</span> --<span class="hljs-comment">bootstrap</span><span class="hljs-literal">-</span><span class="hljs-comment">server</span> <span class="hljs-comment">localhost:9092</span> --<span class="hljs-comment">topic</span> <span class="hljs-comment">test</span> --<span class="hljs-comment">from</span><span class="hljs-literal">-</span><span class="hljs-comment">beginning</span><br></code></pre></td></tr></table></figure><p>topic 是逻辑上的概念，而 partition 是物理上的概念，<font color='cornflowerblue'>每个 partition 对应于一个 log 文件</font>，该 log 文件中存储的就是 producer 生产的数据。（topic = N partition，partition = log）</p><p>Producer 生产的数据会被不断追加到该log 文件末端，且每条数据都有自己的 offset。 consumer组中的每个consumer， 都会实时记录自己消费到了哪个 offset，以便出错恢复时，从上次的位置继续消费。（producer -&gt; log with offset -&gt; consumer(s)）</p><h2 id="09-Kafka文件存储"><a href="#09-Kafka文件存储" class="headerlink" title="09. Kafka文件存储"></a>09. Kafka文件存储</h2><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.5ey1dcq56dc0.webp" alt="image" style="zoom:80%;" /><p>由于生产者生产的消息会不断追加到 log 文件末尾， 为防止 log 文件过大导致数据定位效率低下， Kafka 采取了**<font color='red'>分片</font><strong>&lt;/和**<font color='red'>索引</font></strong>&lt;/机制，将每个 partition 分为多个 segment。</p><p>每个 segment对应两个文件——“.index”文件和“.log”文件。 这些文件位于一个文件夹下， 该文件夹的命名规则为： topic 名称+分区序号。例如， first 这个 topic 有三个分区，则其对应的文件夹为 first-0,first-1,first-2。</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-number">00000000000000000000</span>.<span class="hljs-built_in">index</span><br><span class="hljs-number">00000000000000000000</span>.<span class="hljs-built_in">log</span><br><span class="hljs-number">00000000000000170410</span>.<span class="hljs-built_in">index</span><br><span class="hljs-number">00000000000000170410</span>.<span class="hljs-built_in">log</span><br><span class="hljs-number">00000000000000239430</span>.<span class="hljs-built_in">index</span><br><span class="hljs-number">00000000000000239430</span>.<span class="hljs-built_in">log</span><br></code></pre></td></tr></table></figure><p>index 和 log 文件以当前 segment 的第一条消息的 offset 命名。下图为 index 文件和 log文件的结构示意图。</p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.5byijxzb8ak0.webp" alt="image" style="zoom:80%;" /><p><strong>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据</strong>，索引文件中的元数据指向对应数据文件中 message 的物理偏移地址。</p><blockquote><p>segment 英 [ˈseɡmənt , seɡˈment] 美 [ˈseɡmənt , seɡˈment]<br>n.部分;份;片;段;(柑橘、柠檬等的)瓣;弓形;圆缺 v.分割;划分</p></blockquote><h2 id="10-Kskafa生产者"><a href="#10-Kskafa生产者" class="headerlink" title="10. Kskafa生产者"></a>10. Kskafa生产者</h2><h3 id="10-1-Kafka生产者分区策略"><a href="#10-1-Kafka生产者分区策略" class="headerlink" title="10.1. Kafka生产者分区策略"></a>10.1. Kafka生产者分区策略</h3><ul><li><p>分区的原因</p><ul><li><p><strong>方便在集群中扩展</strong>，每个 Partition 可以通过调整以适应它所在的机器，而一个 topic又可以有多个 Partition 组成，因此整个集群就可以适应适合的数据了；</p></li><li><p><strong>可以提高并发</strong>，因为可以以 Partition 为单位读写了。（联想到ConcurrentHashMap在高并发环境下读写效率比HashTable的高效）</p></li></ul></li><li><p>分区的原则</p><p>我们需要将 producer 发送的数据封装成一个 <code>ProducerRecord</code> 对象。</p><ul><li>指明 partition 的情况下，直接将指明的值直接作为 partiton 值；</li><li>没有指明 partition 值但有 key 的情况下，将 key 的 hash 值与 topic 的 partition 数进行取余得到 partition 值；</li><li>既没有 partition 值又没有 key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition值，也就是常说的 round-robin 算法。</li></ul></li></ul><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.1deyr36fol4w.webp" alt="image"></p><h3 id="10-2-Kafka可靠性保证"><a href="#10-2-Kafka可靠性保证" class="headerlink" title="10.2. Kafka可靠性保证"></a>10.2. Kafka可靠性保证</h3><p>为保证 producer 发送的数据，能可靠的发送到指定的 topic， topic 的每个 partition 收到producer 发送的数据后，都需要向 producer 发送 ack（acknowledgement 确认收到），如果producer 收到 ack， 就会进行下一轮的发送，否则重新发送数据。</p><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.3tl8xan6qzy0.webp" alt="image"></p><p><strong>何时发送ack？</strong></p><p>确保有follower与leader同步完成，leader再发送ack，这样才能保证leader挂掉之后，能在follower中选举出新的leader。</p><hr><p><strong>多少个follower同步完成之后发送ack？</strong></p><ol><li>半数以上的follower同步完成，即可发送ack继续发送重新发送</li><li>全部的follower同步完成，才可以发送ack</li></ol><ul><li><strong>副本数据同步策略</strong></li></ul><table><thead><tr><th>序号</th><th>方案</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>1</td><td>半数以上完成同步， 就发送 ack</td><td>延迟低</td><td>选举新的 leader 时，容忍 n 台节点的故障，需要 2n+1 个副本。（如果集群有2n+1台机器，选举leader的时候至少需要半数以上即n+1台机器投票，那么能容忍的故障，最多就是n台机器发生故障）容错率：1/2</td></tr><tr><td>2</td><td>全部完成同步，才发送ack</td><td>选举新的 leader 时， 容忍 n 台节点的故障，需要 n+1 个副本（如果集群有n+1台机器，选举leader的时候只要有一个副本就可以了）容错率：1</td><td>延迟高</td></tr></tbody></table><p>Kafka 选择了第二种方案，原因如下：</p><ol><li>同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1 个副本，而 Kafka 的每个分区都有大量的数据， 第一种方案会造成大量数据的冗余。</li><li>虽然第二种方案的网络延迟会比较高，但网络延迟对 Kafka 的影响较小。</li></ol><ul><li><p><strong>ISR</strong></p><p>采用第二种方案之后，设想以下情景： leader 收到数据，所有 follower 都开始同步数据，但有一个 follower，因为某种故障，迟迟不能与 leader 进行同步，那 leader 就要一直等下去，直到它完成同步，才能发送 ack。这个问题怎么解决呢？</p><p>Leader 维护了一个动态的 <strong>in-sync replica set</strong> (ISR)，意为和 leader 保持同步的 follower 集合。当 ISR 中的 follower 完成数据的同步之后，就会给 leader 发送 ack。如果 follower长时间未向leader同步数据，则该follower将被踢出ISR，该时间阈值由<code>replica.lag.time.max.ms</code>参数设定。 Leader 发生故障之后，就会从 ISR 中选举新的 leader。</p><blockquote><p><strong>replica.lag.time.max.ms</strong></p><p><strong>DESCRIPTION</strong>: If a follower hasn’t sent any fetch requests or hasn’t consumed up to the leaders log end offset for at least this time, the leader will remove the follower from isr</p><p><strong>TYPE</strong>: long</p><p><strong>DEFAULT</strong>: 10000</p><p><a href="https://gitee.com/link?target=http://kafka.apache.org/0110/documentation/%23brokerconfigs">Source</a></p></blockquote></li></ul><ul><li><p><strong>ACk应答机制</strong></p><p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等 ISR 中的 follower 全部接收成功。所以 Kafka 为用户提供了三种可靠性级别，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。</p><p><strong>acks 参数配置</strong>：</p><p>(1)  ack=0</p><blockquote><p>producer 不等待 broker 的 ack，这一操作提供了一个最低的延迟， broker 一接收到还没有写入磁盘就已经返回，当 broker 故障时有可能<strong>丢失数据</strong>；</p></blockquote><p>(2)  ack = 1</p><blockquote><p>producer 等待 broker 的 ack， partition 的 leader 落盘成功后返回 ack，如果在 follower同步成功之前 leader 故障，那么将会<strong>丢失数据</strong>；</p></blockquote></li></ul><p>​    <img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.3gbp3y8bnck0.webp" alt="image"></p><p>​        (3)  ack = -1</p><blockquote><p>producer 等待 broker 的 ack， partition 的 leader 和 ISR 的follower 全部落盘成功后才返回 ack。但是如果在 follower 同步完成后， broker 发送 ack 之前， leader 发生故障，那么会造成<strong>数据重复</strong>。</p></blockquote><p>​    <img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.2c5ghtqsve3o.webp" alt="image"></p><p>​    <strong>助记：返ACK前，0无落盘，1一落盘，-1全落盘，（落盘：消息存到本地）</strong></p><blockquote><p><strong>acks</strong></p><p><strong>DESCRIPTION</strong>:</p><p>The number of acknowledgments the producer requires the leader to have received before considering a request complete. This controls the durability of records that are sent. The following settings are allowed:</p><ul><li><code>acks=0</code> If set to zero then the producer will not wait for any acknowledgment from the server at all. The record will be immediately added to the socket buffer and considered sent. No guarantee can be made that the server has received the record in this case, and the retries configuration will not take effect (as the client won’t generally know of any failures). The offset given back for each record will always be set to -1.</li><li><code>acks=1</code> This will mean the leader will write the record to its local log but will respond without awaiting full acknowledgement from all followers. In this case should the leader fail immediately after acknowledging the record but before the followers have replicated it then the record will be lost.</li><li><code>acks=all</code> This means the leader will wait for the full set of in-sync replicas to acknowledge the record. This guarantees that the record will not be lost as long as at least one in-sync replica remains alive. This is the strongest available guarantee. This is equivalent to the acks=-1 setting.</li></ul><p><strong>TYPE</strong>:string</p><p><strong>DEFAULT</strong>:1</p><p><strong>VALID VALUES</strong>:[all, -1, 0, 1]</p><p><a href="https://gitee.com/link?target=http://kafka.apache.org/0110/documentation/%23producerconfigs">Source</a></p></blockquote><h3 id="10-3-数据一致性问题"><a href="#10-3-数据一致性问题" class="headerlink" title="10.3. 数据一致性问题"></a>10.3. 数据一致性问题</h3><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.45aa2vgkaac0.webp" alt="image" style="zoom:80%;" /><ul><li><p>LEO：（Log End Offset）每个副本的最后一个offset</p></li><li><p>HW：（High Watermark）高水位，指的是消费者能见到的最大的 offset， ISR 队列中最小的 LEO</p></li><li><p><strong>follower 故障</strong>：follower 发生故障后会被临时踢出 ISR，待该 follower 恢复后， follower 会读取本地磁盘记录的上次的 HW，并将 log 文件高于 HW 的部分截取掉，从 HW 开始向 leader 进行同步。等该 follower 的 LEO 大于等于该 Partition 的 HW，即 follower 追上 leader 之后，就可以重新加入 ISR 了。</p></li><li><p><strong>leader 故障</strong>：leader 发生故障之后，会从 ISR 中选出一个新的 leader，之后，为保证多个副本之间的数据一致性， 其余的 follower 会先将各自的 log 文件高于 HW 的部分截掉，然后从新的 leader同步数据。</p></li></ul><p>注意： 这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</p><h3 id="10-4-ExactlyOnce"><a href="#10-4-ExactlyOnce" class="headerlink" title="10.4. ExactlyOnce"></a>10.4. ExactlyOnce</h3><p>将服务器的 ACK 级别设置为-1（all），可以保证 Producer 到 Server 之间不会丢失数据，即 <strong>At Least Once</strong> 语义。</p><p>相对的，将服务器 ACK 级别设置为 0，可以保证生产者每条消息只会被发送一次，即 <strong>At Most Once</strong> 语义。</p><p>At Least Once 可以保证数据不丢失，但是不能保证数据不重复；相对的， At Most Once可以保证数据不重复，但是不能保证数据不丢失。 但是，对于一些非常重要的信息，比如说<strong>交易数据</strong>，下游数据消费者要求数据既不重复也不丢失，即 <strong>Exactly Once</strong> 语义。</p><blockquote><ul><li>At least once—Messages are <strong>never lost</strong> but may be redelivered.</li><li>At most once—Messages <strong>may be lost</strong> but are never redelivered.</li><li>Exactly once—this is what people actually want, each message is delivered once and only once.</li></ul><p><a href="https://gitee.com/link?target=http://kafka.apache.org/0110/documentation/%23semantics">Source</a></p></blockquote><p>在 0.11 版本以前的 Kafka，对此是无能为力的，只能保证数据不丢失，再在下游消费者对数据做全局去重。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</p><p>0.11 版本的 Kafka，引入了一项重大特性：<strong>幂等性</strong>。<strong>所谓的幂等性就是指 Producer 不论向 Server 发送多少次重复数据， Server 端都只会持久化一条</strong>。幂等性结合 At Least Once 语义，就构成了 Kafka 的 Exactly Once 语义。即：</p><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs mathematica"><span class="hljs-variable">At</span> <span class="hljs-variable">Least</span> <span class="hljs-built_in">Once</span> <span class="hljs-operator">+</span> 幂等性 <span class="hljs-operator">=</span> <span class="hljs-variable">Exactly</span> <span class="hljs-built_in">Once</span><br></code></pre></td></tr></table></figure><p>要启用幂等性，只需要将 Producer 的参数中 <code>enable.idempotence</code> 设置为 true 即可。 Kafka的幂等性实现其实就是将原来下游需要做的去重放在了数据上游。开启幂等性的 Producer 在初始化的时候会被分配一个 PID，发往同一 Partition 的消息会附带 Sequence Number。而Broker 端会对<code>&lt;PID, Partition, SeqNumber&gt;</code>做缓存，当具有相同主键的消息提交时， Broker 只会持久化一条。</p><p>但是 PID 重启就会变化，同时不同的 Partition 也具有不同主键，所以幂等性无法保证跨分区跨会话的 Exactly Once。</p><blockquote><p><strong>enable.idempotence</strong></p><p>DESCRIPTION:When set to ‘true’, the producer will ensure that exactly one copy of each message is written in the stream. If ‘false’, producer retries due to broker failures, etc., may write duplicates of the retried message in the stream. This is set to ‘false’ by default. Note that enabling idempotence requires <code>max.in.flight.requests.per.connection</code> to be set to 1 and <code>retries</code> cannot be zero. Additionally acks must be set to ‘all’. If these values are left at their defaults, we will override the default to be suitable. If the values are set to something incompatible with the idempotent producer, a ConfigException will be thrown.</p><p>TYPE:boolean</p><p>DEFAULT:false</p><p><a href="https://gitee.com/link?target=http://kafka.apache.org/0110/documentation/%23producerconfigs">Source</a></p></blockquote><h2 id="11-Kafka消费者"><a href="#11-Kafka消费者" class="headerlink" title="11.Kafka消费者"></a>11.Kafka消费者</h2><h3 id="11-1-消费方式"><a href="#11-1-消费方式" class="headerlink" title="11.1. 消费方式"></a>11.1. 消费方式</h3><p><strong>consumer 采用 pull（拉） 模式从 broker 中读取数据</strong>。</p><p><strong>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的</strong>。它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而 pull 模式则可以根据 consumer 的消费能力以适当的速率消费消息。</p><p><strong>pull 模式不足之处</strong>是，如果 kafka 没有数据，消费者可能会陷入循环中， 一直返回空数据。 针对这一点， Kafka 的消费者在消费数据时会传入一个时长参数 timeout，如果当前没有数据可供消费， consumer 会等待一段时间之后再返回，这段时长即为 timeout。</p><p><a href="https://gitee.com/link?target=http://kafka.apache.org/0110/documentation/%23design_pull">Push vs. pull</a></p><h3 id="11-2-分区分配策略"><a href="#11-2-分区分配策略" class="headerlink" title="11.2. 分区分配策略"></a>11.2. 分区分配策略</h3><p>一个 consumer group 中有多个 consumer，一个 topic 有多个 partition，所以必然会涉及到 partition 的分配问题，即确定那个 partition 由哪个 consumer 来消费。</p><p>Kafka 有两种分配策略：</p><ul><li>round-robin循环</li><li>range</li></ul><blockquote><p><strong>partition.assignment.strategy</strong></p><p>Select between the “range” or “roundrobin” strategy for assigning分配 partitions to consumer streams.</p><p>The <strong>round-robin</strong> partition assignor lays out规划 all the available partitions and all the available consumer threads. It then proceeds to do接着做 a round-robin assignment from partition to consumer thread. If the subscriptions订阅 of all consumer instances are identical完全同样的, then the partitions will be uniformly 均匀地distributed. (i.e.也就是说, the partition ownership counts will be within a delta of exactly one across all consumer threads.) Round-robin assignment is permitted only if:</p><ol><li>Every topic has the same number of streams within a consumer instance</li><li>The set of subscribed topics is identical for every consumer instance within the group.</li></ol><p><strong>Range</strong> partitioning works on a per-<strong>topic</strong> basis. For each topic, we lay out the available partitions in numeric order and the consumer threads in lexicographic词典式的 order. We then divide the number of partitions by the total number of consumer streams (threads) to determine the number of partitions to assign to each consumer. If it does not evenly divide, then the first few consumers will have one extra partition.</p><p><strong>DEFAULT</strong>:range</p><p><a href="https://gitee.com/link?target=http://kafka.apache.org/0110/documentation/%23oldconsumerconfigs">Source</a></p></blockquote><hr><p><a href="https://gitee.com/link?target=https://zhuanlan.zhihu.com/p/86718818">Kafka再平衡机制详解</a></p><p><strong><font color='red'>（1）Round Robin</font></strong></p><p>关于Roudn Robin重分配策略，其主要采用的是一种轮询的方式分配所有的分区，该策略主要实现的步骤如下。这里我们首先假设有三个topic：t0、t1和t2，这三个topic拥有的分区数分别为1、2和3，那么总共有六个分区，这六个分区分别为：t0-0、t1-0、t1-1、t2-0、t2-1和t2-2。这里假设我们有三个consumer：C0、C1和C2，它们订阅情况为：C0订阅t0，C1订阅t0和t1，C2订阅t0、t1和t2。那么这些分区的分配步骤如下：</p><ul><li>首先将所有的partition和consumer按照字典序进行排序，所谓的字典序，就是按照其名称的字符串顺序，那么上面的六个分区和三个consumer排序之后分别为：</li></ul><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.1ujqs1wyz9vk.webp" alt="image"></p><ul><li>然后依次以按顺序轮询的方式将这六个分区分配给三个consumer，如果当前consumer没有订阅当前分区所在的topic，则轮询的判断下一个consumer：</li><li>尝试将t0-0分配给C0，由于C0订阅了t0，因而可以分配成功；</li><li>尝试将t1-0分配给C1，由于C1订阅了t1，因而可以分配成功；</li><li>尝试将t1-1分配给C2，由于C2订阅了t1，因而可以分配成功；</li><li>尝试将t2-0分配给C0，由于C0没有订阅t2，因而会轮询下一个consumer；</li><li>尝试将t2-0分配给C1，由于C1没有订阅t2，因而会轮询下一个consumer；</li><li>尝试将t2-0分配给C2，由于C2订阅了t2，因而可以分配成功；</li><li>同理由于t2-1和t2-2所在的topic都没有被C0和C1所订阅，因而都不会分配成功，最终都会分配给C2。</li><li>按照上述的步骤将所有的分区都分配完毕之后，最终分区的订阅情况如下：</li></ul><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.4xiq26rwtm80.webp" alt="image"></p><p>从上面的步骤分析可以看出，轮询的策略就是简单的将所有的partition和consumer按照字典序进行排序之后，然后依次将partition分配给各个consumer，如果当前的consumer没有订阅当前的partition，那么就会轮询下一个consumer，直至最终将所有的分区都分配完毕。但是从上面的分配结果可以看出，轮询的方式会导致每个consumer所承载的分区数量不一致，从而导致各个consumer压力不均一。</p><p><strong><font color='red'>（2）Range</font></strong></p><p>所谓的Range重分配策略，就是首先会计算各个consumer将会承载的分区数量，然后将指定数量的分区分配给该consumer。这里我们假设有两个consumer：C0和C1，两个topic：t0和t1，这两个topic分别都有三个分区，那么总共的分区有六个：t0-0、t0-1、t0-2、t1-0、t1-1和t1-2。那么Range分配策略将会按照如下步骤进行分区的分配：</p><ul><li>需要注意的是，Range策略是按照topic依次进行分配的，比如我们以t0进行讲解，其首先会获取t0的所有分区：t0-0、t0-1和t0-2，以及所有订阅了该topic的consumer：C0和C1，并且会将这些分区和consumer按照字典序进行排序；</li><li>然后按照平均分配的方式计算每个consumer会得到多少个分区，如果没有除尽，则会将多出来的分区依次计算到前面几个consumer。比如这里是三个分区和两个consumer，那么每个consumer至少会得到1个分区，而3除以2后还余1，那么就会将多余的部分依次算到前面几个consumer，也就是这里的1会分配给第一个consumer，总结来说，那么C0将会从第0个分区开始，分配2个分区，而C1将会从第2个分区开始，分配1个分区；</li><li>同理，按照上面的步骤依次进行后面的topic的分配。</li><li>最终上面六个分区的分配情况如下：</li></ul><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.ktivc8gvg34.webp" alt="image"></p><p>可以看到，如果按照<code>Range</code>分区方式进行分配，其本质上是依次遍历每个topic，然后将这些topic的分区按照其所订阅的consumer数量进行平均的范围分配。这种方式从计算原理上就会导致排序在前面的consumer分配到更多的分区，从而导致各个consumer的压力不均衡。</p><p>TODO:我的问题：topic分多个partition，有些custom根据上述策略，分到topic的部分partition，难道不是要全部partition吗？是不是还要按照相同策略多分配多一次？</p><h3 id="11-3-消费者offset的存储"><a href="#11-3-消费者offset的存储" class="headerlink" title="11.3. 消费者offset的存储"></a>11.3. 消费者offset的存储</h3><p>由于 consumer 在消费过程中可能会出现断电宕机等故障， consumer 恢复后，需要从故障前的位置的继续消费，所以 <strong>consumer 需要实时记录自己消费到了哪个 offset</strong>，以便故障恢复后继续消费。</p><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.5ojg6y8ympk0.webp" alt="image"></p><p><strong>Kafka 0.9 版本之前， consumer 默认将 offset 保存在 Zookeeper 中，从 0.9 版本开始，consumer 默认将 offset 保存在 Kafka 一个内置的 topic 中，该 topic 为__consumer_offsets</strong>。</p><ol><li>修改配置文件 consumer.properties，<code>exclude.internal.topics=false</code>。</li><li>读取 offset<ul><li>0.11.0.0 之前版本 - <code>bin/kafka-console-consumer.sh --topic __consumer_offsets --zookeeper hadoop102:2181 --formatter &quot;kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter&quot; --consumer.config config/consumer.properties --from-beginning</code></li><li>0.11.0.0 及之后版本 - <code>bin/kafka-console-consumer.sh --topic __consumer_offsets --zookeeper hadoop102:2181 --formatter &quot;kafka.coordinator.group.GroupMetadataManager\$OffsetsMessageFormatter&quot; --consumer.config config/consumer.properties --from-beginning</code></li></ul></li></ol><p>TODO:上机实验</p><h3 id="11-4-消费者组案例"><a href="#11-4-消费者组案例" class="headerlink" title="11.4. 消费者组案例"></a>11.4. 消费者组案例</h3><p><strong>(1) 需求</strong></p><p>测试同一个消费者组中的消费者， <strong>同一时刻只能有一个</strong>消费者消费。</p><p><strong>(2) 操作步骤</strong></p><p>1.修改<code>%KAFKA_HOME\config\consumer.properties%</code>文件中的<code>group.id</code>属性。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">group.id</span>=shan-kou-zu<br></code></pre></td></tr></table></figure><p>2.打开两个cmd，分别启动两个消费者。（以<code>%KAFKA_HOME\config\consumer.properties%</code>作配置参数）</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">bin\windows\kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">console</span><span class="hljs-literal">-</span><span class="hljs-comment">consumer</span><span class="hljs-string">.</span><span class="hljs-comment">bat</span> --<span class="hljs-comment">zookeeper</span> <span class="hljs-comment">127</span><span class="hljs-string">.</span><span class="hljs-comment">0</span><span class="hljs-string">.</span><span class="hljs-comment">0</span><span class="hljs-string">.</span><span class="hljs-comment">1:2181</span> --<span class="hljs-comment">topic</span> <span class="hljs-comment">test</span> --<span class="hljs-comment">consumer</span><span class="hljs-string">.</span><span class="hljs-comment">config</span> <span class="hljs-comment">config\consumer</span><span class="hljs-string">.</span><span class="hljs-comment">properties</span><br></code></pre></td></tr></table></figure><p>3.再打开一个cmd，启动一个生产者。</p><figure class="highlight brainfuck"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs brainfuck"><span class="hljs-comment">bin\windows\kafka</span><span class="hljs-literal">-</span><span class="hljs-comment">console</span><span class="hljs-literal">-</span><span class="hljs-comment">producer</span><span class="hljs-string">.</span><span class="hljs-comment">bat</span> --<span class="hljs-comment">broker</span><span class="hljs-literal">-</span><span class="hljs-comment">list</span> <span class="hljs-comment">127</span><span class="hljs-string">.</span><span class="hljs-comment">0</span><span class="hljs-string">.</span><span class="hljs-comment">0</span><span class="hljs-string">.</span><span class="hljs-comment">1:9092</span> --<span class="hljs-comment">topic</span> <span class="hljs-comment">test</span><br></code></pre></td></tr></table></figure><p>4.在生产者窗口输入消息，观察两个消费者窗口。<strong>会发现两个消费者窗口中，只有一个才会弹出消息</strong>。</p><h2 id="12-Kafka高效读写-amp-ZK作用"><a href="#12-Kafka高效读写-amp-ZK作用" class="headerlink" title="12. Kafka高效读写&amp;ZK作用"></a>12. Kafka高效读写&amp;ZK作用</h2><h3 id="12-1-顺序写磁盘"><a href="#12-1-顺序写磁盘" class="headerlink" title="12.1. 顺序写磁盘"></a>12.1. 顺序写磁盘</h3><p>Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，为顺序写。 官网有数据表明，同样的磁盘，顺序写能到 600M/s，而随机写只有 100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其<strong>省去了大量磁头寻址的时间</strong>。</p><h3 id="12-2-零复制技术"><a href="#12-2-零复制技术" class="headerlink" title="12.2. 零复制技术"></a>12.2. 零复制技术</h3><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.3iuz1tfvjru0.webp" alt="image"></p><ul><li>NIC network interface controller 网络接口控制器</li></ul><h3 id="12-3-zk在kafka中的作用"><a href="#12-3-zk在kafka中的作用" class="headerlink" title="12.3. zk在kafka中的作用"></a>12.3. zk在kafka中的作用</h3><p>Kafka 集群中有一个 broker 会被选举为 Controller，负责管理集群 broker 的上下线，所有 topic 的分区副本分配和 leader 选举等工作。<a href="https://gitee.com/link?target=http://kafka.apache.org/0110/documentation/%23design_replicamanagment">Reference</a></p><p>Controller 的管理工作都是依赖于 Zookeeper 的。</p><p>以下为 partition 的 leader 选举过程：</p><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.3wpw2e3ax9y0.webp" alt="image"></p><h2 id="14-Kafka高级-事务"><a href="#14-Kafka高级-事务" class="headerlink" title="14.Kafka高级_事务"></a>14.Kafka高级_事务</h2><p>Kafka 从 0.11 版本开始引入了事务支持。事务可以保证 Kafka 在 Exactly Once 语义的基础上，生产和消费可以跨分区和会话，要么全部成功，要么全部失败。</p><h3 id="14-1-Producer-事务"><a href="#14-1-Producer-事务" class="headerlink" title="14.1. Producer 事务"></a>14.1. Producer 事务</h3><p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的 Transaction ID，并将 Producer 获得的PID 和Transaction ID 绑定。这样当Producer 重启后就可以通过正在进行的 TransactionID 获得原来的 PID。</p><p>为了管理 Transaction， Kafka 引入了一个新的组件 Transaction Coordinator。 Producer 就是通过和 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态。 Transaction Coordinator 还负责将事务所有写入 Kafka 的一个内部 Topic，这样即使整个服务重启，由于事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p><h3 id="14-2-Consumer-事务"><a href="#14-2-Consumer-事务" class="headerlink" title="14.2. Consumer 事务"></a>14.2. Consumer 事务</h3><p>上述事务机制主要是从 Producer 方面考虑，对于 Consumer 而言，事务的保证就会相对较弱，尤其时无法保证 Commit 的信息被精确消费。这是由于 Consumer 可以通过 offset 访问任意信息，而且不同的 Segment File 生命周期不同，同一事务的消息可能会出现重启后被删除的情况。</p><h2 id="15-Kafka-API"><a href="#15-Kafka-API" class="headerlink" title="15.Kafka API"></a>15.Kafka API</h2><h3 id="15-1-Producer-API"><a href="#15-1-Producer-API" class="headerlink" title="15.1. Producer API"></a>15.1. Producer API</h3><h4 id="15-1-1-消息发送流程"><a href="#15-1-1-消息发送流程" class="headerlink" title="15.1.1. 消息发送流程"></a>15.1.1. 消息发送流程</h4><p>Kafka 的 Producer 发送消息采用的是异步发送的方式。在消息发送的过程中，涉及到了两个线程——main 线程和 Sender 线程，以及一个线程共享变量——RecordAccumulator。 main 线程将消息发送给 RecordAccumulator， Sender 线程不断从 RecordAccumulator 中拉取消息发送到 Kafka broker。</p><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.6aubpl4e98k0.webp" alt="image"></p><p>相关参数：</p><ul><li><strong>batch.size</strong>： 只有数据积累到 batch.size 之后， sender 才会发送数据。</li><li><strong>linger.ms</strong>： 如果数据迟迟未达到 batch.size， sender 等待 linger.time 之后就会发送数据。</li></ul><h4 id="15-1-2-异步发送API"><a href="#15-1-2-异步发送API" class="headerlink" title="15.1.2. 异步发送API"></a>15.1.2. 异步发送API</h4><ol><li><pre><code>导入依赖</code></pre></li></ol><p><a href="https://gitee.com/jallenkwong/LearnKafka/blob/master/pom.xml">pom.xml</a></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-section">&lt;dependency&gt;</span><br><span class="hljs-section">&lt;groupId&gt;</span><span class="hljs-attribute">org</span>.apache.kafka&lt;/groupId&gt;<br><span class="hljs-section">&lt;artifactId&gt;</span><span class="hljs-attribute">kafka</span>-clients&lt;/artifactId&gt;<br><span class="hljs-section">&lt;version&gt;</span><span class="hljs-attribute">0</span>.<span class="hljs-number">11</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>&lt;/version&gt;<br><span class="hljs-section">&lt;/dependency&gt;</span><br></code></pre></td></tr></table></figure><ol start="2"><li>   编写代码</li></ol><p>需要用到的类：</p><ul><li>KafkaProducer：需要创建一个生产者对象，用来发送数据</li><li>ProducerConfig：获取所需的一系列配置参数</li><li>ProducerRecord：每条数据都要封装成一个 ProducerRecord 对象</li></ul><p><a href="https://gitee.com/jallenkwong/LearnKafka/blob/master/src/main/java/com/lun/kafka/producer/CustomProducer.java">CustomProducer.java</a></p><p>(1)    不带回调函数</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-keyword">import</span> java.util.Properties;<br><br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.Producer;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;<br><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CustomProducer</span> &#123;</span><br><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">String</span>[] args)</span> </span>&#123;<br>Properties props = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Properties</span>();<br><span class="hljs-comment">// kafka 集群， broker-list</span><br><br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;bootstrap.servers&quot;</span>, <span class="hljs-string">&quot;127.0.0.1:9092&quot;</span>);<br><br><span class="hljs-comment">//可用ProducerConfig.ACKS_CONFIG 代替 &quot;acks&quot;</span><br><span class="hljs-comment">//props.put(ProducerConfig.ACKS_CONFIG, &quot;all&quot;);</span><br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;acks&quot;</span>, <span class="hljs-string">&quot;all&quot;</span>);<br><span class="hljs-comment">// 重试次数</span><br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;retries&quot;</span>, <span class="hljs-number">1</span>);<br><span class="hljs-comment">// 批次大小</span><br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;batch.size&quot;</span>, <span class="hljs-number">16384</span>);<br><span class="hljs-comment">// 等待时间</span><br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;linger.ms&quot;</span>, <span class="hljs-number">1</span>);<br><span class="hljs-comment">// RecordAccumulator 缓冲区大小</span><br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;buffer.memory&quot;</span>, <span class="hljs-number">33554432</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;key.serializer&quot;</span>, <span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;value.serializer&quot;</span>, <span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);<br>Producer&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt; producer = <span class="hljs-keyword">new</span> KafkaProducer&lt;&gt;(props);<br><span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i++) &#123;<br>producer.<span class="hljs-built_in">send</span>(<span class="hljs-keyword">new</span> ProducerRecord&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt;(<span class="hljs-string">&quot;test&quot;</span>, <span class="hljs-string">&quot;test-&quot;</span> + Integer.<span class="hljs-built_in">toString</span>(i),<br><span class="hljs-string">&quot;test-&quot;</span> + Integer.<span class="hljs-built_in">toString</span>(i)));<br>&#125;<br>producer.<span class="hljs-built_in">close</span>();<br>&#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><p>(2)    带回调函数</p><p>回调函数会在 producer 收到 ack 时调用，为异步调用， 该方法有两个参数，分别是 RecordMetadata 和 Exception，如果     Exception 为 null，说明消息发送成功，如果Exception 不为 null，说明消息发送失败。</p><p><strong>注意</strong>：消息发送失败会自动重试，不需要我们在回调函数中手动重试。</p><p><a href="https://gitee.com/jallenkwong/LearnKafka/blob/master/src/main/java/com/lun/kafka/producer/CallBackProducer.java">CallBackProducer.java</a></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-keyword">import</span> java.util.Properties;<br><br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.Callback;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.Producer;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.RecordMetadata;<br><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CallBackProducer</span> &#123;</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">String</span>[] args)</span> </span>&#123;<br>Properties props = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Properties</span>();<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;bootstrap.servers&quot;</span>, <span class="hljs-string">&quot;127.0.0.1:9092&quot;</span>);<span class="hljs-comment">//kafka 集群， broker-list</span><br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;acks&quot;</span>, <span class="hljs-string">&quot;all&quot;</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;retries&quot;</span>, <span class="hljs-number">1</span>);<span class="hljs-comment">//重试次数</span><br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;batch.size&quot;</span>, <span class="hljs-number">16384</span>);<span class="hljs-comment">//批次大小</span><br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;linger.ms&quot;</span>, <span class="hljs-number">1</span>);<span class="hljs-comment">//等待时间</span><br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;buffer.memory&quot;</span>, <span class="hljs-number">33554432</span>);<span class="hljs-comment">//RecordAccumulator 缓冲区大小</span><br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;key.serializer&quot;</span>,<br><span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;value.serializer&quot;</span>,<br><span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);<br><br>Producer&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt; producer = <span class="hljs-keyword">new</span> KafkaProducer&lt;&gt;(props);<br><span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i++) &#123;<br>producer.<span class="hljs-built_in">send</span>(<span class="hljs-keyword">new</span> ProducerRecord&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt;(<span class="hljs-string">&quot;test&quot;</span>,<br><span class="hljs-string">&quot;test&quot;</span> + Integer.<span class="hljs-built_in">toString</span>(i)), <span class="hljs-keyword">new</span> <span class="hljs-built_in">Callback</span>() &#123;<br><br><span class="hljs-comment">//回调函数， 该方法会在 Producer 收到 ack 时调用，为异步调用</span><br>@Override<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-built_in">onCompletion</span>(RecordMetadata metadata, Exception exception) &#123;<br><span class="hljs-keyword">if</span> (exception == null) &#123;<br>System.out.<span class="hljs-built_in">println</span>(metadata.<span class="hljs-built_in">partition</span>() + <span class="hljs-string">&quot; - &quot;</span> + metadata.<span class="hljs-built_in">offset</span>());<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>exception.<span class="hljs-built_in">printStackTrace</span>();<br>&#125;<br>&#125;<br>&#125;);<br>&#125;<br><br>producer.<span class="hljs-built_in">close</span>();<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="15-1-3-同步发送API"><a href="#15-1-3-同步发送API" class="headerlink" title="15.1.3. 同步发送API"></a>15.1.3. 同步发送API</h4><p>同步发送的意思就是，一条消息发送之后，会阻塞当前线程， 直至返回 ack。</p><p>由于 send 方法返回的是一个 Future 对象，根据 Futrue 对象的特点，我们也可以实现同步发送的效果，只需在调用 Future 对象的 get 方发即可。</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs typescript">Producer&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt; producer = <span class="hljs-keyword">new</span> KafkaProducer&lt;&gt;(props);<br><span class="hljs-keyword">for</span> (int i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i++) &#123;<br>producer.send(<span class="hljs-keyword">new</span> ProducerRecord&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt;(<span class="hljs-string">&quot;test&quot;</span>,  <span class="hljs-string">&quot;test - 1&quot;</span>), <span class="hljs-keyword">new</span> <span class="hljs-function"><span class="hljs-title">Callback</span>(<span class="hljs-params"></span>)</span> &#123;<br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">onCompletion</span>(<span class="hljs-params">RecordMetadata metadata, Exception exception</span>)</span> &#123;<br>...<br>&#125;<br>&#125;).get();<span class="hljs-comment">//&lt;----------------------</span><br>&#125;<br></code></pre></td></tr></table></figure><h4 id="15-1-4-生产者分区策略"><a href="#15-1-4-生产者分区策略" class="headerlink" title="15.1.4. 生产者分区策略"></a>15.1.4. 生产者分区策略</h4><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.39nqnysamsm0.webp" alt="image"></p><p>ProducerRecord类有许多构造函数，其中一个参数partition可指定分区</p><p>TODO:根据策略阐述，亲自设计分区策略测试，range和round-robin间的区别</p><h4 id="15-1-5-带自定义分区器"><a href="#15-1-5-带自定义分区器" class="headerlink" title="15.1.5. 带自定义分区器"></a>15.1.5. 带自定义分区器</h4><p><a href="https://gitee.com/jallenkwong/LearnKafka/blob/master/src/main/java/com/lun/kafka/producer/MyPartitioner.java">MyPartitioner.java</a></p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.Partitioner;<br><span class="hljs-keyword">import</span> org.apache.kafka.common.Cluster;<br><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyPartitioner</span> <span class="hljs-title">implements</span> <span class="hljs-title">Partitioner</span> </span>&#123;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">configure</span>(<span class="hljs-params"><span class="hljs-built_in">Map</span>&lt;<span class="hljs-built_in">String</span>, ?&gt; configs</span>)</span> &#123;<br><span class="hljs-comment">// TODO Auto-generated method stub</span><br><br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> int <span class="hljs-function"><span class="hljs-title">partition</span>(<span class="hljs-params"><span class="hljs-built_in">String</span> topic, <span class="hljs-built_in">Object</span> key, byte[] keyBytes, <span class="hljs-built_in">Object</span> value, byte[] valueBytes, Cluster cluster</span>)</span> &#123;<br><span class="hljs-comment">// TODO Auto-generated method stub</span><br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">close</span>(<span class="hljs-params"></span>)</span> &#123;<br><span class="hljs-comment">// TODO Auto-generated method stub</span><br><br>&#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><p>具体内容填写可参考默认分区器<code>org.apache.kafka.clients.producer.internals.DefaultPartitioner</code></p><p>然后Producer配置中注册使用</p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs haxe">Properties props = <span class="hljs-keyword">new</span> <span class="hljs-type">Properties</span>();<br>...<br>props.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, MyPartitioner.class);<br>...<br>Producer&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt; producer = <span class="hljs-keyword">new</span> <span class="hljs-type">KafkaProducer</span>&lt;&gt;(props);<br></code></pre></td></tr></table></figure><h3 id="15-2-Consumer-API"><a href="#15-2-Consumer-API" class="headerlink" title="15.2. Consumer API"></a>15.2. Consumer API</h3><p>Consumer 消费数据时的可靠性是很容易保证的，因为数据在 Kafka 中是持久化的，故不用担心数据丢失问题。</p><p>由于 consumer 在消费过程中可能会出现断电宕机等故障， consumer 恢复后，需要从故障前的位置的继续消费，所以 consumer 需要实时记录自己消费到了哪个 offset，以便故障恢复后继续消费。</p><p>所以 offset 的维护是 Consumer 消费数据是必须考虑的问题。</p><h4 id="15-2-1-自动提交offset"><a href="#15-2-1-自动提交offset" class="headerlink" title="15.2.1. 自动提交offset"></a>15.2.1. 自动提交offset</h4><ul><li><strong>KafkaConsumer</strong>： 需要创建一个消费者对象，用来消费数据</li><li><strong>ConsumerConfig</strong>： 获取所需的一系列配置参数</li><li><strong>ConsuemrRecord</strong>： 每条数据都要封装成一个 ConsumerRecord 对象</li></ul><p><strong>为了使我们能够专注于自己的业务逻辑， Kafka 提供了自动提交 offset 的功能</strong>。</p><p>自动提交 offset 的相关参数：</p><ul><li><strong>enable.auto.commit</strong>：是否开启自动提交 offset 功能</li><li><strong>auto.commit.interval.ms</strong>：自动提交 offset 的时间间隔</li></ul><p><a href="https://gitee.com/jallenkwong/LearnKafka/blob/master/src/main/java/com/lun/kafka/consumer/CustomConsumer.java">CustomConsumer.java</a></p><blockquote><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-keyword">import</span> java.util.Arrays;<br><span class="hljs-keyword">import</span> java.util.Properties;<br><br><span class="hljs-keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer;<br><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CustomConsumer</span> &#123;</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">String</span>[] args)</span> </span>&#123;<br><br>Properties props = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Properties</span>();<br><br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;bootstrap.servers&quot;</span>, <span class="hljs-string">&quot;127.0.0.1:9092&quot;</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;group.id&quot;</span>, <span class="hljs-string">&quot;abc&quot;</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;enable.auto.commit&quot;</span>, <span class="hljs-string">&quot;true&quot;</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;auto.commit.interval.ms&quot;</span>, <span class="hljs-string">&quot;1000&quot;</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;key.deserializer&quot;</span>,<br><span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;value.deserializer&quot;</span>,<br><span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);<br><br>KafkaConsumer&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt; consumer = <span class="hljs-keyword">new</span> KafkaConsumer&lt;&gt;(props);<br><br>consumer.<span class="hljs-built_in">subscribe</span>(Arrays.<span class="hljs-built_in">asList</span>(<span class="hljs-string">&quot;test&quot;</span>));<br><br><span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) &#123;<br>ConsumerRecords&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt; records = consumer.<span class="hljs-built_in">poll</span>(<span class="hljs-number">100</span>);<br><span class="hljs-keyword">for</span> (ConsumerRecord&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt; record : records) &#123;<br>System.out.<span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;offset = %d, key = %s, value = %s%n&quot;</span>, record.<span class="hljs-built_in">offset</span>(), record.<span class="hljs-built_in">key</span>(), record.<span class="hljs-built_in">value</span>());<br>&#125;<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure></blockquote><h4 id="15-2-2-手动提交offset"><a href="#15-2-2-手动提交offset" class="headerlink" title="15.2.2. 手动提交offset"></a>15.2.2. 手动提交offset</h4><p>虽然自动提交 offset 十分便利，但由于其是基于时间提交的， 开发人员难以把握offset 提交的时机。因此 <strong>Kafka 还提供了手动提交 offset 的 API</strong>。</p><p>手动提交 offset 的方法有两种：</p><ol><li>commitSync（同步提交）</li><li>commitAsync（异步提交）</li></ol><p>两者的<strong>相同点</strong>是，都会将本次 poll 的一批数据最高的偏移量提交；</p><p><strong>不同点</strong>是，commitSync 阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而 commitAsync 则没有失败重试机制，故有可能提交失败。</p><p>(1)    <strong><font color='cornflowerblue'>同步提交offset</font></strong></p><p>由于同步提交 offset 有失败重试机制，故更加可靠，以下为同步提交 offset 的示例。</p><p><a href="https://gitee.com/jallenkwong/LearnKafka/blob/master/src/main/java/com/lun/kafka/consumer/SyncCommitOffset.java">SyncCommitOffset.java</a></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SyncCommitOffset</span> &#123;</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">String</span>[] args)</span> </span>&#123;<br>Properties props = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Properties</span>();<br>...<br><span class="hljs-comment">//&lt;-----------------</span><br><span class="hljs-comment">//关闭自动提交 offset</span><br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;enable.auto.commit&quot;</span>, <span class="hljs-string">&quot;false&quot;</span>);<br>...<br>KafkaConsumer&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt; consumer = <span class="hljs-keyword">new</span> KafkaConsumer&lt;&gt;(props);<br>consumer.<span class="hljs-built_in">subscribe</span>(Arrays.<span class="hljs-built_in">asList</span>(<span class="hljs-string">&quot;first&quot;</span>));<span class="hljs-comment">//消费者订阅主题</span><br><span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) &#123;<br><span class="hljs-comment">//消费者拉取数据</span><br>ConsumerRecords&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt; records =<br>consumer.<span class="hljs-built_in">poll</span>(<span class="hljs-number">100</span>);<br><span class="hljs-keyword">for</span> (ConsumerRecord&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt; record : records) &#123;<br>System.out.<span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;offset = %d, key = %s, value= %s%n&quot;</span>, record.<span class="hljs-built_in">offset</span>(), record.<span class="hljs-built_in">key</span>(), record.<span class="hljs-built_in">value</span>());<br>&#125;<br><span class="hljs-comment">//&lt;---------------------------------------</span><br><span class="hljs-comment">//同步提交，当前线程会阻塞直到 offset 提交成功</span><br>consumer.<span class="hljs-built_in">commitSync</span>();<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>(2)    <strong><font color='cornflowerblue'>异步提交offset</font></strong></p><p>虽然同步提交 offset 更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会收到很大的影响。因此更多的情况下，会选用异步提交 offset 的方式。</p><p><a href="https://gitee.com/jallenkwong/LearnKafka/blob/master/src/main/java/com/lun/kafka/consumer/AsyncCommitOffset.java">AsyncCommitOffset.java</a></p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AsyncCommitOffset</span> </span>&#123;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">main</span>(<span class="hljs-params"><span class="hljs-built_in">String</span>[] args</span>)</span> &#123;<br>Properties props = <span class="hljs-keyword">new</span> Properties();<br>...<br><span class="hljs-comment">//&lt;--------------------------------------</span><br><span class="hljs-comment">//关闭自动提交</span><br>props.put(<span class="hljs-string">&quot;enable.auto.commit&quot;</span>, <span class="hljs-string">&quot;false&quot;</span>);<br>...<br>KafkaConsumer&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt; consumer = <span class="hljs-keyword">new</span> KafkaConsumer&lt;&gt;(props);<br>consumer.subscribe(Arrays.asList(<span class="hljs-string">&quot;first&quot;</span>));<span class="hljs-comment">// 消费者订阅主题</span><br><span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) &#123;<br>ConsumerRecords&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt; records = consumer.poll(<span class="hljs-number">100</span>);<span class="hljs-comment">// 消费者拉取数据</span><br><span class="hljs-keyword">for</span> (ConsumerRecord&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt; record : records) &#123;<br>System.out.printf(<span class="hljs-string">&quot;offset = %d, key = %s, value = %s%n&quot;</span>, record.offset(), record.key(), record.value());<br>&#125;<br><span class="hljs-comment">//&lt;----------------------------------------------</span><br><span class="hljs-comment">// 异步提交</span><br>consumer.commitAsync(<span class="hljs-keyword">new</span> <span class="hljs-function"><span class="hljs-title">OffsetCommitCallback</span>(<span class="hljs-params"></span>)</span> &#123;<br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">onComplete</span>(<span class="hljs-params"><span class="hljs-built_in">Map</span>&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception</span>)</span> &#123;<br><span class="hljs-keyword">if</span> (exception != <span class="hljs-literal">null</span>) &#123;<br>System.err.println(<span class="hljs-string">&quot;Commit failed for&quot;</span> + offsets);<br>&#125;<br>&#125;<br>&#125;);<br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>(3)    <font color='cornflowerblue'>数据漏消费和重复消费分析</font></strong></p><p>无论是同步提交还是异步提交 offset，都有可能会造成数据的漏消费或者重复消费。先提交 offset 后消费，有可能造成数据的漏消费；而先消费后提交 offset，有可能会造成数据的重复消费。</p><h4 id="15-2-3-自定义存储-offset"><a href="#15-2-3-自定义存储-offset" class="headerlink" title="15.2.3. 自定义存储 offset"></a>15.2.3. 自定义存储 offset</h4><p>Kafka 0.9 版本之前， offset 存储在 zookeeper， 0.9 版本及之后，默认将 offset 存储在 Kafka的一个内置的 topic 中。除此之外， Kafka 还可以选择自定义存储 offset。</p><p>offset 的维护是相当繁琐的， 因为需要考虑到消费者的 Rebalace。</p><p><strong>当有新的消费者加入消费者组、 已有的消费者推出消费者组或者所订阅的主题的分区发生变化，就会触发到分区的重新分配，重新分配的过程叫做 Rebalance</strong>。</p><p>消费者发生 Rebalance 之后，每个消费者消费的分区就会发生变化。<strong>因此消费者要首先获取到自己被重新分配到的分区，并且定位到每个分区最近提交的 offset 位置继续消费</strong>。</p><p>要实现自定义存储 offset，需要借助 <code>ConsumerRebalanceListener</code>， 以下为示例代码，其中提交和获取 offset 的方法，需要根据所选的 offset 存储系统自行实现。(可将offset存入MySQL数据库)</p><p><a href="https://gitee.com/jallenkwong/LearnKafka/blob/master/src/main/java/com/lun/kafka/consumer/CustomSaveOffset.java">CustomSaveOffset.java</a></p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CustomSaveOffset</span> </span>&#123;<br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-built_in">Map</span>&lt;TopicPartition, Long&gt; currentOffset = <span class="hljs-keyword">new</span> HashMap&lt;&gt;();<br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">main</span>(<span class="hljs-params"><span class="hljs-built_in">String</span>[] args</span>)</span> &#123;<br><span class="hljs-comment">// 创建配置信息</span><br>Properties props = <span class="hljs-keyword">new</span> Properties();<br>...<br><span class="hljs-comment">//&lt;--------------------------------------</span><br><span class="hljs-comment">// 关闭自动提交 offset</span><br>props.put(<span class="hljs-string">&quot;enable.auto.commit&quot;</span>, <span class="hljs-string">&quot;false&quot;</span>);<br>...<br><span class="hljs-comment">// 创建一个消费者</span><br>KafkaConsumer&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt; consumer = <span class="hljs-keyword">new</span> KafkaConsumer&lt;&gt;(props);<br><span class="hljs-comment">// 消费者订阅主题</span><br>consumer.subscribe(Arrays.asList(<span class="hljs-string">&quot;first&quot;</span>), <br><span class="hljs-comment">//&lt;-------------------------------------</span><br><span class="hljs-keyword">new</span> <span class="hljs-function"><span class="hljs-title">ConsumerRebalanceListener</span>(<span class="hljs-params"></span>)</span> &#123;<br><span class="hljs-comment">// 该方法会在 Rebalance 之前调用</span><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">onPartitionsRevoked</span>(<span class="hljs-params">Collection&lt;TopicPartition&gt; partitions</span>)</span> &#123;<br>commitOffset(currentOffset);<br>&#125;<br><br><span class="hljs-comment">// 该方法会在 Rebalance 之后调用</span><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">onPartitionsAssigned</span>(<span class="hljs-params">Collection&lt;TopicPartition&gt; partitions</span>)</span> &#123;<br><br>currentOffset.clear();<br><span class="hljs-keyword">for</span> (TopicPartition partition : partitions) &#123;<br>consumer.seek(partition, getOffset(partition));<span class="hljs-comment">// 定位到最近提交的 offset 位置继续消费</span><br>&#125;<br>&#125;<br>&#125;);<br><br><span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) &#123;<br>ConsumerRecords&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt; records = consumer.poll(<span class="hljs-number">100</span>);<span class="hljs-comment">// 消费者拉取数据</span><br><span class="hljs-keyword">for</span> (ConsumerRecord&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt; record : records) &#123;<br>System.out.printf(<span class="hljs-string">&quot;offset = %d, key = %s, value = %s%n&quot;</span>, record.offset(), record.key(), record.value());<br>currentOffset.put(<span class="hljs-keyword">new</span> TopicPartition(record.topic(), record.partition()), record.offset());<br>&#125;<br>commitOffset(currentOffset);<span class="hljs-comment">// 异步提交</span><br>&#125;<br>&#125;<br><br><span class="hljs-comment">// 获取某分区的最新 offset</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> long <span class="hljs-function"><span class="hljs-title">getOffset</span>(<span class="hljs-params">TopicPartition partition</span>)</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-comment">// 提交该消费者所有分区的 offset</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">commitOffset</span>(<span class="hljs-params"><span class="hljs-built_in">Map</span>&lt;TopicPartition, Long&gt; currentOffset</span>)</span> &#123;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="15-2-4-保存offset读取问题"><a href="#15-2-4-保存offset读取问题" class="headerlink" title="15.2.4. 保存offset读取问题"></a>15.2.4. 保存offset读取问题</h4><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs maxima"><span class="hljs-built_in">props</span>.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;enable.auto.commit&quot;</span>, <span class="hljs-string">&quot;true&quot;</span>);<br></code></pre></td></tr></table></figure><blockquote><p><strong>enable.auto.commit</strong></p><p>If true the consumer’s offset will be periodically committed in the background.</p><p><strong>TYPE</strong>:boolean</p><p><strong>DEFAULT</strong>:true</p><p><a href="https://gitee.com/link?target=http://kafka.apache.org/0110/documentation/%23newconsumerconfigs">Source</a></p></blockquote><p>PS.我将Offset提交类比成数据库事务的提交。</p><h2 id="16-自定义拦截器API"><a href="#16-自定义拦截器API" class="headerlink" title="16.自定义拦截器API"></a>16.自定义拦截器API</h2><h4 id="16-1-拦截器原理"><a href="#16-1-拦截器原理" class="headerlink" title="16.1. 拦截器原理"></a>16.1. 拦截器原理</h4><p>Producer 拦截器(interceptor)是在 Kafka 0.10 版本被引入的，主要用于实现 clients 端的定制化控制逻辑。</p><p>对于 producer 而言， interceptor 使得用户在消息发送前以及 producer 回调逻辑前有机会对消息做一些定制化需求，比如<code>修改消息</code>等。同时， producer 允许用户指定多个 interceptor按序作用于同一条消息从而形成一个拦截链(interceptor chain)。 Intercetpor 的实现接口是<code>org.apache.kafka.clients.producer.ProducerInterceptor</code>，其定义的方法包括：</p><ul><li><code>configure(configs)</code>：获取配置信息和初始化数据时调用。</li><li><code>onSend(ProducerRecord)</code>：该方法封装进 KafkaProducer.send 方法中，即它运行在用户主线程中。 Producer 确保<strong>在消息被序列化以及计算分区前</strong>调用该方法。 用户可以在该方法中对消息做任何操作，但最好保证不要修改消息所属的 topic 和分区， 否则会影响目标分区的计算。</li><li><code>onAcknowledgement(RecordMetadata, Exception)</code>：<strong>该方法会在消息从 RecordAccumulator 成功发送到 Kafka Broker 之后，或者在发送过程中失败时调用</strong>。 并且通常都是在 producer 回调逻辑触发之前。 onAcknowledgement 运行在producer 的 IO 线程中，因此不要在该方法中放入很重的逻辑，否则会拖慢 producer 的消息发送效率。</li><li><code>close()</code>：关闭 interceptor，主要用于执行一些<strong>资源清理</strong>工作</li></ul><p>如前所述， interceptor 可能被运行在多个线程中，因此在具体实现时用户需要自行确保线程安全。另外<strong>倘若指定了多个 interceptor，则 producer 将按照指定顺序调用它们</strong>，并仅仅是捕获每个 interceptor 可能抛出的异常记录到错误日志中而非在向上传递。这在使用过程中要特别留意。</p><h4 id="16-2-自定义拦截器-代码"><a href="#16-2-自定义拦截器-代码" class="headerlink" title="16.2. 自定义拦截器(代码)"></a>16.2. 自定义拦截器(代码)</h4><p>(1)    需求</p><p>实现一个简单的双 interceptor 组成的拦截链。</p><blockquote><p>第一个 interceptor 会在消息发送前将时间戳信息加到消息 value 的最前部；    </p><p>第二个 interceptor 会在消息发送后更新成功发送消息数或失败发送消息数。</p></blockquote><p>(2)  案例实操</p><ul><li>增加时间戳拦截器</li></ul><p><a href="https://gitee.com/jallenkwong/LearnKafka/blob/master/src/main/java/com/lun/kafka/interceptor/TimeInterceptor.java">TimeInterceptor.java</a></p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-keyword">import</span> java.util.Map;<br><br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.ProducerInterceptor;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.RecordMetadata;<br><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TimeInterceptor</span> <span class="hljs-title">implements</span> <span class="hljs-title">ProducerInterceptor</span>&lt;<span class="hljs-title">String</span>, <span class="hljs-title">String</span>&gt; </span>&#123;<br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">configure</span>(<span class="hljs-params"><span class="hljs-built_in">Map</span>&lt;<span class="hljs-built_in">String</span>, ?&gt; configs</span>)</span> &#123;<br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> ProducerRecord&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt; <span class="hljs-function"><span class="hljs-title">onSend</span>(<span class="hljs-params">ProducerRecord&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt; record</span>)</span> &#123;<br><span class="hljs-comment">// 创建一个新的 record，把时间戳写入消息体的最前部</span><br><span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> ProducerRecord(record.topic(), record.partition(), record.timestamp(), record.key(),<br><span class="hljs-string">&quot;TimeInterceptor: &quot;</span> + System.currentTimeMillis() + <span class="hljs-string">&quot;,&quot;</span> + record.value().toString());<br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">close</span>(<span class="hljs-params"></span>)</span> &#123;<br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">onAcknowledgement</span>(<span class="hljs-params">RecordMetadata metadata, Exception exception</span>)</span> &#123;<br><span class="hljs-comment">// TODO Auto-generated method stub</span><br><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>增加时间戳拦截器</li></ul><p>统计发送消息成功和发送失败消息数，并在 producer 关闭时打印这两个计数器</p><p><a href="https://gitee.com/jallenkwong/LearnKafka/blob/master/src/main/java/com/lun/kafka/interceptor/CounterInterceptor.java">CounterInterceptor.java</a></p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-keyword">import</span> java.util.Map;<br><br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.ProducerInterceptor;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.RecordMetadata;<br><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CounterInterceptor</span> <span class="hljs-title">implements</span> <span class="hljs-title">ProducerInterceptor</span>&lt;<span class="hljs-title">String</span>, <span class="hljs-title">String</span>&gt;</span>&#123;<br><br><span class="hljs-keyword">private</span> int errorCounter = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">private</span> int successCounter = <span class="hljs-number">0</span>;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">configure</span>(<span class="hljs-params"><span class="hljs-built_in">Map</span>&lt;<span class="hljs-built_in">String</span>, ?&gt; configs</span>)</span> &#123;<br><span class="hljs-comment">// TODO Auto-generated method stub</span><br><br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> ProducerRecord&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt; <span class="hljs-function"><span class="hljs-title">onSend</span>(<span class="hljs-params">ProducerRecord&lt;<span class="hljs-built_in">String</span>, <span class="hljs-built_in">String</span>&gt; record</span>)</span> &#123;<br><span class="hljs-keyword">return</span> record;<br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">onAcknowledgement</span>(<span class="hljs-params">RecordMetadata metadata, Exception exception</span>)</span> &#123;<br><span class="hljs-comment">// 统计成功和失败的次数</span><br><span class="hljs-keyword">if</span> (exception == <span class="hljs-literal">null</span>) &#123;<br>successCounter++;<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>errorCounter++;<br>&#125;<br>&#125;<br><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">close</span>(<span class="hljs-params"></span>)</span> &#123;<br><span class="hljs-comment">// 保存结果</span><br>System.out.println(<span class="hljs-string">&quot;Successful sent: &quot;</span> + successCounter);<br>System.out.println(<span class="hljs-string">&quot;Failed sent: &quot;</span> + errorCounter);<br><br>&#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><ul><li>producer 主程序</li></ul><p><a href="https://gitee.com/jallenkwong/LearnKafka/blob/master/src/main/java/com/lun/kafka/producer/InterceptorProducer.java">InterceptorProducer.java</a></p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-keyword">import</span> java.util.ArrayList;<br><span class="hljs-keyword">import</span> java.util.List;<br><span class="hljs-keyword">import</span> java.util.Properties;<br><br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.KafkaProducer;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.Producer;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.ProducerConfig;<br><span class="hljs-keyword">import</span> org.apache.kafka.clients.producer.ProducerRecord;<br><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">InterceptorProducer</span> &#123;</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">String</span>[] args)</span> </span>&#123;<br><span class="hljs-comment">// 1 设置配置信息</span><br>Properties props = <span class="hljs-keyword">new</span> <span class="hljs-built_in">Properties</span>();<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;bootstrap.servers&quot;</span>, <span class="hljs-string">&quot;127.0.0.1:9092&quot;</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;acks&quot;</span>, <span class="hljs-string">&quot;all&quot;</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;retries&quot;</span>, <span class="hljs-number">3</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;batch.size&quot;</span>, <span class="hljs-number">16384</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;linger.ms&quot;</span>, <span class="hljs-number">1</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;buffer.memory&quot;</span>, <span class="hljs-number">33554432</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;key.serializer&quot;</span>,<br><span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);<br>props.<span class="hljs-built_in">put</span>(<span class="hljs-string">&quot;value.serializer&quot;</span>,<br><span class="hljs-string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);<br><span class="hljs-comment">//&lt;--------------------------------------------</span><br><span class="hljs-comment">// 2 构建拦截链</span><br>List&lt;<span class="hljs-keyword">String</span>&gt; interceptors = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();<br>interceptors.<span class="hljs-built_in">add</span>(<span class="hljs-string">&quot;com.lun.kafka.interceptor.TimeInterceptor&quot;</span>);<br>interceptors.<span class="hljs-built_in">add</span>(<span class="hljs-string">&quot;com.lun.kafka.interceptor.CounterInterceptor&quot;</span>);<br><br>props.<span class="hljs-built_in">put</span>(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);<br><br><span class="hljs-keyword">String</span> topic = <span class="hljs-string">&quot;test&quot;</span>;<br>Producer&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt; producer = <span class="hljs-keyword">new</span> KafkaProducer&lt;&gt;(props);<br><span class="hljs-comment">// 3 发送消息</span><br><span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++) &#123;<br>ProducerRecord&lt;<span class="hljs-keyword">String</span>, <span class="hljs-keyword">String</span>&gt; record = <span class="hljs-keyword">new</span> ProducerRecord&lt;&gt;(topic, <span class="hljs-string">&quot;message&quot;</span> + i);<br>producer.<span class="hljs-built_in">send</span>(record);<br>&#125;<br><br><span class="hljs-comment">// 4 一定要关闭 producer，这样才会调用 interceptor 的 close 方法</span><br>producer.<span class="hljs-built_in">close</span>();<br><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="16-3-拦截器-案例测试"><a href="#16-3-拦截器-案例测试" class="headerlink" title="16.3. 拦截器(案例测试)"></a>16.3. 拦截器(案例测试)</h4><p><img src="https://raw.githubusercontent.com/kusuzi/image-folder/master/Kafka/image.286oo9pc0ny8.webp" alt="image"></p><h2 id="17-Kafka面试题"><a href="#17-Kafka面试题" class="headerlink" title="17. Kafka面试题"></a>17. Kafka面试题</h2><ol><li>Kafka 中的 ISR(InSyncRepli)、 OSR(OutSyncRepli)、 AR(AllRepli)代表什么？</li><li>Kafka 中的 HW、 LEO 等分别代表什么？</li><li>Kafka 中是怎么体现消息顺序性的？</li><li>Kafka 中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？</li><li>Kafka 生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？</li><li>“消费组中的消费者个数如果超过 topic 的分区，那么就会有消费者消费不到数据”这句 话是否正确？</li><li>消费者提交消费位移时提交的是当前消费到的最新消息的 offset 还是 offset+1？</li><li>有哪些情形会造成重复消费？</li><li>那些情景会造成消息漏消费？</li><li>当你使用 kafka-topics.sh 创建（删除）了一个 topic 之后， Kafka 背后会执行什么逻辑？<ul><li>会在 zookeeper 中的/brokers/topics 节点下创建一个新的 topic 节点，如：/brokers/topics/first</li><li>触发 Controller 的监听程序</li><li>kafka Controller 负责 topic 的创建工作，并更新 metadata cache</li></ul></li><li>topic 的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？</li><li>topic 的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？</li><li>Kafka 有内部的 topic 吗？如果有是什么？有什么所用？</li><li>Kafka 分区分配的概念？</li><li>简述 Kafka 的日志目录结构？</li><li>如果我指定了一个 offset， Kafka Controller 怎么查找到对应的消息？</li><li>聊一聊 Kafka Controller 的作用？</li><li>Kafka 中有那些地方需要选举？这些地方的选举策略又有哪些？</li><li>失效副本是指什么？有那些应对措施？</li><li>Kafka 的哪些设计让它有如此高的性能？</li></ol>]]></content>
    
    
    <categories>
      
      <category>中间件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>learn</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySql</title>
    <link href="/2021/12/25/MySql/"/>
    <url>/2021/12/25/MySql/</url>
    
    <content type="html"><![CDATA[<p>本视频是按照<a href="https://www.bilibili.com/video/BV12b411K7Zu?from=search&seid=14241557604549366754&spm_id_from=333.337.0.0">尚硅谷</a>的相关教程所做的笔记😋。</p><h2 id="数据库的好处"><a href="#数据库的好处" class="headerlink" title="数据库的好处"></a>数据库的好处</h2><p>​    1.持久化数据到本地<br>​    2.可以实现结构化查询，方便管理<br>​    </p><h2 id="数据库相关概念"><a href="#数据库相关概念" class="headerlink" title="数据库相关概念"></a>数据库相关概念</h2><p>​    1、DB：数据库，保存一组有组织的数据的容器<br>​    2、DBMS：数据库管理系统，又称为数据库软件（产品），用于管理DB中的数据<br>​    3、SQL:结构化查询语言，用于和DBMS通信的语言</p><h2 id="数据库存储数据的特点"><a href="#数据库存储数据的特点" class="headerlink" title="数据库存储数据的特点"></a>数据库存储数据的特点</h2><p>​    1、将数据放到表中，表再放到库中<br>​    2、一个数据库中可以有多个表，每个表都有一个的名字，用来标识自己。表名具有唯一性。<br>​    3、表具有一些特性，这些特性定义了数据在表中如何存储，类似java中 “类”的设计。<br>​    4、表由列组成，我们也称为字段。所有表都是由一个或多个列组成的，每一列类似java 中的”属性”<br>​    5、表中的数据是按行存储的，每一行类似于java中的“对象”。</p><h2 id="一、MySQL产品的介绍和安装"><a href="#一、MySQL产品的介绍和安装" class="headerlink" title="一、MySQL产品的介绍和安装"></a>一、MySQL产品的介绍和安装</h2><h3 id="1-1-MySQL服务的启动和停止"><a href="#1-1-MySQL服务的启动和停止" class="headerlink" title="1.1 MySQL服务的启动和停止"></a>1.1 MySQL服务的启动和停止</h3><ul><li>方式一：计算机——右击管理——服务</li><li>方式二：通过管理员身份运行<br>​    net start 服务名（启动服务）<br>​    net stop 服务名（停止服务）</li></ul><h3 id="1-2-MySQL服务的登录和退出"><a href="#1-2-MySQL服务的登录和退出" class="headerlink" title="1.2 MySQL服务的登录和退出"></a>1.2 MySQL服务的登录和退出</h3><ul><li><p>方式一：通过mysql自带的客户端</p><pre><code>只限于root用户</code></pre></li><li><p>方式二：通过windows自带的客户端</p><pre><code>登录：mysql 【-h主机名 -P端口号 】-u用户名 -p密码</code></pre><p>  退出：exit或ctrl+C</p></li></ul><h3 id="1-3-MySQL的常见命令"><a href="#1-3-MySQL的常见命令" class="headerlink" title="1.3 MySQL的常见命令"></a>1.3 MySQL的常见命令</h3><pre><code>1.查看当前所有的数据库show databases;2.打开指定的库use 库名3.查看当前库的所有表show tables;4.查看其它库的所有表show tables from 库名;5.创建表create table 表名(    列名 列类型,    列名 列类型，    。。。);6.查看表结构desc 表名;7.查看服务器的版本方式一：登录到mysql服务端select version();方式二：没有登录到mysql服务端mysql --version或mysql --V</code></pre><h3 id="1-4MySQL的语法规范"><a href="#1-4MySQL的语法规范" class="headerlink" title="1.4MySQL的语法规范"></a>1.4MySQL的语法规范</h3><p>​    1.不区分大小写,但建议关键字大写，表名、列名小写<br>​    2.每条命令最好用分号结尾<br>​    3.每条命令根据需要，可以进行缩进 或换行<br>​    4.注释<br>​        单行注释：#注释文字<br>​        单行注释：– 注释文字<br>​        多行注释：/* 注释文字  */<br>​        </p><h3 id="1-5-SQL的语言分类"><a href="#1-5-SQL的语言分类" class="headerlink" title="1.5 SQL的语言分类"></a>1.5 SQL的语言分类</h3><pre><code>DQL（Data Query Language）：数据查询语言    select DML(Data Manipulate Language):数据操作语言    insert 、update、deleteDDL（Data Define Languge）：数据定义语言    create、drop、alterTCL（Transaction Control Language）：事务控制语言    commit、rollback</code></pre><h2 id="二、DQL语言的学习"><a href="#二、DQL语言的学习" class="headerlink" title="二、DQL语言的学习"></a>二、DQL语言的学习</h2><h3 id="进阶1：基础查询"><a href="#进阶1：基础查询" class="headerlink" title="进阶1：基础查询"></a>进阶1：基础查询</h3><p>​    语法：<br>​    <em>SELECT 要查询的东西</em><br><em>​    【FROM 表名】;</em></p><pre><code>类似于Java中 :System.out.println(要打印的东西);特点：①通过select查询完的结果 ，是一个虚拟的表格，不是真实存在② 要查询的东西 可以是常量值、可以是表达式、可以是字段、可以是函数</code></pre><h3 id="进阶2：条件查询"><a href="#进阶2：条件查询" class="headerlink" title="进阶2：条件查询"></a>进阶2：条件查询</h3><p>​    条件查询：根据条件过滤原始表的数据，查询到想要的数据<br><em>​    语法：</em><br><em>​    select</em><br><em>​        要查询的字段|表达式|常量值|函数</em><br><em>​    from</em><br><em>​        表</em><br><em>​    where</em><br><em>​        条件 ;</em></p><pre><code>分类：一、条件表达式    示例：salary&gt;10000    条件运算符：    &gt; &lt; &gt;= &lt;= = != &lt;&gt;二、逻辑表达式示例：salary&gt;10000 &amp;&amp; salary&lt;20000逻辑运算符：    and（&amp;&amp;）:两个条件如果同时成立，结果为true，否则为false    or(||)：两个条件只要有一个成立，结果为true，否则为false    not(!)：如果条件成立，则not后为false，否则为true三、模糊查询示例：last_name like &#39;a%&#39;</code></pre><h3 id="进阶3：排序查询"><a href="#进阶3：排序查询" class="headerlink" title="进阶3：排序查询"></a>进阶3：排序查询</h3><pre><code>语法：select    要查询的东西from    表where     条件order by 排序的字段|表达式|函数|别名 【asc|desc】</code></pre><h3 id="进阶4：常见函数"><a href="#进阶4：常见函数" class="headerlink" title="进阶4：常见函数"></a>进阶4：常见函数</h3><pre><code>一、单行函数1、字符函数    concat拼接    substr截取子串    upper转换成大写    lower转换成小写    trim去前后指定的空格和字符    ltrim去左边空格    rtrim去右边空格    replace替换    lpad左填充    rpad右填充    instr返回子串第一次出现的索引    length 获取字节个数2、数学函数    round 四舍五入    rand 随机数    floor向下取整    ceil向上取整    mod取余    truncate截断3、日期函数    now当前系统日期+时间    curdate当前系统日期    curtime当前系统时间    str_to_date 将字符转换成日期    date_format将日期转换成字符4、流程控制函数    if 处理双分支    case语句 处理多分支        情况1：处理等值判断        情况2：处理条件判断    5、其他函数    version版本    database当前库    user当前连接用户</code></pre><p>​    </p><p>二、分组函数</p><pre><code>    sum 求和    max 最大值    min 最小值    avg 平均值    count 计数    特点：    1、以上五个分组函数都忽略null值，除了count(*)    2、sum和avg一般用于处理数值型        max、min、count可以处理任何数据类型    3、都可以搭配distinct使用，用于统计去重后的结果    4、count的参数可以支持：        字段、*、常量值，一般放1       建议使用 count(*)</code></pre><h3 id="进阶5：分组查询"><a href="#进阶5：分组查询" class="headerlink" title="进阶5：分组查询"></a>进阶5：分组查询</h3><pre><code>语法：select 查询的字段，分组函数from 表group by 分组的字段特点：1、可以按单个字段分组2、和分组函数一同查询的字段最好是分组后的字段3、分组筛选               针对的表         位置                关键字分组前筛选：        原始表        group by的前面        where分组后筛选：    分组后的结果集     group by的后面     having4、可以按多个字段分组，字段之间用逗号隔开5、可以支持排序6、having后可以支持别名</code></pre><h3 id="进阶6：多表连接查询"><a href="#进阶6：多表连接查询" class="headerlink" title="进阶6：多表连接查询"></a>进阶6：多表连接查询</h3><pre><code>笛卡尔乘积：如果连接条件省略或无效则会出现解决办法：添加上连接条件</code></pre><p>一、传统模式下的连接 ：等值连接——非等值连接</p><pre><code>1.等值连接的结果 = 多个表的交集2.n表连接，至少需要n-1个连接条件3.多个表不分主次，没有顺序要求4.一般为表起别名，提高阅读性和性能</code></pre><p>二、sql99语法：通过<strong>join</strong>关键字实现连接</p><pre><code>含义：1999年推出的sql语法支持：等值连接、非等值连接 （内连接）外连接交叉连接语法：select 字段，...from 表1【inner|left outer|right outer|cross】join 表2 on  连接条件【inner|left outer|right outer|cross】join 表3 on  连接条件【where 筛选条件】【group by 分组字段】【having 分组后的筛选条件】【order by 排序的字段或表达式】好处：语句上，连接条件和筛选条件实现了分离，简洁明了！</code></pre><p>​<br>三、自连接</p><p>案例：查询员工名和直接上级的名称</p><p>sql99</p><pre><code>SELECT e.last_name,m.last_nameFROM employees eJOIN employees m ON e.`manager_id`=m.`employee_id`;</code></pre><p>sql92</p><pre><code>SELECT e.last_name,m.last_nameFROM employees e,employees m WHERE e.`manager_id`=m.`employee_id`;</code></pre><h3 id="进阶7：子查询"><a href="#进阶7：子查询" class="headerlink" title="进阶7：子查询"></a>进阶7：子查询</h3><p>含义：</p><pre><code>一条查询语句中又嵌套了另一条完整的select语句，其中被嵌套的select语句，称为子查询或内查询在外面的查询语句，称为主查询或外查询</code></pre><p>特点：</p><pre><code>1、子查询都放在小括号内2、子查询可以放在from后面、select后面、where后面、having后面，但一般放在条件的右侧3、子查询优先于主查询执行，主查询使用了子查询的执行结果4、子查询根据查询结果的行数不同分为以下两类：① 单行子查询    结果集只有一行    一般搭配单行操作符使用：&gt; &lt; = &lt;&gt; &gt;= &lt;=     非法使用子查询的情况：    a、子查询的结果为一组值    b、子查询的结果为空    ② 多行子查询    结果集有多行    一般搭配多行操作符使用：any、all、in、not in    in： 属于子查询结果中的任意一个就行    any和all往往可以用其他查询代替</code></pre><h3 id="进阶8：分页查询"><a href="#进阶8：分页查询" class="headerlink" title="进阶8：分页查询"></a>进阶8：分页查询</h3><p>应用场景：</p><pre><code>实际的web项目中需要根据用户的需求提交对应的分页查询的sql语句</code></pre><p>语法：</p><pre><code>select 字段|表达式,...from 表【where 条件】【group by 分组字段】【having 条件】【order by 排序的字段】limit 【起始的条目索引，】条目数;</code></pre><p>特点：</p><pre><code>1.起始条目索引从0开始2.limit子句放在查询语句的最后3.公式：select * from  表 limit （page-1）*sizePerPage,sizePerPage假如:每页显示条目数sizePerPage要显示的页数 page</code></pre><h3 id="进阶9：联合查询"><a href="#进阶9：联合查询" class="headerlink" title="进阶9：联合查询"></a>进阶9：联合查询</h3><p>引入：<br>    union 联合、合并</p><p>语法：</p><pre><code>select 字段|常量|表达式|函数 【from 表】 【where 条件】 union 【all】select 字段|常量|表达式|函数 【from 表】 【where 条件】 union 【all】select 字段|常量|表达式|函数 【from 表】 【where 条件】 union  【all】.....select 字段|常量|表达式|函数 【from 表】 【where 条件】</code></pre><p>特点：</p><pre><code>1、多条查询语句的查询的列数必须是一致的2、多条查询语句的查询的列的类型几乎相同3、union代表去重，union all代表不去重</code></pre><h2 id="三、DML语言"><a href="#三、DML语言" class="headerlink" title="三、DML语言"></a>三、DML语言</h2><h3 id="3-1-插入"><a href="#3-1-插入" class="headerlink" title="3.1 插入"></a>3.1 插入</h3><p>语法：<br>    insert into 表名(字段名，…)<br>    values(值1，…);</p><p>特点：</p><pre><code>1、字段类型和值类型一致或兼容，而且一一对应2、可以为空的字段，可以不用插入值，或用null填充3、不可以为空的字段，必须插入值4、字段个数和值的个数必须一致5、字段可以省略，但默认所有字段，并且顺序和表中的存储顺序一致</code></pre><h3 id="3-2-修改"><a href="#3-2-修改" class="headerlink" title="3.2 修改"></a>3.2 修改</h3><p>修改单表语法：</p><pre><code>update 表名 set 字段=新值,字段=新值【where 条件】</code></pre><p>修改多表语法：</p><pre><code>update 表1 别名1,表2 别名2set 字段=新值，字段=新值where 连接条件and 筛选条件</code></pre><h3 id="3-3-删除"><a href="#3-3-删除" class="headerlink" title="3.3 删除"></a>3.3 删除</h3><ul><li>方式1：delete语句 </li></ul><pre><code>单表的删除： ★delete from 表名 【where 筛选条件】多表的删除：delete 别名1，别名2from 表1 别名1，表2 别名2where 连接条件and 筛选条件;</code></pre><ul><li>方式2：truncate语句</li></ul><pre><code>truncate table 表名</code></pre><ul><li><p>两种方式的区别【面试题】    </p><p>#1.truncate不能加where条件，而delete可以加where条件</p><p>#2.truncate的效率高一丢丢</p><p>#3.truncate 删除带自增长的列的表后，如果再插入数据，数据从1开始<br>#delete 删除带自增长列的表后，如果再插入数据，数据从上一次的断点处开始</p><p>#4.truncate删除不能回滚，delete删除可以回滚</p></li></ul><h2 id="四、DDL语句"><a href="#四、DDL语句" class="headerlink" title="四、DDL语句"></a>四、DDL语句</h2><h3 id="4-1-库的管理"><a href="#4-1-库的管理" class="headerlink" title="4.1 库的管理"></a>4.1 库的管理</h3><pre><code>一、创建库create database 库名二、删除库drop database 库名</code></pre><h3 id="4-2-表的管理："><a href="#4-2-表的管理：" class="headerlink" title="4.2 表的管理："></a>4.2 表的管理：</h3><h4 id="4-2-1-创建表"><a href="#4-2-1-创建表" class="headerlink" title="4.2.1. 创建表"></a>4.2.1. 创建表</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs mysql">CREATE TABLE IF NOT EXISTS stuinfo(<br>stuId INT,<br>stuName VARCHAR(20),<br>gender CHAR,<br>bornDate DATETIME<br>);<br>DESC studentinfo;<br></code></pre></td></tr></table></figure><p>​    </p><h4 id="4-2-2-修改表-alter"><a href="#4-2-2-修改表-alter" class="headerlink" title="4.2.2.修改表 alter"></a>4.2.2.修改表 alter</h4><pre><code>语法：ALTER TABLE 表名 ADD|MODIFY|DROP|CHANGE COLUMN 字段名 【字段类型】;</code></pre><h5 id="①修改字段名"><a href="#①修改字段名" class="headerlink" title="①修改字段名"></a>①修改字段名</h5><pre><code>ALTER TABLE studentinfo CHANGE  COLUMN sex gender CHAR;</code></pre><h5 id="②修改表名"><a href="#②修改表名" class="headerlink" title="②修改表名"></a>②修改表名</h5><pre><code>ALTER TABLE stuinfo RENAME [TO]  studentinfo;</code></pre><h5 id="③修改字段类型和列级约束"><a href="#③修改字段类型和列级约束" class="headerlink" title="③修改字段类型和列级约束"></a>③修改字段类型和列级约束</h5><pre><code>ALTER TABLE studentinfo MODIFY COLUMN borndate DATE ;    </code></pre><h5 id="④添加字段"><a href="#④添加字段" class="headerlink" title="④添加字段"></a>④添加字段</h5><pre><code>ALTER TABLE studentinfo ADD COLUMN email VARCHAR(20) first;</code></pre><h5 id="⑤删除字段"><a href="#⑤删除字段" class="headerlink" title="⑤删除字段"></a>⑤删除字段</h5><pre><code>ALTER TABLE studentinfo DROP COLUMN email;</code></pre><h4 id="4-2-3-删除表"><a href="#4-2-3-删除表" class="headerlink" title="4.2.3.删除表"></a>4.2.3.删除表</h4><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">DROP</span> <span class="hljs-keyword">TABLE</span> [<span class="hljs-keyword">IF</span> <span class="hljs-keyword">EXISTS</span>] 表名;<br></code></pre></td></tr></table></figure><h2 id="五、常见数据类型"><a href="#五、常见数据类型" class="headerlink" title="五、常见数据类型"></a>五、常见数据类型</h2><pre><code>整型：    小数：    浮点型    定点型字符型：日期型：Blob类型：</code></pre><h2 id="六、常见约束"><a href="#六、常见约束" class="headerlink" title="六、常见约束"></a>六、常见约束</h2><pre><code>NOT NULLDEFAULTUNIQUECHECKPRIMARY KEYFOREIGN KEY</code></pre><h2 id="七、数据库事务"><a href="#七、数据库事务" class="headerlink" title="七、数据库事务"></a>七、数据库事务</h2><p>含义</p><p>​    通过一组逻辑操作单元（一组DML——sql语句），将数据从一种状态切换到另外一种状态</p><h3 id="7-1-特点"><a href="#7-1-特点" class="headerlink" title="7.1 特点"></a>7.1 特点</h3><p>原子性：要么都执行，要么都回滚<br>一致性：保证数据的状态操作前和操作后保持一致<br>隔离性：多个事务同时操作相同数据库的同一个数据时，一个事务的执行不受另外一个事务的干扰<br>持久性：一个事务一旦提交，则数据将持久化到本地，除非其他事务对其进行修改</p><h3 id="7-2-相关步骤："><a href="#7-2-相关步骤：" class="headerlink" title="7.2 相关步骤："></a>7.2 相关步骤：</h3><pre><code>1、开启事务2、编写事务的一组逻辑操作单元（多条sql语句）3、提交事务或回滚事务</code></pre><h3 id="7-3-事务的分类："><a href="#7-3-事务的分类：" class="headerlink" title="7.3 事务的分类："></a>7.3 事务的分类：</h3><p>隐式事务，没有明显的开启和结束事务的标志</p><pre><code>比如insert、update、delete语句本身就是一个事务</code></pre><p>显式事务，具有明显的开启和结束事务的标志</p><pre><code>    1、开启事务    取消自动提交事务的功能        2、编写事务的一组逻辑操作单元（多条sql语句）    insert    update    delete        3、提交事务或回滚事务</code></pre><h3 id="7-4-使用到的关键字"><a href="#7-4-使用到的关键字" class="headerlink" title="7.4 使用到的关键字"></a>7.4 使用到的关键字</h3><pre><code>set autocommit=0;start transaction;commit;rollback;savepoint  断点commit to 断点rollback to 断点</code></pre><h3 id="7-5-事务的隔离级别"><a href="#7-5-事务的隔离级别" class="headerlink" title="7.5 事务的隔离级别:"></a>7.5 事务的隔离级别:</h3><p>事务并发问题如何发生？</p><pre><code>当多个事务同时操作同一个数据库的相同数据时</code></pre><p>事务的并发问题有哪些？</p><pre><code>脏读：一个事务读取到了另外一个事务未提交的数据不可重复读：同一个事务中，多次读取到的数据不一致幻读：一个事务读取数据时，另外一个事务进行更新，导致第一个事务读取到了没有更新的数据</code></pre><p>如何避免事务的并发问题？</p><pre><code>通过设置事务的隔离级别1、READ UNCOMMITTED2、READ COMMITTED 可以避免脏读3、REPEATABLE READ 可以避免脏读、不可重复读和一部分幻读4、SERIALIZABLE可以避免脏读、不可重复读和幻读</code></pre><p>设置隔离级别：</p><pre><code>set session|global  transaction isolation level 隔离级别名;</code></pre><p>查看隔离级别：</p><pre><code>select @@tx_isolation;</code></pre><h2 id="八、视图"><a href="#八、视图" class="headerlink" title="八、视图"></a>八、视图</h2><p>含义：理解成一张虚拟的表</p><h3 id="8-1-视图和表的区别："><a href="#8-1-视图和表的区别：" class="headerlink" title="8.1 视图和表的区别："></a>8.1 视图和表的区别：</h3><table><thead><tr><th></th><th>使用方式</th><th>占用物理空间</th></tr></thead><tbody><tr><td>视图</td><td>完全相同</td><td>不占用，仅仅保存的是sql逻辑</td></tr><tr><td>表</td><td>完全相同</td><td>占用</td></tr></tbody></table><h3 id="8-2-视图的好处："><a href="#8-2-视图的好处：" class="headerlink" title="8.2 视图的好处："></a>8.2 视图的好处：</h3><pre><code>1、sql语句提高重用性，效率高2、和表实现了分离，提高了安全性</code></pre><h3 id="8-3-视图的创建"><a href="#8-3-视图的创建" class="headerlink" title="8.3 视图的创建"></a>8.3 视图的创建</h3><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs n1ql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">VIEW</span>  视图名<br><span class="hljs-keyword">AS</span><br>查询语句;<br></code></pre></td></tr></table></figure><h3 id="8-4-视图的增删改查"><a href="#8-4-视图的增删改查" class="headerlink" title="8.4 视图的增删改查"></a>8.4 视图的增删改查</h3><p>​    1、查看视图的数据 ★</p><pre><code>SELECT * FROM my_v4;SELECT * FROM my_v1 WHERE last_name=&#39;Partners&#39;;2、插入视图的数据INSERT INTO my_v4(last_name,department_id) VALUES(&#39;虚竹&#39;,90);3、修改视图的数据UPDATE my_v4 SET last_name =&#39;梦姑&#39; WHERE last_name=&#39;虚竹&#39;;4、删除视图的数据DELETE FROM my_v4;</code></pre><h3 id="8-5-某些视图不能更新"><a href="#8-5-某些视图不能更新" class="headerlink" title="8.5 某些视图不能更新"></a>8.5 某些视图不能更新</h3><p>​    包含以下关键字的sql语句：分组函数、distinct、group  by、having、union或者union all<br>​    常量视图<br>​    Select中包含子查询<br>​    join<br>​    from一个不能更新的视图<br>​    where子句的子查询引用了from子句中的表</p><h3 id="8-6-视图逻辑的更新"><a href="#8-6-视图逻辑的更新" class="headerlink" title="8.6 视图逻辑的更新"></a>8.6 视图逻辑的更新</h3><pre><code>#方式一：CREATE OR REPLACE VIEW test_v7ASSELECT last_name FROM employeesWHERE employee_id&gt;100;#方式二:ALTER VIEW test_v7ASSELECT employee_id FROM employees;SELECT * FROM test_v7;</code></pre><h3 id="8-7-视图的删除"><a href="#8-7-视图的删除" class="headerlink" title="8.7 视图的删除"></a>8.7 视图的删除</h3><pre><code>DROP VIEW test_v1,test_v2,test_v3;</code></pre><h3 id="8-8-视图结构的查看"><a href="#8-8-视图结构的查看" class="headerlink" title="8.8 视图结构的查看"></a>8.8 视图结构的查看</h3><pre><code>DESC test_v7;SHOW CREATE VIEW test_v7;</code></pre><h2 id="九、存储过程"><a href="#九、存储过程" class="headerlink" title="九、存储过程"></a>九、存储过程</h2><p>含义：一组经过预先编译的sql语句的集合<br>好处：</p><pre><code>1、提高了sql语句的重用性，减少了开发程序员的压力2、提高了效率3、减少了传输次数</code></pre><p>分类：</p><pre><code>1、无返回无参2、仅仅带in类型，无返回有参3、仅仅带out类型，有返回无参4、既带in又带out，有返回有参5、带inout，有返回有参注意：in、out、inout都可以在一个存储过程中带多个</code></pre><h3 id="9-1-创建存储过程"><a href="#9-1-创建存储过程" class="headerlink" title="9.1 创建存储过程"></a>9.1 创建存储过程</h3><p>语法：</p><pre><code>create procedure 存储过程名(in|out|inout 参数名  参数类型,...)begin    存储过程体end</code></pre><p>类似于方法：</p><pre><code>修饰符 返回类型 方法名(参数类型 参数名,...)&#123;    方法体;&#125;</code></pre><p>注意</p><pre><code>1、需要设置新的结束标记delimiter 新的结束标记示例：delimiter $CREATE PROCEDURE 存储过程名(IN|OUT|INOUT 参数名  参数类型,...)BEGIN    sql语句1;    sql语句2;END $2、存储过程体中可以有多条sql语句，如果仅仅一条sql语句，则可以省略begin end3、参数前面的符号的意思in:该参数只能作为输入 （该参数不能做返回值）out：该参数只能作为输出（该参数只能做返回值）inout：既能做输入又能做输出</code></pre><h3 id="9-2-调用存储过程"><a href="#9-2-调用存储过程" class="headerlink" title="9.2 调用存储过程"></a>9.2 调用存储过程</h3><p>​    call 存储过程名(实参列表)</p><h2 id="十、函数"><a href="#十、函数" class="headerlink" title="十、函数"></a>十、函数</h2><h3 id="10-1-创建函数"><a href="#10-1-创建函数" class="headerlink" title="10.1 创建函数"></a>10.1 创建函数</h3><p>学过的函数：LENGTH、SUBSTR、CONCAT等<br>语法：</p><pre><code>CREATE FUNCTION 函数名(参数名 参数类型,...) RETURNS 返回类型BEGIN    函数体END</code></pre><h3 id="10-2-调用函数"><a href="#10-2-调用函数" class="headerlink" title="10.2  调用函数"></a>10.2  调用函数</h3><p>​    SELECT 函数名（实参列表）</p><h3 id="10-3-函数和存储过程的区别"><a href="#10-3-函数和存储过程的区别" class="headerlink" title="10.3 函数和存储过程的区别"></a>10.3 函数和存储过程的区别</h3><table><thead><tr><th></th><th>关键字</th><th>调用语法</th><th>返回值</th><th>应用场景</th></tr></thead><tbody><tr><td>函数</td><td>FUNCTION</td><td>SELECT</td><td>函数()    只能是一个</td><td>一般用于查询结果为一个值并返回时，当有返回值而且仅仅一个</td></tr><tr><td>存储过程</td><td>PROCEDURE</td><td>CALL</td><td>存储过程()    可以有0个或多个</td><td>一般用于更新</td></tr></tbody></table><h2 id="十一、流程控制结构"><a href="#十一、流程控制结构" class="headerlink" title="十一、流程控制结构"></a>十一、流程控制结构</h2><h3 id="11-1-系统变量"><a href="#11-1-系统变量" class="headerlink" title="11.1 系统变量"></a>11.1 系统变量</h3><p>一、全局变量</p><p>作用域：针对于所有会话（连接）有效，但不能跨重启</p><pre><code>查看所有全局变量SHOW GLOBAL VARIABLES;查看满足条件的部分系统变量SHOW GLOBAL VARIABLES LIKE &#39;%char%&#39;;查看指定的系统变量的值SELECT @@global.autocommit;为某个系统变量赋值SET @@global.autocommit=0;SET GLOBAL autocommit=0;</code></pre><p>二、会话变量</p><p>作用域：针对于当前会话（连接）有效</p><pre><code>查看所有会话变量SHOW SESSION VARIABLES;查看满足条件的部分会话变量SHOW SESSION VARIABLES LIKE &#39;%char%&#39;;查看指定的会话变量的值SELECT @@autocommit;SELECT @@session.tx_isolation;为某个会话变量赋值SET @@session.tx_isolation=&#39;read-uncommitted&#39;;SET SESSION tx_isolation=&#39;read-committed&#39;;</code></pre><h3 id="11-2-自定义变量"><a href="#11-2-自定义变量" class="headerlink" title="11.2 自定义变量"></a>11.2 自定义变量</h3><h4 id="11-2-1-用户变量"><a href="#11-2-1-用户变量" class="headerlink" title="11.2.1 用户变量"></a>11.2.1 用户变量</h4><p>声明并初始化：</p><pre><code>SET @变量名=值;SET @变量名:=值;SELECT @变量名:=值;</code></pre><p>赋值：</p><pre><code>方式一：一般用于赋简单的值SET 变量名=值;SET 变量名:=值;SELECT 变量名:=值;方式二：一般用于赋表 中的字段值SELECT 字段名或表达式 INTO 变量FROM 表;</code></pre><p>使用：</p><pre><code>select @变量名;</code></pre><h4 id="11-2-2-局部变量"><a href="#11-2-2-局部变量" class="headerlink" title="11.2.2 局部变量"></a>11.2.2 局部变量</h4><p>声明：</p><pre><code>declare 变量名 类型 【default 值】;</code></pre><p>赋值：</p><pre><code>方式一：一般用于赋简单的值SET 变量名=值;SET 变量名:=值;SELECT 变量名:=值;方式二：一般用于赋表 中的字段值SELECT 字段名或表达式 INTO 变量FROM 表;</code></pre><p>使用：</p><pre><code>select 变量名</code></pre><h4 id="12-2-3-二者的区别："><a href="#12-2-3-二者的区别：" class="headerlink" title="12.2.3 二者的区别："></a>12.2.3 二者的区别：</h4><pre><code>        作用域            定义位置        语法</code></pre><p>用户变量    当前会话        会话的任何地方        加@符号，不用指定类型<br>局部变量    定义它的BEGIN END中     BEGIN END的第一句话    一般不用加@,需要指定类型</p><h2 id="十二、分支"><a href="#十二、分支" class="headerlink" title="十二、分支"></a>十二、分支</h2><h3 id="12-1-if函数"><a href="#12-1-if函数" class="headerlink" title="12.1 if函数"></a>12.1 if函数</h3><p>​    语法：if(条件，值1，值2)<br>​    特点：可以用在任何位置</p><h3 id="12-2-case语句"><a href="#12-2-case语句" class="headerlink" title="12.2 case语句"></a>12.2 case语句</h3><p>语法：</p><pre><code>情况一：类似于switchcase 表达式when 值1 then 结果1或语句1(如果是语句，需要加分号) when 值2 then 结果2或语句2(如果是语句，需要加分号)...else 结果n或语句n(如果是语句，需要加分号)end 【case】（如果是放在begin end中需要加上case，如果放在select后面不需要）情况二：类似于多重ifcase when 条件1 then 结果1或语句1(如果是语句，需要加分号) when 条件2 then 结果2或语句2(如果是语句，需要加分号)...else 结果n或语句n(如果是语句，需要加分号)end 【case】（如果是放在begin end中需要加上case，如果放在select后面不需要）</code></pre><p>特点：<br>    可以用在任何位置</p><h3 id="12-3-if-elseif语句"><a href="#12-3-if-elseif语句" class="headerlink" title="12.3 if elseif语句"></a>12.3 if elseif语句</h3><p>语法：</p><pre><code>if 情况1 then 语句1;elseif 情况2 then 语句2;...else 语句n;end if;</code></pre><p>特点：<br>    只能用在<strong>begin end</strong>中！！！！！！！！！！！！！！！</p><p>三者比较：<br>            应用场合<br>    if函数        简单双分支<br>    case结构    等值判断 的多分支<br>    if结构        区间判断 的多分支</p><h3 id="12-4-循环"><a href="#12-4-循环" class="headerlink" title="12.4 循环"></a>12.4 循环</h3><p>语法：</p><pre><code>【标签：】WHILE 循环条件  DO    循环体END WHILE 【标签】;</code></pre><p>特点：</p><pre><code>只能放在BEGIN END里面如果要搭配leave跳转语句，需要使用标签，否则可以不用标签leave类似于java中的break语句，跳出所在循环！！！</code></pre>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>learn</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SpringBoot</title>
    <link href="/2021/12/15/SpringBoot/"/>
    <url>/2021/12/15/SpringBoot/</url>
    
    <content type="html"><![CDATA[<p>本篇文章是根据<a href="https://www.bilibili.com/video/BV15b4y1a7yG?p=1">黑马程序员SpringBoot2全套视频教程</a>出品的视频，学习所做的笔记🐰。</p><p>视频发布时间：2021.10.26</p><h1 id="1-快速上手SpringBoot"><a href="#1-快速上手SpringBoot" class="headerlink" title="1. 快速上手SpringBoot"></a>1. 快速上手SpringBoot</h1><h2 id="1-1-SpringBoot入门程序开发"><a href="#1-1-SpringBoot入门程序开发" class="headerlink" title="1.1 SpringBoot入门程序开发"></a>1.1 SpringBoot入门程序开发</h2><ul><li>SpringBoot是由Pivotal团队提供的全新框架，其设计目的是用来<font color='red'>简化</font>Spring应用的<font color='red'>初始搭建</font>以及<font color='red'>开发过程</font></li></ul><h3 id="1-1-1-S2pringBoot入门程序"><a href="#1-1-1-S2pringBoot入门程序" class="headerlink" title="1.1.1 S2pringBoot入门程序"></a>1.1.1 S2pringBoot入门程序</h3><p>（1）创建新模块，选择Spring Initializr，并配置模块相关基础信息</p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/image.png" alt="image" style="zoom: 67%;" /><p>2）选择当前模块需要使用的技术集</p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/image.6vp7mfozcus0.png" alt="image" style="zoom: 80%;" /><p>3）开发控制器类</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/image.75euv8hmxiw0.png" alt="image"></p><p>4）运行自动生成的Application类</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/image.613hxfau7o00.png" alt="image"></p><h3 id="1-1-2-入门案列"><a href="#1-1-2-入门案列" class="headerlink" title="1.1.2 入门案列"></a>1.1.2 入门案列</h3><ul><li><p>最简SpringBoot程序所包含的基础文件</p><ul><li>pom.xml文件</li><li> Application类</li></ul></li><li><p>Spring程序与SpringBoot程序对比</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/image.1rlayaopp3y8.png" alt="image"></p><p>注意：基于idea开发SpringBoot程序需要确保<strong>联网</strong>且能够加载到程序框架结构</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/image.42687dug5hk0.png" alt="image"></p></li></ul><h3 id="1-1-3-隐藏指定文件-文件夹"><a href="#1-1-3-隐藏指定文件-文件夹" class="headerlink" title="1.1.3 隐藏指定文件/文件夹"></a>1.1.3 隐藏指定文件/文件夹</h3><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/image.5l74k9ymyp40.png" alt="image"></p><p>Idea中隐藏指定文件或指定类型文件</p><ul><li>Setting → File Types → Ignored Files and Folders</li><li> 输入要隐藏的文件名，支持*号通配符 </li><li>回车确认添加</li></ul><h2 id="1-2-SpringBoot简介"><a href="#1-2-SpringBoot简介" class="headerlink" title="1.2 SpringBoot简介"></a>1.2 SpringBoot简介</h2><p>SpringBoot是由Pivotal团队提供的全新框架，其设计目的是用来简化Spring应用的初始搭建以及开发过程</p><ul><li>Spring程序缺点<br> 依赖设置繁琐<br> 配置繁琐</li><li>SpringBoot程序优点<br> 起步依赖（简化依赖配置）<br> 自动配置（简化常用工程相关配置）<br> 辅助功能（内置服务器，……</li></ul><ol><li><p>简化依赖配置</p><p><strong>parent</strong></p><ul><li><p>开发SpringBoot程序要继承spring-boot-starter-parent</p></li><li><p>spring-boot-starter-parent中定义了若干个依赖管理</p></li><li><p>继承parent模块可以避免多个依赖使用相同技术时出现依赖版本冲突</p></li><li><p>继承parent的形式也可以采用引入依赖的形式实现效果</p></li><li><p>定义了若干个坐标版本号（依赖管理，而非依赖），以达到<font color='red'>减少依赖冲突</font>的目的</p></li><li><p>spring-boot-starter-parent各版本间存在着诸多坐标版本不同</p></li></ul><p><strong>starter</strong></p><ul><li>  SpringBoot中常见项目名称，定义了当前项目使用的所有依赖坐标，以达到<font color='red'>减少依赖配置</font>的目的</li><li>开发SpringBoot程序需要导入坐标时通常导入对应的starter</li><li>每个不同的starter根据功能不同，通常包含多个依赖坐标</li><li>使用starter可以实现快速配置的效果，达到简化配置的目的</li></ul><p><strong>实际开发</strong></p><ul><li>使用任意坐标时，仅书写GAV中的G和A，V由SpringBoot提供，除非SpringBoot未提供对应版本V</li><li>如发生坐标错误，再指定Version（要小心版本冲突）</li></ul></li><li><p>自动配置</p><p><strong>引导类</strong></p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs typescript"><span class="hljs-meta">@SpringBootApplication</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Quickstart01Application</span> </span>&#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-built_in">void</span> <span class="hljs-function"><span class="hljs-title">main</span>(<span class="hljs-params"><span class="hljs-built_in">String</span>[] args</span>)</span> &#123;<br>        SpringApplication.run(Quickstart01Application.class, args);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>SpringBoot的引导类是Boot工程的执行入口，运行main方法就可以启动项目</li><li>SpringBoot工程运行后初始化Spring容器，扫描引导类所在包加载bean</li></ul></li><li><p>辅助功能</p><p><strong>内嵌tomcat</strong></p><ol><li>内嵌Tomcat服务器是SpringBoot辅助功能之一</li><li>内嵌Tomcat工作原理是将Tomcat服务器作为对象运行，并将该对象交给Spring容器管理</li><li>变更内嵌服务器思想是去除现有服务器，添加全新的服务器</li></ol><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/image.19yep7mcer4w.png" alt="image"></p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/image.5e7uh7t7quo0.png" alt="image"></p></li></ol><ul><li><p>Jetty比Tomcat更轻量级，可扩展性更强（相较于Tomcat），谷歌应用引擎（GAE）已经全面切换为Jetty</p><p>内置服务器的比较：</p><table><thead><tr><th>tomcat(默认)</th><th align="left">apache出品，粉丝多，应用面广，负载了若干较重的组件</th></tr></thead><tbody><tr><td>jetty</td><td align="left">更轻量级，负载性能远不及tomcat</td></tr><tr><td>undertow</td><td align="left">负载性能勉强跑赢tomcat</td></tr></tbody></table></li></ul><h1 id="2-基础配置"><a href="#2-基础配置" class="headerlink" title="2.  基础配置"></a>2.  基础配置</h1><h3 id="2-1-属性配置"><a href="#2-1-属性配置" class="headerlink" title="2.1 属性配置"></a>2.1 属性配置</h3><p>配置位置：SpringBoot默认配置文件application.properties</p><ul><li><p>修改服务器端口</p><blockquote><p>server.port=80</p></blockquote></li><li><p>关闭运行日志图标（banner）</p><blockquote><p>spring.main.banner-mode=off</p></blockquote></li><li><p>设置日志相关</p><blockquote><p>logging.level.root=debug</p></blockquote></li></ul><p>SpringBoot内置属性查询<br> <a href="https://docs.spring.io/spring-boot/docs/current/reference/html/application-properties.html#application-properties">https://docs.spring.io/spring-boot/docs/current/reference/html/application-properties.html#application-properties</a><br> 官方文档中参考文档第一项：Application Properties</p><h3 id="2-2-配置文件分类"><a href="#2-2-配置文件分类" class="headerlink" title="2.2  配置文件分类"></a>2.2  配置文件分类</h3><ul><li>SpringBoot提供了多种属性配置方式</li></ul><blockquote><p>properties  yml    yaml</p></blockquote><ul><li><p> properties（传统格式/默认格式）</p></li><li><p> yml（主流格式）</p></li><li><p> yaml</p></li><li><p>SpringBoot配置文件加载顺序</p><pre><code>  application.properties &gt; application.yml &gt; application.yaml</code></pre></li><li><p>配置文件间的加载优先级</p><ul><li>properties（最高）</li><li>yml</li><li>yaml（最低）</li></ul></li></ul><ol start="2"><li>不同配置文件中相同配置按照加载优先级相互覆盖，不同配置文件中不同配置全部保留</li></ol><h3 id="2-3-yaml文件"><a href="#2-3-yaml文件" class="headerlink" title="2.3  yaml文件"></a>2.3  yaml文件</h3><ul><li><p>YAML文件扩展名</p><ul><li>.yml（主流）</li><li> .yaml</li></ul></li><li><p>yaml语法规则</p><ul><li>大小写敏感</li></ul></li><li><p>属性层级关系使用多行描述，每行结尾使用冒号结束</p><ul><li>使用缩进表示层级关系，同层级左侧对齐，只允许使用空格（不允许使用Tab键）</li></ul></li><li><p>属性值前面添加空格（属性名与属性值之间使用冒号+空格作为分隔）</p><ul><li># 表示注释</li></ul></li><li><p> 核心规则：数据前面要加空格与冒号隔开</p></li><li><p> <img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/yaml.png" alt="yaml"></p></li></ul><h3 id="2-4-yaml数据读取"><a href="#2-4-yaml数据读取" class="headerlink" title="2.4  yaml数据读取"></a>2.4  yaml数据读取</h3><p>方式一：</p><p><strong>使用局部变量</strong></p><ul><li><p>使用@Value读取单个数据，属性名引用方式：${一级属性名.二级属性名……}</p></li><li><p>如果数据存在多层级，依次书写层级名称即可</p><p>缺点：需要定义多个变量</p></li></ul><p>方式二</p><p>​    <strong>封装全部数据到Environment对象</strong></p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/env.png" alt="env" style="zoom: 50%;" /><ol><li>使用Environment对象封装全部配置信息</li><li>使用@Autowired自动装配数据到Environment对象中</li></ol><p>方式三</p><p><strong>自定义对象封装指定数据</strong></p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/dataclass.png" alt="dataclass" style="zoom:50%;" /><p>注意：</p><ul><li>自定义对象中的变量名需要和配置文件中的变量名一致</li><li>封装类需要定义为Spring管理的bean，否则无法进行属性注入</li><li>使用@ConfigurationProperties注解绑定配置信息到封装类中</li></ul><h1 id="3-整合第三方技术"><a href="#3-整合第三方技术" class="headerlink" title="3. 整合第三方技术"></a>3. 整合第三方技术</h1><h2 id="3-1-整合junit"><a href="#3-1-整合junit" class="headerlink" title="3.1 整合junit"></a>3.1 整合junit</h2><p>直接创建一个最简单的spring Initializer模块即可</p><ol><li>导入测试对应的starter</li><li>测试类使用@SpringBootTest修饰</li><li>使用自动装配的形式添加要测试的对象</li></ol><p>对SpringBootTest的解释：</p><ul><li><p>类型：测试类注解</p></li><li><p> 位置：测试类定义上方</p></li><li><p> 作用：设置JUnit加载的SpringBoot启动类</p></li><li><p>范例：  </p><blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@SpringBootTest</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JunitInterApplicationTests</span> </span>&#123;<br>&#125;<br></code></pre></td></tr></table></figure></blockquote><p><font color='red'>注意</font>：如果测试类在SpringBoot启动类的包或子包中，可以省略启动类的设置，也就是省略classes的设定</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@SpringBootTest(classes = Springboot05JUnitApplication.class)</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Springboot07JUnitApplicationTests</span> </span>&#123;&#125;<br></code></pre></td></tr></table></figure></li></ul><ol><li> 测试类如果存在于引导类所在包或子包中无需指定引导类</li><li>测试类如果不存在于引导类所在的包或子包中需要通过<font color='cornflowerblue'>classes</font>属性指定引导类</li></ol><h2 id="3-2-整合MyBatis"><a href="#3-2-整合MyBatis" class="headerlink" title="3.2 整合MyBatis"></a>3.2 整合MyBatis</h2><p>①创建新模块，选择Spring初始化，并配置模块相关基础信息</p><p>②选择当前模块需要使用的技术集（MyBatis、MySQL）</p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/mybatis_inte.3a01r3gjd6k0.png" alt="mybatis_inte" style="zoom: 80%;" /><p>③设置数据源参数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java">spring:<br>  datasource:<br>    driver-<span class="hljs-class"><span class="hljs-keyword">class</span>-<span class="hljs-title">name</span>: <span class="hljs-title">com</span>.<span class="hljs-title">mysql</span>.<span class="hljs-title">cj</span>.<span class="hljs-title">jdbc</span>.<span class="hljs-title">Driver</span></span><br><span class="hljs-class">    <span class="hljs-title">url</span>: <span class="hljs-title">jdbc</span>:<span class="hljs-title">mysql</span>://<span class="hljs-title">localhost</span>:3306/<span class="hljs-title">test</span>?<span class="hljs-title">serverTimezone</span></span>=UTC<br>    username: root<br>    password: Fyl147258369<br></code></pre></td></tr></table></figure><p>注意：SpringBoot版本低于2.4.3(不含)，<strong>Mysql驱动版本大于8.0时，需要在url连接串中配置时区</strong></p><p>④定义数据层接口与映射配置</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Mapper</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">interface</span> <span class="hljs-title">UserDao</span> </span>&#123;<br>    <span class="hljs-meta">@Select(&quot;select * from user where id = #&#123;id&#125;&quot;)</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> List&lt;User&gt; <span class="hljs-title">getById</span><span class="hljs-params">(Integer id)</span></span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>⑤测试类中注入dao接口，测试功能</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@SpringBootTest</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MybatisInterApplicationTests</span> </span>&#123;<br><br>    <span class="hljs-meta">@Autowired</span><br>    <span class="hljs-keyword">public</span> UserDao userDao;<br><br>    <span class="hljs-meta">@Test</span><br>    <span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">testgetById</span><span class="hljs-params">()</span> </span>&#123;<br>        System.out.println(userDao.getById(<span class="hljs-number">3</span>));<br>    &#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><p>总结✍🏻:</p><ol><li><p>勾选MyBatis技术，也就是导入MyBatis对应的starter</p></li><li><p>数据库连接相关信息转换成配置</p></li><li><p>数据库SQL映射需要添加@Mapper被容器识别到</p></li></ol><h2 id="3-3-整合MyBatis-Plus"><a href="#3-3-整合MyBatis-Plus" class="headerlink" title="3.3. 整合MyBatis-Plus"></a>3.3. 整合MyBatis-Plus</h2><p>①创建新模块，选择Spring初始化，并配置模块相关基础信息</p><p>②只勾选Mysql的驱动，手动添加SpringBoot整合MyBatis-Plus的坐标，可以通过mvnrepository获取</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.baomidou<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>mybatis-plus-boot-starter<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.4.3<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></td></tr></table></figure><p>③设置数据源参数</p><p>④定义数据层接口与映射配置</p><blockquote><p>直接可以继承BaseMapper,不需要自己手动写常见的增删改查操作。不过需要注意BaseMapper<T>中的泛型需要和数据库中的表对应，否则差不多相关的表存在。解决办法可以在配置文件中进行相关配置。</p></blockquote><p>总结✍🏻:</p><ol><li>手工添加MyBatis-Plus对应的starter</li><li>数据层接口使用BaseMapper简化开发</li><li>需要使用的第三方技术无法通过勾选确定时，需要手工添加坐标</li></ol><h2 id="3-4-整合Druid"><a href="#3-4-整合Druid" class="headerlink" title="3.4 整合Druid"></a>3.4 整合Druid</h2><p>①按照整合mybatis的步骤，创建新模块</p><p>②手动添加SpringBoot整合Druid的坐标，可以通过mvnrepository获取</p><p>③设置数据源参数（直接打druid）</p><p>④定义数据层接口与映射配置</p><p>整合第三方技术通用方式:</p><ul><li>导入对应的starter</li><li>根据提供的配置格式，配置非默认值对应的配置项</li></ul><h1 id="4-SSMP项目整合"><a href="#4-SSMP项目整合" class="headerlink" title="4.SSMP项目整合"></a>4.SSMP项目整合</h1><p>需要导入的开发模块坐标有：Mysql,Mybatis-plus,Druid,Lombok</p><h2 id="4-1-模块搭建"><a href="#4-1-模块搭建" class="headerlink" title="4.1 模块搭建"></a>4.1 模块搭建</h2><p>创建Spring Initializr, 自动导入Mysql坐标，手动添加Mybatis-plus,Druid,Lombok的坐标.</p><h2 id="4-2-实体类开发"><a href="#4-2-实体类开发" class="headerlink" title="4.2 实体类开发"></a>4.2 实体类开发</h2><ul><li>数据库创建相应的表</li><li>Domain文件夹创建与数据库对应的实体类</li><li>利用Lombok的@Data注解自动实现相应的get方法和set方法</li></ul><h2 id="4-3-数据层开发【Mapper】"><a href="#4-3-数据层开发【Mapper】" class="headerlink" title="4.3 数据层开发【Mapper】"></a>4.3 数据层开发【Mapper】</h2><ul><li><p>首先对配置文件进行配置（数据源环境、数据库id的自增策略）</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs java"># 链接数据库<br>spring:<br>  datasource:<br>    druid:<br>      driver-<span class="hljs-class"><span class="hljs-keyword">class</span>-<span class="hljs-title">name</span>: <span class="hljs-title">com</span>.<span class="hljs-title">mysql</span>.<span class="hljs-title">cj</span>.<span class="hljs-title">jdbc</span>.<span class="hljs-title">Driver</span></span><br><span class="hljs-class">      <span class="hljs-title">url</span>: <span class="hljs-title">jdbc</span>:<span class="hljs-title">mysql</span>://<span class="hljs-title">localhost</span>:3306/<span class="hljs-title">test</span>?<span class="hljs-title">serverTimezone</span></span>=UTC<br>      username: root<br>      password: Fyl147258369<br><br># Mybatis-plus的设置<br>mybatis-plus:<br>  global-config:<br>    db-config:<br>#      设置id是自增策略<br>      id-type: auto<br>  configuration:<br>#    打开日志<br>    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl<br></code></pre></td></tr></table></figure></li><li><p>创建对应的接口Mapper(Dao)</p></li><li><p>将对应接口设置为Spring的对象，添加@Mapper注解</p></li><li><p>接口同时利用Mybatis-plus的封装，继承BaseMapper，可以省去常见的增删改查操作</p></li><li><p>制作测试类测试Mapper(Dao)功能是否有效</p></li></ul><p>除去常见的增删改查操作，如果需要分页操作和查找操作，则还需要其他内容。</p><ul><li><p>分页操作</p><p>分页操作需要设定分页对象IPage，以及对拦截器的设置。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java">   <span class="hljs-meta">@Test</span><br>   <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testgetPage</span><span class="hljs-params">()</span></span>&#123;<br><span class="hljs-comment">//分页除了定义Ipage对象，还需要对其利用拦截器进行实现</span><br>       IPage&lt;User&gt; page = <span class="hljs-keyword">new</span> Page(<span class="hljs-number">2</span>,<span class="hljs-number">5</span>);<br>       System.out.println(userDao.selectPage(page,<span class="hljs-keyword">null</span>));<br>   &#125;<br></code></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Configuration</span>  <span class="hljs-comment">//需要此注解表明该类是一个配置类，Spring扫描到会加载其中内容</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MpConfig</span> </span>&#123;<br><br>    <span class="hljs-meta">@Bean</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> MybatisPlusInterceptor <span class="hljs-title">mybatisPlusInterceptor</span><span class="hljs-params">()</span></span>&#123;<br>        <span class="hljs-comment">//1. 定义 Mp 拦截器</span><br>        MybatisPlusInterceptor interceptor=<span class="hljs-keyword">new</span> MybatisPlusInterceptor();<br>        <span class="hljs-comment">//2. 添加具体的拦截器</span><br>        interceptor.addInnerInterceptor(<span class="hljs-keyword">new</span> PaginationInnerInterceptor());<span class="hljs-comment">// 通过该配置表明新增了一个分页增强</span><br>        <span class="hljs-keyword">return</span> interceptor;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>拦截器的配置类似于AOP，需要什么功能在addInnerInterceptor.</p></li><li><p>查找操作</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Test</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">testgetBy</span><span class="hljs-params">()</span></span>&#123;<br>    String name = <span class="hljs-string">&quot;王&quot;</span>;<span class="hljs-comment">//查询姓名中带有王的</span><br>    LambdaQueryWrapper&lt;User&gt; queryWrapper = <span class="hljs-keyword">new</span> LambdaQueryWrapper&lt;&gt;();<br>    queryWrapper.like(name!=<span class="hljs-keyword">null</span>,User::getName,name);<span class="hljs-comment">//condition为true时，按照条件查询</span><br>    userDao.selectList(queryWrapper);<br>&#125;<br></code></pre></td></tr></table></figure><p> 1.使用QueryWrapper对象封装查询条件</p></li></ul><ol start="2"><li>推荐使用LambdaQueryWrapper对象</li><li>所有查询操作封装成方法调用</li><li>查询条件支持动态条件拼装</li></ol><h2 id="4-4-业务层开发【Service】"><a href="#4-4-业务层开发【Service】" class="headerlink" title="4.4 业务层开发【Service】"></a>4.4 业务层开发【Service】</h2><ul><li><p>service接口类定义</p><ul><li><p>使用通用接口（ISerivce<T>）快速开发Service，通过继承的形式。则常见的利用增删改查的业务也不需要在其中定义</p></li><li><p>在通用类基础上做功能重载或功能追加</p></li><li><p>注意重载时不要覆盖原始操作，避免原始提供的功能丢失</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Springboot/Iservice.1cirmskqzoyo.webp" alt="Iservice"></p></li></ul></li><li><p>service实现类定义【需要利用注解@Service表明】</p><ul><li>使用通用实现类（ServiceImpl&lt;M,T&gt;）快速开发ServiceImpl</li><li>如果service接口有追加功能，则实现类中也需要实现接口并重写方法，通过利用Dao的Bean对象</li></ul></li><li><p>service测试类</p></li></ul><h2 id="4-5-表现层开发【Controller】"><a href="#4-5-表现层开发【Controller】" class="headerlink" title="4.5 表现层开发【Controller】"></a>4.5 表现层开发【Controller】</h2><ul><li><p>编写表现层的类</p><ul><li>需要利用注解@RestController表明</li><li>利用注解@RequestMapping(“/xxx”)定义类的路径</li><li>实现对应的功能函数，利用Service层的Bean对象</li></ul><p>若是基于Restful进行表现层接口开发，则需要在每一个功能函数上通过注解表明是Restful中四种请求的某种请求，否则需要为每一个功能函数定义路径</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@RestController</span><br><span class="hljs-meta">@RequestMapping(&quot;/books&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BookController</span> </span>&#123;<br>    <span class="hljs-meta">@Autowired</span><br>    <span class="hljs-keyword">private</span> IBookService bookService;<br>    <br>    <span class="hljs-meta">@GetMapping</span>  # Get请求<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> List&lt;Book&gt; <span class="hljs-title">getAll</span><span class="hljs-params">()</span></span>&#123;<br>        <span class="hljs-keyword">return</span> bookService.list();<br>    &#125;<br>    <br>    <span class="hljs-meta">@PutMapping</span>  # Put请求<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> Boolean <span class="hljs-title">update</span><span class="hljs-params">(<span class="hljs-meta">@RequestBody</span> Book book)</span></span>&#123; # 接收实体参数<br>    <span class="hljs-keyword">return</span> bookService.modify(book);<br>    &#125;<br>    <br>    <span class="hljs-meta">@DeleteMapping(&quot;/&#123;id&#125;&quot;)</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> Boolean <span class="hljs-title">delete</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable</span> Integer id)</span></span>&#123; # 接收路径变量<br>    <span class="hljs-keyword">return</span> bookService.delete(id);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure></li></ul><ol><li>基于Restful制作表现层接口</li></ol><ul><li> 新增：POST</li><li> 删除：DELETE</li><li>修改：PUT</li><li>查询：GET</li></ul><ol start="2"><li>接收参数</li></ol><ul><li>实体数据：@RequestBody</li><li>路径变量：@PathVariable</li></ul>]]></content>
    
    
    <categories>
      
      <category>Spring系列</category>
      
    </categories>
    
    
    <tags>
      
      <tag>learn</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Redis</title>
    <link href="/2021/12/10/Redis/"/>
    <url>/2021/12/10/Redis/</url>
    
    <content type="html"><![CDATA[<p> 本篇文章是根据<a href="https://www.bilibili.com/video/BV1CJ411m7Gc">黑马程序员</a>的视频，学习所做的笔记🦊。</p><h1 id="1-Redis的简单介绍"><a href="#1-Redis的简单介绍" class="headerlink" title="1. Redis的简单介绍"></a>1. Redis的简单介绍</h1><p><strong>概念：</strong>Redis (REmote DIctionary Server) 是用 C 语言开发的一个开源的<em>高性能键值对（key-value）数据库。</em></p><p><strong>类型</strong>：非关系型数据库（Nosql）</p><p><strong>特征：</strong></p><ul><li>可扩容，可伸缩</li><li>大数据量下高性能</li><li>灵活的数据模型</li><li>高可用</li></ul><p><strong>关键词：</strong>单线程、高性能、多数据类型、持久化</p><h1 id="2-Redis的应用"><a href="#2-Redis的应用" class="headerlink" title="2. Redis的应用"></a>2. Redis的应用</h1><ul><li>为热点数据加速查询（主要场景），如热点商品、热点新闻、热点资讯、推广类等高访问量信息等</li><li>任务队列，如秒杀、抢购、购票排队等</li><li>即时信息查询，如各位排行榜、各类网站访问统计、公交到站信息、在线人数信息（聊天室、网站）、设<br>备信号等 </li><li>时效性信息控制，如验证码控制、投票控制等</li><li>分布式数据共享，如分布式集群架构中的 session 分离</li><li>消息队列</li><li>分布式锁</li></ul><h1 id="3-Redis的五大数据类型"><a href="#3-Redis的五大数据类型" class="headerlink" title="3. Redis的五大数据类型"></a>3. Redis的五大数据类型</h1><p>​        <strong>redis                             java</strong></p><ul><li><p>String                          String</p></li><li><p>hash                          HashMap</p></li><li><p>list                             LinkedList</p></li><li><p>set                              HashSet</p></li><li><p>sortedset(zset)          TreeSet</p><p>数据类型指的是存储的数据的类型，也就是 value 部分的类型，key 部分永远都是字符串</p></li></ul><h1 id="4-Redis对不同数据类型的常见命令"><a href="#4-Redis对不同数据类型的常见命令" class="headerlink" title="4. Redis对不同数据类型的常见命令"></a>4. Redis对不同数据类型的常见命令</h1><h2 id="4-1-String"><a href="#4-1-String" class="headerlink" title="4.1 String"></a>4.1 String</h2><ul><li> 存储的数据：单个数据，最简单的数据存储类型，也是最常用的数据存储类型</li><li> 存储数据的格式：一个存储空间保存一个数据</li><li>存储内容：通常使用字符串，如果字符串以整数的形式展示，可以作为数字操作使用</li></ul><ol><li><strong>基本命令：</strong></li></ol><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs maxima">set <span class="hljs-built_in">key</span> value                                         [添加/修改单条数据]<br><span class="hljs-built_in">get</span> <span class="hljs-built_in">key</span>                                               [获取单条数据]<br><span class="hljs-built_in">del</span> <span class="hljs-built_in">key</span>                                               [删除数据]<br>setex <span class="hljs-built_in">key</span>  <span class="hljs-built_in">second</span> value                               [设置<span class="hljs-built_in">key</span>的生命周期]<br>incr <span class="hljs-built_in">key</span>                                              [为某一个<span class="hljs-built_in">key</span>做自增操作，++<span class="hljs-built_in">key</span>]<br>decr <span class="hljs-built_in">key</span> <br></code></pre></td></tr></table></figure><ol start="2"><li><strong>其他命令:</strong></li></ol><blockquote><p><strong>mset</strong> key1 value1 key2 value2 … 【添加/修改多条数据】</p><p><strong>mget</strong> key1 key2 …                                【获取多条数据】</p><p><strong>strlen</strong> key                                    【获取数据字符个数（字符串长度）】</p><p><strong>append</strong> key value       [ 追加信息到原始信息后部（如果原始信息存在就追加，否则新建）]</p></blockquote><p>set 和 mset之间的选择问题：如果查询数据量较多时，可以选择mset来节约服务器与redis之间的往返时间</p><blockquote><p><strong>incrby</strong>  key   increment                         【为某一个key加上increment，但只能是整数】</p><p><strong>incrbyfloat</strong> key increment                  【为某一个key加上increment，可以是小数】</p><p><strong>decrby</strong> key increment</p></blockquote><p>string 作为数值操作:</p><ul><li><p>string在redis内部存储默认就是一个字符串，当遇到增减类操作incr，decr时会转成数值型进行计算。</p></li><li><p>redis所有的操作都是原子性的，采用单线程处理所有业务，命令是一个一个执行的，因此无需考虑并发<br>带来的数据影响。</p></li><li><p>注意：按数值进行操作的数据，如果原始数据不能转成数值，或超越了redis 数值上限范围，将报错。<br>9223372036854775807（java中long型数据最大值，Long.MAX_VALUE）</p><p>string 类型数据操作的注意事项</p><blockquote><p> <strong>数据操作不成功的反馈与数据正常操作之间的差异</strong></p><p>① 表示运行结果是否成功</p><p>(integer) 0 → false 失败<br> (integer) 1 → true  成功<br>② 表示运行结果值<br> (integer) 3 → 3 3个<br>(integer) 1 → 1 1个<br> <strong>数据未获取到</strong><br>（nil）等同于null<br><strong>数据最大存储量</strong><br>512MB<br> <strong>数值计算最大范围（java中的long的最大值）</strong><br>9223372036854775807</p></blockquote></li></ul><p><strong>业务场景</strong>：主页高频访问信息显示控制，例如新浪微博大V主页显示粉丝数与微博数量</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/string_01.png" alt="string_01"></p><h2 id="4-2-hash"><a href="#4-2-hash" class="headerlink" title="4.2 hash"></a>4.2 hash</h2><ul><li>新的存储需求：对一系列存储的数据进行编组，方便管理，典型应用存储对象信息</li><li>需要的存储结构：一个存储空间保存多个键值对数据</li><li>hash类型：底层使用哈希表结构实现数据存储</li></ul><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/hash_01.png" alt="hash_01"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java">hset key field value         [添加/修改数据]<br>hget key field               [获取数据]<br>hgetall key                  <br>hdel key field1 [field2]     [删除数据]      <br></code></pre></td></tr></table></figure><ol start="2"><li><strong>其他命令</strong> </li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java">hmset key field1 value1 field2 value2 … <br>hmget key field1 field2 … <br>hlen key                    [获取哈希表中field字段的数量]<br>hexists key field           [获取哈希表中是否存在指定的字段]<br>    <br>hkeys key                   [ 获取哈希表中所有的字段名或字段值]<br>hvals key<br>hincrby key field increment [设置指定字段的数值数据增加指定范围的值]<br>hincrbyfloat key field increment<br></code></pre></td></tr></table></figure><p>hash 类型数据操作的注意事项 </p><ul><li><p>hash类型下的value只能存储字符串，不允许存储其他数据类型，不存在嵌套现象。如果数据未获取到，<br>对应的值为（nil）</p></li><li><p>hash 类型数据操作的注意事项</p></li><li><p>每个 hash 可以存储 2 32 - 1 个键值对</p></li><li><p>hash类型十分贴近对象的数据存储形式，并且可以灵活添加删除对象属性。但hash设计初衷不是为了存<br>储大量对象而设计的，切记不可滥用，更不可以将hash作为对象列表使用</p></li><li><p>hgetall 操作可以获取全部属性，如果内部field过多，遍历整体数据效率就很会低，有可能成为数据访问<br>瓶颈</p></li></ul><p>对比：string存储对象（json）<strong>VS</strong> hash存储对象</p><p>String的好处：将对象的内容组装为一个整体，更倾向于<em>读取</em> </p><p>hash的好处：将对象的内容分成不同的field，更倾向于<em>更新</em></p><h2 id="4-3-list"><a href="#4-3-list" class="headerlink" title="4.3 list"></a>4.3 list</h2><ul><li> 数据存储需求：存储多个数据，并对数据进入存储空间的顺序进行区分</li><li>需要的存储结构：一个存储空间保存多个数据，且通过数据可以体现进入顺序</li><li>list类型：保存多个数据，底层使用<strong>双向链表</strong>存储结构实现</li></ul><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/list_1.jpg" alt="list_1"></p><ol><li><p><strong>基本命令</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java">lpush key value1 [value2] ……        【 添加/修改数据】<br>rpush key value1 [value2] ……<br>  <br>lrange key start stop                【获取数据】<br>lindex key index<br>llen key <br>    <br>lpop key                            【获取并移除数据】<br>rpop key<br></code></pre></td></tr></table></figure></li><li><p><strong>其他命令</strong></p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs applescript">blpop key1 [key2] <span class="hljs-keyword">timeout</span>           [ 规定时间内获取并移除数据]<br>brpop key1 [key2] <span class="hljs-keyword">timeout</span><br>brpoplpush source destination <span class="hljs-keyword">timeout</span><br><br>lrem key <span class="hljs-built_in">count</span> value                [移除指定数据,<span class="hljs-built_in">count</span>表示为：移掉多少个]<br></code></pre></td></tr></table></figure><p>相当于阻塞，如果list中没有数据则阻塞，在规定的时间内有数据就输出并移除</p></li><li><p><strong>注意事项</strong></p><ul><li>list中保存的数据都是string类型的，数据总容量是有限的，最多2 32 - 1 个元素 (4294967295)。</li><li>list具有索引的概念，但是操作数据时通常以队列的形式进行入队出队操作，或以栈的形式进行入栈出栈操作</li><li>获取全部数据操作结束索引设置为-1</li><li>list可以对数据进行分页操作，通常第一页的信息来自于list，第2页及更多的信息通过数据库的形式加载</li></ul></li><li><p><strong>业务场景</strong></p><ul><li>twitter、新浪微博、腾讯微博中个人用户的<strong>关注列表</strong>需要按照用户的关注顺序进行展示，粉丝列表需要将最<br>近关注的粉丝列在前面</li><li>新闻、资讯类网站如何将最新的新闻或资讯按照发生的<strong>时间顺序展示？</strong></li></ul></li></ol><h2 id="4-4-set"><a href="#4-4-set" class="headerlink" title="4.4 set"></a>4.4 set</h2><ul><li><p>新的存储需求：存储大量的数据，在查询方面提供更高的效率</p></li><li><p>需要的存储结构：能够保存大量的数据，高效的内部存储机制，便于查询</p></li><li><p>set类型：与hash存储结构完全相同，仅存储键，不存储值（nil），并且值是不允许重复的</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/set1.png" alt="set1"></p></li></ul><ol><li>基本命令</li></ol><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sadd</span> key member<span class="hljs-number">1</span><span class="hljs-meta"> [member2]        [添加数据]</span><br><span class="hljs-attribute">smembers</span> key                     <span class="hljs-meta"> [获取全部数据]</span><br><span class="hljs-attribute">srem</span> key member<span class="hljs-number">1</span><span class="hljs-meta"> [member2]        [删除数据]</span><br></code></pre></td></tr></table></figure><ol start="2"><li><strong>其他命令</strong></li></ol><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs css">scard key                         <span class="hljs-selector-attr">[获取集合数据总量]</span><br>sismember key member              <span class="hljs-selector-attr">[判断集合中是否包含指定数据]</span><br>srandmember key <span class="hljs-selector-attr">[count]</span>           <span class="hljs-selector-attr">[随机获取集合中指定数量的数据]</span><br>spop key <span class="hljs-selector-attr">[count]</span>                  <span class="hljs-selector-attr">[随机获取集合中的某个数据并将该数据移出集合]</span><br></code></pre></td></tr></table></figure><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">sinter</span> key<span class="hljs-number">1</span><span class="hljs-meta"> [key2]               [求两个集合的交、并、差集]</span><br><span class="hljs-attribute">sunion</span> key<span class="hljs-number">1</span><span class="hljs-meta"> [key2]</span><br><span class="hljs-attribute">sdiff</span> key<span class="hljs-number">1</span><span class="hljs-meta"> [key2]</span><br><br><span class="hljs-attribute">sinterstore</span> destination key<span class="hljs-number">1</span><span class="hljs-meta"> [key2]  [求两个集合的交、并、差集并存储到指定集合中]</span><br><span class="hljs-attribute">sunionstore</span> destination key<span class="hljs-number">1</span><span class="hljs-meta"> [key2]</span><br><span class="hljs-attribute">sdiffstore</span> destination key<span class="hljs-number">1</span><span class="hljs-meta"> [key2]</span><br><br><span class="hljs-attribute">smove</span> source destination member     <span class="hljs-meta"> [将指定数据从原始集合中移动到目标集合中]</span><br></code></pre></td></tr></table></figure><ol start="3"><li><strong>注意事项</strong></li></ol><ul><li> set 类型不允许数据重复，如果添加的数据在 set 中已经存在，将只保留一份</li><li> set 虽然与hash的存储结构相同，但是无法启用hash中存储值的空间【set中的value类似于hash中的field】</li></ul><ol start="4"><li><strong>业务场景</strong></li></ol><ul><li>redis 应用于随机推荐类信息检索，例如热点歌单推荐，热点新闻推荐，热卖旅游线路，应用APP推荐，<br>大V推荐等</li><li>新浪微博为了增加用户热度，提高用户留存性，需要微博用户在关注更多的人，以此获得更多的信息或热门<br>话题，如何提高用户关注他人的总量？</li><li>共同好友、共同关注等</li><li>redis 应用于同类型数据的快速去重</li><li>设置白名单或者黑名单</li></ul><h2 id="4-5-sorteds-set"><a href="#4-5-sorteds-set" class="headerlink" title="4.5 sorteds_set"></a>4.5 sorteds_set</h2><ul><li><p>新的存储需求：数据排序有利于数据的有效展示，需要提供一种可以根据自身特征进行排序的方式</p></li><li><p>需要的存储结构：新的存储模型，可以保存可排序的数据</p></li><li><p>sorted_set类型：在set的存储结构基础上添加<strong>可排序字段</strong></p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/sorted_set.png" alt="sorted_set"></p></li></ul><ol><li><p><strong>基本命令</strong></p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs less"><span class="hljs-selector-tag">zadd</span> <span class="hljs-selector-tag">key</span> <span class="hljs-selector-tag">score1</span> <span class="hljs-selector-tag">member1</span> <span class="hljs-selector-attr">[score2 member2]</span>           <span class="hljs-selector-attr">[添加数据]</span>  <br><br><span class="hljs-selector-tag">zrange</span> <span class="hljs-selector-tag">key</span> <span class="hljs-selector-tag">start</span> <span class="hljs-selector-tag">stop</span> <span class="hljs-selector-attr">[WITHSCORES]</span>                 <span class="hljs-selector-attr">[获取全部数据]</span>(升序)<br><span class="hljs-selector-tag">zrevrange</span> <span class="hljs-selector-tag">key</span> <span class="hljs-selector-tag">start</span> <span class="hljs-selector-tag">stop</span> <span class="hljs-selector-attr">[WITHSCORES]</span>               (降序)<br><br><span class="hljs-selector-tag">zrem</span> <span class="hljs-selector-tag">key</span> <span class="hljs-selector-tag">member</span> <span class="hljs-selector-attr">[member ...]</span>                       <span class="hljs-selector-attr">[删除数据]</span><br></code></pre></td></tr></table></figure></li><li><p><strong>其他命令</strong></p><figure class="highlight xquery"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs xquery">zrangebyscore<span class="hljs-built_in"> key</span><span class="hljs-built_in"> min</span><span class="hljs-built_in"> max</span> [WITHSCORES] [LIMIT]         [按条件获取数据]<br>zrevrangebyscore<span class="hljs-built_in"> key</span><span class="hljs-built_in"> max</span><span class="hljs-built_in"> min</span> [WITHSCORES]<br><br>zremrangebyrank<span class="hljs-built_in"> key</span> <span class="hljs-keyword">start</span> stop                         [条件删除数据]<br>zremrangebyscore<span class="hljs-built_in"> key</span><span class="hljs-built_in"> min</span><span class="hljs-built_in"> max</span><br><br></code></pre></td></tr></table></figure><ul><li> min与max用于限定搜索查询的条件</li><li> start与stop用于限定查询范围，作用于索引，表示开始和结束索引</li><li>offset与count用于限定查询范围，作用于查询结果，表示开始位置和数据总量</li></ul><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs maxima">zcard <span class="hljs-built_in">key</span>                                              [获取集合数据总量]           <br>zcount <span class="hljs-built_in">key</span> <span class="hljs-built_in">min</span> <span class="hljs-built_in">max</span>                                     [集合交、并操作]<br><br>zrank <span class="hljs-built_in">key</span> <span class="hljs-built_in">member</span>                                      [获取数据对应的索引（排名）]<br>zrevrank <span class="hljs-built_in">key</span> <span class="hljs-built_in">member</span><br>   <br>zscore <span class="hljs-built_in">key</span> <span class="hljs-built_in">member</span>                                      score值获取与修改<br>zincrby <span class="hljs-built_in">key</span> increment <span class="hljs-built_in">member</span><br></code></pre></td></tr></table></figure></li><li><p><strong>注意事项</strong></p><ul><li> score保存的数据存储空间是64位，如果是整数范围是-9007199254740992~9007199254740992</li><li>score保存的数据也可以是一个<strong>双精度的double值</strong>，基于双精度浮点数的特征，可能会丢失精度，使用时<br>候要慎重</li><li>sorted_set 底层存储还是基于set结构的，因此数据不能重复，如果重复添加相同的数据，score值将被反<br>复覆盖，保留最后一次修改的结果</li></ul></li><li><p><strong>业务场景</strong></p><ul><li>票选广东十大杰出青年，各类综艺选秀海选投票</li><li>各类资源网站TOP10（电影，歌曲，文档，电商，游戏等）</li><li>聊天室活跃度统计</li><li>游戏好友亲密度</li><li>redis 应用于即时任务/消息队列执行管理(对于高优先级的任务要保障对其优先处理)</li></ul></li></ol><h2 id="4-6-数据类型实践案例"><a href="#4-6-数据类型实践案例" class="headerlink" title="4.6 数据类型实践案例"></a>4.6 数据类型实践案例</h2><p>业务场景：</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/sorted_set2.png" alt="sorted_set2"></p><p><a href="https://www.bilibili.com/video/BV1CJ411m7Gc?p=32">代码实现</a></p><h1 id="5-Redis-通用指令"><a href="#5-Redis-通用指令" class="headerlink" title="5. Redis 通用指令"></a>5. Redis 通用指令</h1><h2 id="5-1-key-通用指令"><a href="#5-1-key-通用指令" class="headerlink" title="5.1 key 通用指令"></a>5.1 key 通用指令</h2><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs maxima">keys *       [查看所有的<span class="hljs-built_in">key</span>]<br><span class="hljs-built_in">del</span> <span class="hljs-built_in">key</span>      [删除指定的<span class="hljs-built_in">key</span>]<br>exists <span class="hljs-built_in">key</span>   [获取<span class="hljs-built_in">key</span>是否存在]<br>type <span class="hljs-built_in">key</span>     [获取<span class="hljs-built_in">key</span>的类型]<br>expire <span class="hljs-built_in">key</span> seconds [设置指定<span class="hljs-built_in">key</span>的有效期]<br>ttl <span class="hljs-built_in">key</span>       [获取指定<span class="hljs-built_in">key</span>的有效时间]<br>pttl <span class="hljs-built_in">key</span><br><span class="hljs-built_in">rename</span> <span class="hljs-built_in">key</span> newkey   [为<span class="hljs-built_in">key</span>改名]<br>renamenx <span class="hljs-built_in">key</span> newkey<br></code></pre></td></tr></table></figure><h2 id="5-2-数据库通用指令"><a href="#5-2-数据库通用指令" class="headerlink" title="5.2 数据库通用指令"></a>5.2 数据库通用指令</h2><ul><li><p>redis为每个服务提供有16个数据库，编号从0到15</p></li><li><p>每个数据库之间的数据相互独立</p><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs sas"><span class="hljs-meta">select</span> <span class="hljs-meta">index</span>   [切换数据库]<br><span class="hljs-keyword">quit</span><br><span class="hljs-keyword"></span>move <span class="hljs-meta">key</span> db    [数据移动]<br>dbsize         [数据清除]<br>flushdb<br>flushall<br></code></pre></td></tr></table></figure></li></ul><h1 id="6-Jedis"><a href="#6-Jedis" class="headerlink" title="6. Jedis"></a>6. Jedis</h1><h2 id="6-1-准备工作"><a href="#6-1-准备工作" class="headerlink" title="6.1 准备工作"></a>6.1 准备工作</h2><ul><li><p>导入jedis坐标</p><blockquote><dependency><groupId>redis.clients</groupId><artifactId>jedis</artifactId><version>2.9.0</version></dependency></blockquote></li><li><p>连接jedis</p><blockquote><p>Jedis jedis = new Jedis(“localhost”, 6379);</p></blockquote></li><li><p>操作jedis</p></li><li><p>关闭jedis连接</p><blockquote><p>jedis.close();</p></blockquote></li></ul><h2 id="6-2-案例"><a href="#6-2-案例" class="headerlink" title="6.2 案例"></a>6.2 案例</h2><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/jedis_1.jpg" alt="jedis_1"></p><p><a href="https://www.bilibili.com/video/BV1CJ411m7Gc?p=44">代码演示</a></p><p>主程序：</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/jedis_02.jpg" alt="jedis_02"></p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/jedis_03.jpg" alt="jedis_03"  /><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/jedis_04.jpg" alt="jedis_04"></p><h2 id="6-3-jedis简易工具类开发"><a href="#6-3-jedis简易工具类开发" class="headerlink" title="6.3 jedis简易工具类开发"></a>6.3 jedis简易工具类开发</h2><p> JedisPool：Jedis提供的连接池技术</p><p>需要的三个内容：</p><p>poolConfig:连接池配置对象<br>host:redis服务地址<br>port:redis服务端口号</p><blockquote><p>//设置poolConfig</p><p>poolConfig = new JedisPoolConfig();<br>poolConfig.setMaxTotal(maxTotal);<br>poolConfig.setMaxIdle(maxIdle);</p><p>// 设置JedisPool</p><p>jedisPool = new JedisPool(poolConfig,host,port);</p></blockquote><h1 id="7-Redis的linux环境安装"><a href="#7-Redis的linux环境安装" class="headerlink" title="7. Redis的linux环境安装"></a>7. Redis的linux环境安装</h1><h2 id="7-1-基于Center-OS7安装Redis"><a href="#7-1-基于Center-OS7安装Redis" class="headerlink" title="7.1 基于Center OS7安装Redis"></a>7.1 基于Center OS7安装Redis</h2><ul><li>下载安装包<br>wget <a href="http://download.redis.io/releases/redis-?.?.?.tar.gz">http://download.redis.io/releases/redis-?.?.?.tar.gz</a></li><li>解压<br>tar –xvf 文件名.tar.gz</li><li>编译<br>make</li><li>安装<br>make install [destdir=/目录]</li></ul><h2 id="7-2-Redis服务器端启动"><a href="#7-2-Redis服务器端启动" class="headerlink" title="7.2 Redis服务器端启动"></a>7.2 Redis服务器端启动</h2><ol><li><p>默认：redis-server</p><p>如果想启动多个redis服务器，则需要换端口，那么对应的客户端也需要指定这个端口号</p></li><li><p>redis-server –port xxx(端口号)</p><p>redis-cli –port xxx</p></li><li><p>通过配置文件启动</p><ul><li><p>cp redis-6379.conf redis-6380.conf  [复制配置文件]</p></li><li><p>修改新的配置文件的端口号和日志名</p></li><li><p>启动对应端口的配置文件</p><p>redis-server redis-6380.conf</p></li></ul></li></ol><h1 id="8-Redis持久化"><a href="#8-Redis持久化" class="headerlink" title="8. Redis持久化"></a>8. Redis持久化</h1><h2 id="8-1持久化简介"><a href="#8-1持久化简介" class="headerlink" title="8.1持久化简介"></a>8.1持久化简介</h2><p><strong>什么是持久化：</strong></p><p>利用永久性存储介质将数据进行保存，在特定的时间将保存的数据进行恢复的工作机制称为持久化。</p><p><strong>为什么要进行持久化：</strong></p><p>防止数据的意外丢失，确保数据安全性</p><p><strong>持久化过程保存什么：</strong></p><ul><li><p> 将当前数据状态进行保存，快照形式，存储数据结果，存储格式简单，关注点在数据</p></li><li><p>将数据的操作过程进行保存，日志形式，存储操作过程，存储格式复杂，关注点在数据的操作过程</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/permenent.png" alt="permenent"></p></li></ul><h2 id="8-2-RDB"><a href="#8-2-RDB" class="headerlink" title="8.2 RDB"></a>8.2 RDB</h2><h3 id="8-2-1RDB启动方式-——-save指令"><a href="#8-2-1RDB启动方式-——-save指令" class="headerlink" title="8.2.1RDB启动方式 —— save指令"></a>8.2.1<strong>RDB启动方式 —— save指令</strong></h3><blockquote><p>save</p><p>作用：手动执行一次保存操作</p></blockquote><p>相关配置：</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/rdb_1.png" alt="rdb_1"></p><p>save工作原理：</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/rdb_2.png" alt="rdb_2"></p><p><strong>注意：save指令的执行会<u>阻塞当前Redis服务器，</u>直到当前RDB过程完成为止，有可能会造成长时间阻塞，线上环境不建议使用。</strong></p><h3 id="8-2-2-RDB启动方式-——-bgsave指令"><a href="#8-2-2-RDB启动方式-——-bgsave指令" class="headerlink" title="8.2.2 RDB启动方式 —— bgsave指令"></a>8.2.2 RDB启动方式 —— bgsave指令</h3><blockquote><p>bgsave</p><p>作用：手动启动后台保存操作，但不是立即执行</p></blockquote><p>bgsave工作原理：</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/rdb_3.png" alt="rdb_3"></p><p>注意： bgsave命令是针对save阻塞问题做的优化。Redis内部所有涉及到RDB操作都采用bgsave的方式，save命令可以放弃使用</p><p>以上两种方式均为手动保存，通过配置文件的方式是自动保存</p><h3 id="8-2-3-RDB启动方式-——save配置"><a href="#8-2-3-RDB启动方式-——save配置" class="headerlink" title="8.2.3 RDB启动方式 ——save配置"></a>8.2.3 RDB启动方式 ——save配置</h3><ul><li><p>配置</p><blockquote><p>save second changes</p></blockquote></li><li><p>作用<br>满足限定时间范围内key的变化数量达到指定数量即进行持久化</p></li><li><p>参数<br>second：监控时间范围<br>changes：监控key的变化量</p></li><li><p>位置<br>在conf文件中进行配置</p></li><li><p>范例</p><blockquote><p>save 900 1<br>save 300 10<br>save 60 10000</p></blockquote><p>注意：save配置启动后执行的是bgsave操作</p><p>RDB三种启动方式对比</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/rdb_4.png" alt="rdb_4"></p></li></ul><h3 id="8-2-4-总结"><a href="#8-2-4-总结" class="headerlink" title="8.2.4 总结"></a>8.2.4 总结</h3><p><strong>优点：</strong></p><ul><li> RDB是一个紧凑压缩的二进制文件，存储效率较高</li><li>RDB内部存储的是redis在某个时间点的<strong>数据快照</strong>，非常适合用于数据备份，全量复制等场景</li><li>RDB<strong>恢复数据</strong>的速度要比AOF<strong>快</strong>很多</li><li>应用：服务器中每X小时执行bgsave备份，并将RDB文件拷贝到远程机器中，用于灾难恢复。</li></ul><p><strong>缺点：</strong></p><ul><li>RDB方式无论是执行指令还是利用配置，<strong>无法做到实时持久化</strong>，具有较大的可能性丢失数据</li><li> bgsave指令每次运行要执行<strong>fork操作创建子进程</strong>，要牺牲掉一些性能</li><li> Redis的众多版本中未进行RDB文件格式的版本统一，有可能出现<strong>各版本</strong>服务之间数据格式<strong>无法兼容现象</strong></li></ul><h2 id="8-3-AOF"><a href="#8-3-AOF" class="headerlink" title="8.3 AOF"></a>8.3 AOF</h2><h3 id="8-3-1-AOF概念"><a href="#8-3-1-AOF概念" class="headerlink" title="8.3.1 AOF概念"></a>8.3.1 AOF概念</h3><ul><li>AOF(append only file)持久化：以<strong>独立日志</strong>的方式记录每次写<strong>命令</strong>，重启时再重新执行AOF文件中命令<br>达到恢复数据的目的。与RDB相比可以简单描述为改记录数据为记录数据产生的过程</li><li>AOF的主要作用是解决了<strong>数据持久化的实时性</strong>，目前已经是Redis持久化的主流方式</li></ul><h3 id="8-3-2-AOF写数据三种策略-appendfsync"><a href="#8-3-2-AOF写数据三种策略-appendfsync" class="headerlink" title="8.3.2 AOF写数据三种策略(appendfsync)"></a>8.3.2 AOF写数据三种策略(appendfsync)</h3><ul><li>always(每次）<br>每次写入操作均同步到AOF文件中，数据零误差，性能较低</li><li>everysec（每秒）<br>每秒将缓冲区中的指令同步到AOF文件中，数据准确性较高，性能较高<br>在系统突然宕机的情况下丢失1秒内的数据</li><li>no（系统控制）<br>由操作系统控制每次同步到AOF文件的周期，整体过程不可控</li></ul><h3 id="8-3-3-AOF功能开启"><a href="#8-3-3-AOF功能开启" class="headerlink" title="8.3.3 AOF功能开启"></a>8.3.3 AOF功能开启</h3><ul><li><p>配置</p><blockquote><p>appendonly yes|no</p></blockquote></li><li><p>作用<br>是否开启AOF持久化功能，默认为不开启状态</p></li><li><p>配置</p><blockquote><p>appendfsync always|everysec|no</p></blockquote></li><li><p>作用<br>AOF写数据策略</p></li></ul><h3 id="8-3-4-AOF重写"><a href="#8-3-4-AOF重写" class="headerlink" title="8.3.4 AOF重写"></a>8.3.4 AOF重写</h3><p><strong>作用：</strong></p><ul><li>降低磁盘占用量，提高磁盘利用率</li><li>提高持久化效率，降低持久化写时间，提高IO性能</li><li>降低数据恢复用时，提高数据恢复效率</li></ul><p><strong>重写规则：</strong></p><ul><li>进程内已超时的数据不再写入文件</li><li>忽略无效指令，重写时使用进程内数据直接生成，这样新的AOF文件只保留最终数据的写入命令<pre><code>  如del key1、 hdel key2、srem key3、set key4 111、set key4 222等</code></pre></li><li>对同一数据的多条写命令合并为一条命令<pre><code> 如lpush list1 a、lpush list1 b、 lpush list1 c 可以转化为：lpush list1 a b c。为防止数据量过大造成客户端缓冲区溢出，对list、set、hash、zset等类型，每条指令最多写入64个元素</code></pre></li></ul><p><strong>重写方式：</strong></p><ul><li><p>手动重写</p><blockquote><p>bgrewriteaof</p></blockquote></li><li><p> 自动重写</p></li></ul><blockquote><p>auto-aof-rewrite-min-size size<br>auto-aof-rewrite-percentage percentage</p></blockquote><p><strong>工作原理：</strong></p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/aof_1.png" alt="aof_1"></p><p><strong>工作流程：</strong></p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/aof-process.png" alt="aof-process"></p><p>AOF重写流程：</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/aof-rewrite.png" alt="aof-rewrite"></p><h3 id="8-4-RDB-VS-AOF"><a href="#8-4-RDB-VS-AOF" class="headerlink" title="8.4 RDB VS AOF"></a>8.4 RDB VS AOF</h3><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/aof_2.png" alt="aof_2"></p><ul><li><p>对数据非常敏感，建议使用默认的AOF持久化方案</p><ul><li><p>AOF持久化策略使用everysecond，每秒钟fsync一次。该策略redis仍可以保持很好的处理性能，当出<br>现问题时，最多丢失0-1秒内的数据。</p></li><li><p>注意：由于AOF文件存储体积较大，且恢复速度较慢</p></li></ul></li><li><p>数据呈现阶段有效性，建议使用RDB持久化方案</p><ul><li><p>数据可以良好的做到阶段内无丢失（该阶段是开发者或运维人员手工维护的），且恢复速度较快，阶段<br>点数据恢复通常采用RDB方案</p></li><li><p>注意：利用RDB实现紧凑的数据持久化会使Redis降的很低，慎重总结：</p></li></ul></li><li><p>综合比对</p><ul><li>RDB与AOF的选择实际上是在做一种权衡，每种都有利有弊</li><li>如不能承受数分钟以内的数据丢失，对业务数据非常敏感，选用AOF</li><li>如能承受数分钟以内的数据丢失，且追求大数据集的恢复速度，选用RDB</li><li>灾难恢复选用RDB</li><li>双保险策略，同时开启 RDB 和 AOF，重启后，Redis优先使用 AOF 来恢复数据，降低丢失数据的量</li></ul></li></ul><h1 id="9-Redis事务"><a href="#9-Redis事务" class="headerlink" title="9. Redis事务"></a>9. Redis事务</h1><h2 id="9-1-事务简介"><a href="#9-1-事务简介" class="headerlink" title="9.1 事务简介"></a>9.1 事务简介</h2><p>redis事务就是一个命令执行的队列，将一系列预定义命令包装成一个整体（一个队列）。当执行时，一次性<br>按照添加顺序依次执行，中间不会被打断或者干扰。一个队列中，一次性、顺序性、排他性的执行一系列命令。</p><h2 id="9-2-事务基本操作"><a href="#9-2-事务基本操作" class="headerlink" title="9.2 事务基本操作"></a>9.2 事务基本操作</h2><h3 id="9-2-1-基本命令"><a href="#9-2-1-基本命令" class="headerlink" title="9.2.1 基本命令"></a>9.2.1 基本命令</h3><ul><li> 开启事务</li></ul><blockquote><p>multi</p></blockquote><ul><li><p>作用</p><p>设定事务的开启位置，此指令执行后，后续的所有指令均加入到事务中</p></li><li><p>执行事务</p><blockquote><p>exec</p></blockquote></li><li><p>作用</p><p>设定事务的结束位置，同时执行事务。与multi成对出现，成对使用</p><p><strong><font color='red'>注意：加入事务的命令暂时进入到任务队列中，并没有立即执行，只有执行exec命令才开始执行</font></strong></p></li><li><p> 取消事务</p></li></ul><blockquote><p>discard</p></blockquote><ul><li><p>作用</p><p>终止当前事务的定义，发生在multi之后，exec之前</p><h3 id="9-2-2-事务的工作流程"><a href="#9-2-2-事务的工作流程" class="headerlink" title="9.2.2 事务的工作流程"></a>9.2.2 事务的工作流程</h3><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/tx_1.png" alt="tx_1"></p></li></ul><h3 id="9-2-3-事务的注意事项"><a href="#9-2-3-事务的注意事项" class="headerlink" title="9.2.3 事务的注意事项"></a>9.2.3 事务的注意事项</h3><ul><li>定义事务的过程中，<strong>命令格式****输入</strong>错误怎么办？<ul><li>语法错误<pre><code>指命令书写格式有误</code></pre></li><li>处理结果<pre><code> 如果定义的事务中所包含的命令存在语法错误，整体事务中所有命令均不会执行。包括那些语法正确的命令。</code></pre></li></ul></li><li>定义事务的过程中，<strong>命令执行</strong>出现错误怎么办？<ul><li>运行错误<pre><code>指命令格式正确，但是无法正确的执行。例如对list进行incr操作</code></pre></li><li>处理结果<br>  能够正确运行的命令会执行，运行错误的命令不会被执行[错的和正确地各执行各的]</li></ul></li></ul><p><font color='red'>注意：已经执行完毕的命令对应的数据不会自动回滚，需要程序员自己在代码中实现回滚。</font></p><h3 id="9-2-4-手动进行事务回滚"><a href="#9-2-4-手动进行事务回滚" class="headerlink" title="9.2.4 手动进行事务回滚"></a>9.2.4 手动进行事务回滚</h3><ul><li>记录操作过程中被影响的数据之前的状态<pre><code>    单数据：string      多数据：hash、list、set、zset</code></pre></li><li>设置指令恢复所有的被修改的项<pre><code>  单数据：直接set（注意周边属性，例如时效）  多数据：修改对应值或整体克隆复制</code></pre></li></ul><h2 id="9-3-锁"><a href="#9-3-锁" class="headerlink" title="9.3 锁"></a>9.3 锁</h2><p><strong>业务分析1:</strong></p><p> 多个客户端有可能同时操作同一组数据，并且该数据一旦被操作修改后，将不适用于继续操作<br> 在操作之前锁定要操作的数据，一旦发生变化，终止当前操作</p><p><strong>解决方案1：</strong></p><ul><li> 对 key 添加监视锁，在执行exec前如果key发生了变化，终止事务执行</li></ul><blockquote><p>watch key1 [key2……]     [只要被监控的发生了变化，则后续的事务都不会被执行，哪怕是没有被监控的对象]</p></blockquote><ul><li><p>取消对所有 key 的监视</p><blockquote><p>unwatch</p></blockquote></li></ul><p><strong>业务分析2:【超卖问题】</strong></p><p> 使用watch监控一个key有没有改变已经不能解决问题，此处要监控的是具体数据<br> 虽然redis是单线程的，但是多个客户端对同一数据同时进行操作时，如何避免不被同时修改？</p><p><strong>解决方案2：</strong></p><ul><li> 使用 setnx 设置一个公共锁</li></ul><blockquote><p>setnx lock-key value</p></blockquote><p>  利用setnx命令的返回值特征，有值则返回设置失败，无值则返回设置成功<br>           对于返回设置成功的，拥有控制权，进行下一步的具体业务操作<br>          对于返回设置失败的，不具有控制权，排队或等待<br>  操作完毕通过del操作释放锁</p><p>  注意：上述解决方案是一种设计概念，依赖规范保障，具有风险性</p><p><strong>业务分析3:</strong></p><p> 由于锁操作由用户控制加锁解锁，必定会存在<font color='cornflowerblue'>加锁后未解锁</font>的风险<br> 需要解锁操作不能仅依赖用户控制，系统级别要给出对应的保底处理方案</p><p><strong>解决方案3：</strong></p><ul><li> 使用 expire 为锁key添加时间限定，到时不释放，放弃锁</li></ul><blockquote><p>expire lock-key second<br>pexpire lock-key milliseconds</p></blockquote><p>  由于操作通常都是微秒或毫秒级，因此该锁定时间不宜设置过大。具体时间需要业务测试后确认。<br>        例如：持有锁的操作最长执行时间127ms，最短执行时间7ms。<br>        测试百万次最长执行时间对应命令的最大耗时，测试百万次网络延迟平均耗时<br>        锁时间设定推荐：最大耗时<em>120%+平均网络延迟</em>110%<br>        如果业务最大耗时&lt;&lt;网络平均延迟，通常为2个数量级，取其中单个耗时较长即可</p><h1 id="10-Redis删除策略"><a href="#10-Redis删除策略" class="headerlink" title="10. Redis删除策略"></a>10. Redis删除策略</h1><h2 id="10-1-过期数据"><a href="#10-1-过期数据" class="headerlink" title="10.1 过期数据"></a>10.1 过期数据</h2><p>Redis中的数据特征</p><ul><li>Redis是一种内存级数据库，所有数据均存放在内存中，内存中的数据可以通过TTL指令获取其状态<ul><li>XX ：具有时效性的数据</li><li> -1 ：永久有效的数据</li><li> -2 ：已经过期的数据 或 被删除的数据 或 未定义的数据</li></ul></li></ul><h2 id="10-2-数据删除策略"><a href="#10-2-数据删除策略" class="headerlink" title="10.2 数据删除策略"></a>10.2 数据删除策略</h2><ol><li><p>定时删除</p></li><li><p>惰性删除</p></li><li><p>定期删除</p><p><strong>时效性数据的存储结构</strong></p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/del_1.png" alt="del_1"></p></li></ol><h3 id="10-2-1-定时删除"><a href="#10-2-1-定时删除" class="headerlink" title="10.2.1 定时删除"></a>10.2.1 定时删除</h3><ul><li> 创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作</li><li>优点：节约内存，到时就删除，快速释放掉不必要的内存占用</li><li>缺点：CPU压力很大，无论CPU此时负载量多高，均占用CPU，会影响redis服务器响应时间和指令吞吐量</li><li>总结：用处理器性能换取存储空间 （拿时间换空间）</li></ul><h3 id="10-2-2-惰性删除"><a href="#10-2-2-惰性删除" class="headerlink" title="10.2.2 惰性删除"></a>10.2.2 惰性删除</h3><ul><li>数据到达过期时间，不做处理。等下次访问该数据时<ul><li>如果未过期，返回数据</li><li>发现已过期，删除，返回不存在</li></ul></li><li>优点：节约CPU性能，发现必须删除的时候才删除</li><li> 缺点：内存压力很大，出现长期占用内存的数据</li><li>总结：用存储空间换取处理器性能（拿空间换时间)<br>会用到expireIfNeeded()函数</li></ul><h3 id="10-2-3-定期删除"><a href="#10-2-3-定期删除" class="headerlink" title="10.2.3 定期删除"></a>10.2.3 定期删除</h3><p><strong>定时轮询，对每个库进行轮询</strong></p><ul><li><p>Redis启动服务器初始化时，读取配置server.hz的值，默认为10</p></li><li><p>每秒钟执行server.hz次<strong>serverCron()</strong>——&gt;<strong>databasesCron()</strong>——–&gt;<strong>activeExpireCycle()</strong></p></li><li><p> <font color='red'>activeExpireCycle()</font>对每个expires[*]逐一进行检测，每次执行250ms/server.hz</p></li><li><p>*对某个expires[*]检测时，随机挑选W个key检测</p></li><li><p>如果key超时，删除key</p></li><li><p>如果一轮中删除的key的数量&gt;W*25%，循环该过程</p></li><li><p>如果一轮中删除的key的数量≤W<em>25%，检查下一个expires[</em>]，0-15循环</p></li><li><p>W取值=ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP属性值</p></li><li><p> 参数current_db用于记录<font color='red'>activeExpireCycle() </font>进入哪个expires[*] 执行</p></li><li><p>如果<font color='red'>activeExpireCycle()</font>执行时间到期，下次从current_db继续向下执行</p></li></ul><p>总结：</p><ol><li>周期性轮询redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度</li><li>特点1：CPU性能占用设置有峰值，检测频度可自定义设置</li><li>特点2：内存压力不是很大，长期占用内存的冷数据会被持续清理</li><li>总结：周期性抽查存储空间（随机抽查，重点抽查）</li></ol><h3 id="10-2-4-删除策略比对"><a href="#10-2-4-删除策略比对" class="headerlink" title="10.2.4 删除策略比对"></a>10.2.4 删除策略比对</h3><table><thead><tr><th>定期删除</th><th>内存定期随机清理</th><th>每秒花费固定的CPU资源维护内存</th><th>随机抽查，重点抽查</th></tr></thead><tbody><tr><td>定时删除</td><td>节约内存，无占用</td><td>不分时段占用CPU资源，频度高</td><td>拿时间换空间</td></tr><tr><td>惰性删除</td><td>内存占用严重</td><td>延时执行，CPU利用率高</td><td>拿空间换时间</td></tr></tbody></table><h2 id="10-3-逐出算法（淘汰算法）"><a href="#10-3-逐出算法（淘汰算法）" class="headerlink" title="10.3 逐出算法（淘汰算法）"></a>10.3 逐出算法（淘汰算法）</h2><p>问题：当新数据进入redis时，如果内存不足怎么办？</p><ul><li>Redis使用内存存储数据，在执行每一个命令前，会调用<font color='red'>freeMemoryIfNeeded()</font>检测内存是否充足。如<br>果内存不满足新加入数据的最低存储要求，redis要临时删除一些数据为当前指令清理存储空间。清理数据<br>的策略称为逐出算法。</li><li>注意：逐出数据的过程不是100%能够清理出足够的可使用的内存空间，如果不成功则反复执行。当对所<br>有数据尝试完毕后，如果不能达到内存清理的要求，将出现错误信息。</li></ul><h3 id="10-3-1-影响数据逐出的相关配置"><a href="#10-3-1-影响数据逐出的相关配置" class="headerlink" title="10.3.1. 影响数据逐出的相关配置"></a>10.3.1. 影响数据逐出的相关配置</h3><ul><li><p>最大可使用内存</p><blockquote><p>maxmemory</p></blockquote><p>占用物理内存的比例，默认值为0，表示不限制。生产环境中根据需求设定，通常设置在50%以上。</p></li><li><p>每次选取待删除数据的个数</p><blockquote><p>maxmemory-samples</p></blockquote><p>选取数据时并不会全库扫描，导致严重的性能消耗，降低读写性能。因此采用随机获取数据的方式作为待检测删除数据</p></li><li><p> 删除策略</p></li></ul><blockquote><p>maxmemory-policy</p></blockquote><p>  达到最大内存后的，对被挑选出来的数据进行删除的策略</p><h3 id="10-3-2-逐出算法种类"><a href="#10-3-2-逐出算法种类" class="headerlink" title="10.3.2. 逐出算法种类"></a>10.3.2. 逐出算法种类</h3><ol><li>检测易失数据（可能会过期的数据集server.db[i].expires ）<br>① volatile-lru：挑选最近最少使用的数据淘汰<br>② volatile-lfu：挑选最近使用次数最少的数据淘汰<br>③ volatile-ttl：挑选将要过期的数据淘汰<br>④ volatile-random：任意选择数据淘汰</li><li>检测全库数据（所有数据集server.db[i].dict ）<br>⑤ allkeys-lru：挑选最近最少使用的数据淘汰<br>⑥ allkeys-lfu：挑选最近使用次数最少的数据淘汰<br>⑦ allkeys-random：任意选择数据淘汰</li><li>放弃数据驱逐<br>⑧ no-enviction（驱逐）：禁止驱逐数据（redis4.0中默认策略），会引发错误OOM（Out Of Memory）</li></ol><p><strong>数据逐出策略配置依据</strong><br> 使用INFO命令输出监控信息，查询缓存 hit 和 miss 的次数，根据业务需求调优Redis配置</p><h1 id="11-主从复制"><a href="#11-主从复制" class="headerlink" title="11. 主从复制"></a>11. 主从复制</h1><h2 id="11-1-主从复制简介"><a href="#11-1-主从复制简介" class="headerlink" title="11.1. 主从复制简介"></a>11.1. 主从复制简介</h2><h3 id="11-1-1-互联网“三高”架构"><a href="#11-1-1-互联网“三高”架构" class="headerlink" title="11.1.1. 互联网“三高”架构"></a>11.1.1. 互联网“三高”架构</h3><ul><li> 高并发</li><li>高性能</li><li> 高可用</li></ul><p><strong>单机redis的风险与问题</strong></p><ul><li>问题1.机器故障<pre><code>      现象：硬盘故障、系统崩溃          本质：数据丢失，很可能对业务造成灾难性打击           结论：基本上会放弃使用redis.</code></pre></li><li>问题2.容量瓶颈<pre><code>    现象：内存不足，从16G升级到64G，从64G升级到128G，无限升级内存   本质：穷，硬件条件跟不上   结论：放弃使用redis</code></pre></li><li>结论：<pre><code>   为了避免单点Redis服务器故障，准备多台服务器，互相连通。将数据复制多个副本保存在不同的服   务器上，连接在一起，并保证数据是同步的。即使有其中一台服务器宕机，其他服务器依然可以继续  提供服务，实现Redis的高可用，同时实现数据冗余备份。</code></pre></li></ul><h4 id="11-1-2-多台服务器连接方案"><a href="#11-1-2-多台服务器连接方案" class="headerlink" title="11.1.2. 多台服务器连接方案"></a>11.1.2. 多台服务器连接方案</h4><ul><li><p>提供数据方：master</p><ul><li>主服务器，主节点，主库</li><li>主客户端</li></ul></li><li><p>接收数据方：slave</p><ul><li>从服务器，从节点，从库</li><li>从客户端</li></ul></li><li><p>需要解决的问题：</p><ul><li>数据同步</li></ul></li><li><p>核心工作：</p><ul><li><p>master的数据复制到slave中</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/%E4%B8%BB%E4%BB%8E_01.png" alt="主从_01"></p></li></ul></li></ul><h3 id="11-1-3-主从复制的作用"><a href="#11-1-3-主从复制的作用" class="headerlink" title="11.1.3. 主从复制的作用"></a>11.1.3. 主从复制的作用</h3><p>主从复制即将master中的数据即时、有效的复制到slave中<br>特征：一个master可以拥有多个slave，一个slave只对应一个master</p><p>职责：</p><ul><li><p>master:</p><ul><li>写数据</li><li>执行写操作时，将出现变化的数据自动同步到slave</li><li> 读数据（可忽略）</li></ul></li><li><p>slave:</p><ul><li> 读数据</li><li>写数据（禁止）</li></ul><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/%E9%9B%86%E7%BE%A4.png" alt="集群"></p></li><li><p>读写分离：master写、slave读，提高服务器的读写负载能力</p></li><li><p> 负载均衡：基于主从结构，配合读写分离，由slave分担master负载，并根据需求的变化，改变slave的数量，通过多个从节点分担数据读取负载，大大提高Redis服务器并发量与数据吞吐量</p></li><li><p>故障恢复：当master出现问题时，由slave提供服务，实现快速的故障恢复</p></li><li><p>数据冗余：实现数据热备份，是持久化之外的一种数据冗余方式</p></li><li><p>高可用基石：基于主从复制，构建哨兵模式与集群，实现Redis的高可用方案</p></li></ul><h2 id="11-2-主从复制工作流程"><a href="#11-2-主从复制工作流程" class="headerlink" title="11.2. 主从复制工作流程"></a>11.2. 主从复制工作流程</h2><p>主从复制过程大体可以分为3个阶段<br> 建立连接阶段（即准备阶段）<br> 数据同步阶段<br> 命令传播阶段</p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/主从流程_01.png" alt="主从流程_01" style="zoom:67%;" /><h3 id="11-2-1-阶段一：建立连接阶段"><a href="#11-2-1-阶段一：建立连接阶段" class="headerlink" title="11.2.1 阶段一：建立连接阶段"></a>11.2.1 阶段一：建立连接阶段</h3><ul><li> 建立slave到master的连接，使master能够识别slave，并保存slave端口号</li></ul><p>步骤1：设置master的地址和端口，客户端保存master信息<br>步骤2：建立socket连接<br>步骤3：发送ping命令（定时器任务）<br>步骤4：身份验证<br>步骤5：发送slave端口信息<br>至此，主从连接成功！<br><strong>状态：</strong><br>slave：保存master的地址与端口<br>master：保存slave的端口<br><strong>总体：</strong><br>之间创建了连接的socket</p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/stage_01.png" alt="stage_01" style="zoom:67%;" /><p>主从连接（slave连接master）：</p><ol><li><p>方式一：客户端发送命令</p><blockquote><p>slaveof <masterip> <masterport>  [从主动连接]</p></blockquote></li><li><p>方式二：启动服务器参数</p><blockquote><p>redis-server -slaveof <masterip> <masterport></p></blockquote></li><li><p>方式三：服务器配置</p><blockquote><p>slaveof <masterip> <masterport>   [在配置文件中配置，启动这个配置文件时，就会有主从结构]</p></blockquote></li></ol><p>主从断开连接:</p><ol><li><p>客户端发送命令</p><blockquote><p>slaveof no one</p><p>attention:   slave断开连接后，不会删除已有数据，只是不再接受master发送的数据</p></blockquote></li></ol><ul><li> 授权访问</li></ul><table><thead><tr><th>1 master客户端发送命令设置密码</th><th>1 slave客户端发送命令设置密码</th></tr></thead><tbody><tr><td>requirepass <password></td><td>auth <password></td></tr><tr><td>2 master配置文件设置密码</td><td>2 slave配置文件设置密码</td></tr><tr><td>config set requirepass <password></td><td>masterauth <password></td></tr><tr><td>config get requirepass</td><td>3 slave启动服务器设置密码</td></tr><tr><td></td><td>redis-server –a <password></td></tr></tbody></table><h3 id="11-2-2-阶段二：数据同步阶段工作流程"><a href="#11-2-2-阶段二：数据同步阶段工作流程" class="headerlink" title="11.2.2 阶段二：数据同步阶段工作流程"></a>11.2.2 阶段二：数据同步阶段工作流程</h3><ul><li>在slave初次连接master后，复制master中的所有数据到slave</li><li> 将slave的数据库状态更新成master当前的数据库状态</li></ul><p>步骤1：请求同步数据<br>步骤2：创建RDB同步数据<br>步骤3：恢复RDB同步数据<br>步骤4：请求部分同步数据<br>步骤5：恢复部分同步数据<br>至此，数据同步工作完成！ </p><p><strong>状态：</strong><br>slave：具有master端全部数据，包含RDB过程接收的数据<br>master：保存slave当前数据同步的位置<br><strong>总体：</strong><br>之间完成了数据克隆</p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/stage_02.png" alt="stage_02" style="zoom:67%;" /><p><strong>数据同步阶段master说明</strong></p><ol><li><p>如果master数据量巨大，数据同步阶段应避开流量高峰期，避免造成master阻塞，影响业务正常执行</p></li><li><p>复制缓冲区大小设定不合理，会导致数据溢出。如进行全量复制周期太长，进行部分复制时发现数据已经存在丢失的情况，必须进行第二次全量复制，致使slave陷入死循环状态。</p></li></ol><blockquote><p>repl-backlog-size 1mb     [master修改复制缓冲区的大小]</p></blockquote><ol start="3"><li>master单机内存占用主机内存的比例不应过大，建议使用50%-70%的内存，留下30%-50%的内存用于执行bgsave命令和创建复制缓冲区</li></ol><p><strong>数据同步阶段slave说明</strong></p><ol><li><p>为避免slave进行全量复制、部分复制时服务器响应阻塞或数据不同步，建议关闭此期间的对外服务</p><blockquote><p>slave-serve-stale-data yes|no</p></blockquote></li><li><p>数据同步阶段，master发送给slave信息可以理解master是slave的一个客户端，主动向slave发送命令</p></li><li><p>多个slave同时对master请求数据同步，master发送的RDB文件增多，会对带宽造成巨大冲击，如果master带宽不足，因此数据同步需要根据业务需求，适量错峰</p></li><li><p>slave过多时，建议调整拓扑结构，由一主多从结构变为树状结构，中间的节点既是master，也是slave。注意使用树状结构时，由于层级深度，导致深度越高的slave与最顶层master间数据同步延迟较大，数据一致性变差，应谨慎选择</p></li></ol><h3 id="11-2-3-命令传播阶段"><a href="#11-2-3-命令传播阶段" class="headerlink" title="11.2.3 命令传播阶段"></a>11.2.3 命令传播阶段</h3><ul><li><p>当master数据库状态被修改后，导致主从服务器数据库状态不一致，此时需要让主从数据同步到一致的<br>状态，同步的动作称为命令传播</p></li><li><p>master将接收到的数据变更命令发送给slave，slave接收命令后执行命令</p></li></ul><p>不同情况发生时，命令传播阶段会采用不同的数据同步方法</p><ul><li> 网络闪断闪连           忽略</li><li>短时间网络中断        部分复制</li><li>长时间网络中断       全量复制</li></ul><p>部分复制的三个核心要素</p><ol><li><p>服务器的运行 id（run id）</p><blockquote><p>概念：服务器运行ID是每一台服务器每次运行的身份识别码，一台服务器多次运行可以生成多个运行id</p><p>作用：运行id被用于在服务器间进行传输，识别身份如果想两次操作均对同一台服务器进行，必须每次操作携带对应的运行id，用于对方识别</p><p>实现方式：运行id在每台服务器启动时自动生成的，master在首次连接slave时，会将自己的运行ID发送给slave，slave保存此ID，通过info Server命令，可以查看节点的runid</p></blockquote></li><li><p> 主服务器的复制积压缓冲区</p></li></ol><blockquote><p>概念：复制缓冲区，又名复制积压缓冲区，是一个先进先出（FIFO）的队列，用于存储服务器执行过的命令，每次传播命令，master都会将传播的命令记录下来，并存储在复制缓冲区</p></blockquote><ol start="3"><li><p>主从服务器的复制偏移量</p><blockquote><p>概念：一个数字，描述复制缓冲区中的指令字节位置</p><p>作用：同步信息，比对master与slave的差异，当slave断线后，恢复数据使用</p></blockquote></li></ol><p><font color='red'>数据同步+命令传播阶段工作流程</font></p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/stage_23.png" alt="stage_23"></p><h3 id="11-2-4-心跳机制"><a href="#11-2-4-心跳机制" class="headerlink" title="11.2.4 心跳机制"></a>11.2.4 心跳机制</h3><ul><li>进入命令传播阶段候，master与slave间需要进行信息交换，使用心跳机制进行维护，实现双方连接保持在线</li><li>master心跳：<ul><li>指令：PING</li><li> 周期：由repl-ping-slave-period决定，默认10秒</li><li> 作用：判断slave是否在线</li><li>查询：INFO replication  获取slave最后一次连接时间间隔，lag项维持在0或1视为正常</li></ul></li><li>slave心跳任务<ul><li> 指令：REPLCONF ACK {offset}</li><li> 周期：1秒</li><li>作用1：汇报slave自己的复制偏移量，获取最新的数据变更指令</li><li> 作用2：判断master是否在线</li></ul></li></ul><h1 id="12-哨兵模式"><a href="#12-哨兵模式" class="headerlink" title="12. 哨兵模式"></a>12. 哨兵模式</h1><h2 id="12-1-哨兵简介"><a href="#12-1-哨兵简介" class="headerlink" title="12.1 哨兵简介"></a>12.1 哨兵简介</h2><p>哨兵(sentinel) 是一个分布式系统，用于对主从结构中的每台服务器进行<font color='cornflowerblue'>监控</font>，当出现故障时通过投票机制<font color='cornflowerblue'>选择</font>新的master并将所有slave连接到新的master。</p><p><strong>哨兵的作用</strong>    </p><ul><li>监控<ul><li>不断的检查master和slave是否正常运行。</li><li>master存活检测、master与slave运行情况检测</li></ul></li><li>通知（提醒）<ul><li>当被监控的服务器出现问题时，向其他（哨兵间，客户端）发送通知。</li></ul></li><li>自动故障转移<ul><li>断开master与slave连接，选取一个slave作为master，将其他slave连接到新的master，并告知客户端新的服务器地址</li></ul></li></ul><p><font color='cornflowerblue'>注意：</font></p><ul><li>哨兵也是一台redis服务器，只是不提供数据服务</li><li>通常哨兵配置数量为<font color='red'>单数</font></li></ul><h2 id="12-2-启动哨兵模式"><a href="#12-2-启动哨兵模式" class="headerlink" title="12.2 启动哨兵模式"></a>12.2 启动哨兵模式</h2><ul><li><p>配置一拖二的主从结构</p></li><li><p>配置三个哨兵（配置相同，端口不同）<br>参看sentinel.conf</p></li><li><p>启动哨兵</p><blockquote><p>redis-sentinel sentinel- 端口号 .conf</p></blockquote></li></ul><p>配置哨兵</p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/sential_config.png" alt="sential_config"></p><h2 id="12-3-哨兵工作原理"><a href="#12-3-哨兵工作原理" class="headerlink" title="12.3 哨兵工作原理"></a>12.3 哨兵工作原理</h2><p> 哨兵在进行主从切换过程中经历三个阶段</p><ul><li>监控</li><li>通知</li><li>故障转移</li></ul><h3 id="12-3-1-监控阶段"><a href="#12-3-1-监控阶段" class="headerlink" title="12.3.1 监控阶段"></a>12.3.1 监控阶段</h3><p>用于同步各个节点的状态信息</p><ul><li><p> 获取各个sentinel的状态（是否在线）</p></li><li><p> 获取master的状态</p></li><li><p>master属性</p></li><li><p>runid</p></li><li><p>role：master</p></li><li><p> 各个slave的详细信息</p></li><li><p>获取所有slave的状态（根据master中的slave信息）</p><ul><li> runid</li><li>role：slave</li><li> master_host、master_port</li><li> offset</li><li> ……</li></ul></li></ul><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/sential_stage01.png" alt="sential_stage01"  /><h3 id="12-3-2-通知阶段"><a href="#12-3-2-通知阶段" class="headerlink" title="12.3.2 通知阶段"></a>12.3.2 通知阶段</h3><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/sential_stage02.png" alt="sential_stage02"></p><h3 id="12-3-3-故障转移阶段"><a href="#12-3-3-故障转移阶段" class="headerlink" title="12.3.3 故障转移阶段"></a>12.3.3 故障转移阶段</h3><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/sential_stage03.png" alt="sential_stage03"></p><p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/stage032.png" alt="stage032"></p><p>选择了哨兵老大过后，选择相应的slave当选master</p><ul><li>服务器列表中挑选备选master<ul><li> 在线的</li><li>响应快的</li><li> 与原master断开时间短的</li><li>优先原则<ul><li> 优先级</li><li>offset</li><li>runid</li></ul></li></ul></li><li>发送指令（ sentinel ）<ul><li> 向新的master发送slaveof no one</li><li> 向其他slave发送slaveof 新masterIP端口</li></ul></li></ul><h3 id="12-4-总结"><a href="#12-4-总结" class="headerlink" title="12.4 总结"></a>12.4 总结</h3><ul><li> 监控</li><li> 同步信息</li><li>通知<ul><li> 保持联通   【sentinel和sentinel，sentinel和master和 slave】</li></ul></li><li>故障转移<ul><li> 发现问题</li><li>竞选负责人   【选取sentinel来处理故障】</li><li> 优选新master</li><li> 新master上任，其他slave切换master，原master作为slave故障回复后连接</li></ul></li></ul><h1 id="13-Cluster"><a href="#13-Cluster" class="headerlink" title="13. Cluster"></a>13. Cluster</h1><h2 id="13-1-集群简介"><a href="#13-1-集群简介" class="headerlink" title="13.1 集群简介"></a>13.1 集群简介</h2><p>集群就是使用网络将若干台计算机联通起来，并提供统一的管理方式，使其对外呈现单机的服务效果</p><p><strong>集群作用</strong></p><ul><li><p> 分散单台服务器的访问压力，实现负载均衡</p></li><li><p> 分散单台服务器的存储压力，实现可扩展性</p></li><li><p> 降低单台服务器宕机带来的业务灾难</p></li></ul>  <img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/cluster.png" alt="cluster" style="zoom:67%;" /><h2 id="13-2-redis集群结构设计"><a href="#13-2-redis集群结构设计" class="headerlink" title="13.2 redis集群结构设计"></a>13.2 redis集群结构设计</h2><ol><li>数据存储设计</li></ol><ul><li><p>通过算法设计，计算出key应该保存的位置</p></li><li><p>将所有的存储空间计划切割成16384份，每台主机保存一部分每份代表的是一个存储空间，不是一个key的保存空间</p></li><li><p>将key按照计算出的结果放到对应的存储空间【槽】</p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/slot_cal.png" alt="slot_cal" style="zoom:67%;" /></li></ul><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/slot.png" alt="slot" style="zoom:50%;" /><ol start="2"><li>集群内部通讯设计</li></ol><ul><li><p>各个数据库相互通信，保存各个库中槽的编号数据</p></li><li><p>一次命中，直接返回</p></li><li><p>一次未命中，告知具体位置</p><img src="https://cdn.jsdelivr.net/gh/kusuzi/image-folder@master/Redis/cluster_com.png" alt="cluster_com" style="zoom:67%;" /></li></ul><h2 id="13-3-cluster集群结构搭建"><a href="#13-3-cluster集群结构搭建" class="headerlink" title="13.3 cluster集群结构搭建"></a>13.3 cluster集群结构搭建</h2><p><a href="https://www.bilibili.com/video/BV1CJ411m7Gc?p=104&spm_id_from=pageDriver">视频搭建教程</a></p><h1 id="14-企业级解决方案"><a href="#14-企业级解决方案" class="headerlink" title="14. 企业级解决方案"></a>14. 企业级解决方案</h1><h2 id="14-2-缓存预热"><a href="#14-2-缓存预热" class="headerlink" title="14.2 缓存预热"></a>14.2 缓存预热</h2><p><strong>问题</strong>：服务器启动后迅速宕机</p><p><strong>排查：</strong></p><ol><li>请求数量较高</li><li>主从之间数据吞吐量较大，数据同步操作频度较高</li></ol><p><strong>解决方案：</strong></p><p>前置准备工作：</p><ol><li>日常例行统计数据访问记录，统计访问频度较高的热点数据</li><li>利用LRU数据删除策略，构建数据留存队列<br>例如：storm与kafka配合</li></ol><p>准备工作：</p><ol><li>将统计结果中的数据分类，根据级别，redis优先加载级别较高的热点数据</li><li>利用分布式多服务器同时进行数据读取，提速数据加载过程</li><li>热点数据主从同时预热</li></ol><p>实施：</p><ol><li>使用脚本程序固定触发数据预热过程</li><li>如果条件允许，使用了CDN（内容分发网络），效果会更好</li></ol><p><strong>总结</strong>：缓存预热就是系统启动前，<font color='red'>提前将相关的缓存数据直接加载到缓存系统</font>。避免在用户请求的时候，先查询数据库，然后再将数据缓<br>存的问题！用户直接查询事先被预热的缓存数据！</p><h2 id="14-2-缓存雪崩"><a href="#14-2-缓存雪崩" class="headerlink" title="14.2 缓存雪崩"></a>14.2 缓存雪崩</h2><p><strong>问题</strong>：缓存雪崩描述的就是这样⼀个简单的场景：<strong>缓存在同⼀时间大面积的失效，后⾯的请求都直接落到了数据库上，</strong>造成数据库短时间内承受⼤量请求。 这就好⽐雪崩⼀样，摧枯拉朽之势，数据库的压⼒可想⽽知，可能直接就被这么多请求弄宕机了。</p><p><strong>解决方案：</strong></p><p>针对 Redis 服务不可⽤的情况：</p><ol><li>采⽤ Redis 集群，避免单机出现问题整个缓存服务都没办法使⽤。</li><li>限流，避免同时处理⼤量的请求。</li></ol><p>针对热点缓存失效的情况：</p><ol><li>数据有效期策略调整<ul><li>根据业务数据有效期进行分类错峰，A类90分钟，B类80分钟，C类70分钟</li><li>过期时间使用固定时间+随机值的形式，稀释集中到期的key的数量</li></ul></li><li>缓存永不失效。</li></ol><p><strong>总结：</strong>缓存雪崩就是<strong>瞬间过期数据量太大，导致对数据库服务器造成压力。</strong>如能够有效避免过期时间集中，可以有效解决雪崩现象的出现<br>（约40%），配合其他策略一起使用，并监控服务器的运行数据，根据运行记录做快速调整。</p><h2 id="14-3-缓存击穿"><a href="#14-3-缓存击穿" class="headerlink" title="14.3 缓存击穿"></a>14.3 缓存击穿</h2><p><strong>问题：</strong></p><ol><li>Redis中<strong>某个key</strong>过期，该key访问量巨大</li><li>多个数据请求从服务器直接压到Redis后，均未命中</li><li>Redis在短时间内发起了大量对数据库中<strong>同一数据的访问</strong></li></ol><p><strong>解决方案：</strong></p><ol><li>预先设定<br>以电商为例，每个商家根据店铺等级，指定若干款主打商品，在购物节期间，加大此类信息key的过期时长<br>注意：购物节不仅仅指当天，以及后续若干天，访问峰值呈现逐渐降低的趋势</li><li>现场调整<br>监控访问量，对自然流量激增的数据延长过期时间或设置为永久性key</li><li>后台刷新数据<br>启动定时任务，高峰期来临之前，刷新数据有效期，确保不丢失</li><li>二级缓存<br>设置不同的失效时间，保障不会被同时淘汰就行</li><li>加锁<br>分布式锁，防止被击穿，但是要注意也是性能瓶颈，慎重！</li></ol><p><strong>总结</strong>：缓存击穿就是<strong>单个高热数据过期的瞬间，数据访问量较大</strong>，未命中redis后，发起了大量对同一数据的数据库访问，导致对数据库服务器造成压力。应对策略应该在业务数据分析与预防方面进行，配合运行监控测试与即时调整策略，毕竟单个key的过期监控难度<br>较高，配合雪崩处理策略即可。</p><h2 id="14-4-缓存穿透"><a href="#14-4-缓存穿透" class="headerlink" title="14.4 缓存穿透"></a>14.4 缓存穿透</h2><p><strong>问题：</strong></p><ul><li>获取的数据在Redis和数据库中都不存在，数据库查询未得到对应数据</li><li>Redis获取到null数据未进行持久化，直接返回</li><li>下次此类数据到达重复上述过程</li><li>出现黑客攻击服务</li></ul><p><strong>解决方案：</strong></p><ol><li>缓存null【无效key】<br>对查询结果为null的数据进行缓存（长期使用，定期清理），设定短时限，例如30-60秒，最高5分钟</li><li>白名单策略</li></ol><ul><li>提前预热各种分类数据id对应的bitmaps，id作为bitmaps的offset，相当于设置了数据白名单。当加载正常数据时，放<br>行，加载异常数据时直接拦截（效率偏低）</li><li> <strong>使用布隆过滤器</strong>（有关布隆过滤器的命中问题对当前状况可以忽略）</li></ul><ol start="3"><li>实施监控<br> 实时监控redis命中率（业务正常范围时，通常会有一个波动值）与null数据的占比</li></ol><ul><li>非活动时段波动：通常检测3-5倍，超过5倍纳入重点排查对象</li><li>活动时段波动：通常检测10-50倍，超过50倍纳入重点排查对象<br>根据倍数不同，启动不同的排查流程。然后使用黑名单进行防控（运营）</li></ul><ol start="4"><li>key加密<br> 问题出现后，临时启动防灾业务key，对key进行业务层传输加密服务，设定校验程序，过来的key校验<br> 例如每天随机分配60个加密串，挑选2到3个，混淆到页面数据id中，发现访问key不满足规则，驳回数据访问</li></ol><p>缓存击穿访问了不存在的数据，跳过了合法数据的redis数据缓存阶段，每次访问数据库，导致对数据库服务器造成压力,根本没有经过缓存这⼀层。通常此类数据的出现量是一个较低的值，当出现此类情况以毒攻毒，并及时报警。应对策略应该在临时预案防范方面多做文章。</p><h2 id="14-5-性能指标监控"><a href="#14-5-性能指标监控" class="headerlink" title="14.5 性能指标监控"></a>14.5 性能指标监控</h2><ul><li> 性能指标：Performance</li><li> 内存指标：Memory</li><li> 基本活动指标：Basic activity</li><li>持久性指标：Persistence</li><li>错误指标：Error</li></ul>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>learn</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
